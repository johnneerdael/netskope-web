<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Nathan Catania</title>
        <link>https://nathancatania.com/posts/</link>
        <description>Recent content in Posts on Nathan Catania</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Mon, 24 Jul 2023 00:00:00 +0000</lastBuildDate>
        <atom:link href="https://nathancatania.com/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Insecure Kubernetes for Evaluation Purposes</title>
            <link>https://nathancatania.com/posts/insecure-kubernetes-for-evaluation-purposes/</link>
            <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/insecure-kubernetes-for-evaluation-purposes/</guid>
            <description>&amp;nbsp; Heads Up!
This document is a draft &amp;amp; is pending spelling and grammar corrections + citations. This is a quick document that covers my own notes and the steps to follow to deploy an app (Rocket.Chat) using managed Kubernetes in AWS (Amazon Elastic Kubernetes Service, EKS), delibrately in an insecure manner, for the purposes of evaluating the workload security offerings of cloud security vendors.
This document will cover the deployment of a containerised public facing web service leveraging Kubernetes; specicially Amazon&amp;rsquo;s managed Kubernetes service: EKS (Elastic Kubernetes Service).</description>
            <content type="html"><![CDATA[<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
This document is a draft &amp; is pending spelling and grammar corrections + citations.
</div>

<p>This is a quick document that covers my own notes and the steps to follow to deploy an app (Rocket.Chat) using managed Kubernetes in AWS (Amazon Elastic Kubernetes Service, EKS), <strong>delibrately in an insecure manner</strong>, for the purposes of evaluating the workload security offerings of cloud security vendors.</p>
<p>This document will cover the deployment of a containerised public facing web service leveraging Kubernetes; specicially Amazon&rsquo;s managed Kubernetes service: EKS (Elastic Kubernetes Service). As part of this exercise, MongoDB and AWS S3 will also be used and configured insecurely.</p>
<p>In terms of methodology, this document will cover the setup of all services using the AWS Management Console (where possible) and NOT via CLI. Almost all of these steps can be replaced and done more succinctly using a combination of the AWS CLI and <code>eksctl</code>.</p>
<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
<strong>This exercise delibrately deploys these services in an insecure manner in order to showcase and test the security capabilities of cloud security service providers</strong>. Do not follow this guide for a production deployment or in a non-isolated environment.
</div>

<hr>
<h2 id="10---setup-infrastructure">1.0 - Setup Infrastructure</h2>
<p>In this section we will deploy the infrastructure and services required for the project. This includes:</p>
<ul>
<li>A VM running an outdated version of Ubuntu Server (Ubuntu Server 16.04).</li>
<li>An outdated version of MongoDB running on the aforementioned VM (MongoDB Community Edition 4.4.5).</li>
<li>An Amazon EKS Cluster in the same VPC as the above VM.</li>
<li>An Amazon S3 storage bucket configured for Public Read access.</li>
<li>A containized web application that leverages MongoDB as a database (Rocket.Chat)</li>
</ul>
<h3 id="11---aws-cli--kubectl">1.1 - AWS CLI &amp; <code>kubectl</code></h3>
<p>To begin, we need to ensure that we have two CLI tools on our machine to allow us to interact with our Kubernetes cluster once we have set it up:</p>
<ol>
<li>AWS CLI: This is an open-source tool that enables you to interact with AWS services using the CLI.</li>
<li><code>kubectl</code>: This is a tool that enables you to communicate with the Kubernetes API and interact with the cluster.</li>
</ol>
<h4 id="install-homebrew">Install Homebrew</h4>
<p>Homebrew is a package manager for macOS and we will use it to install the above tools:</p>
<pre tabindex="0"><code>/bin/bash -c &#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&#34;
</code></pre><p>Verify that Homebrew was installed correctly:</p>
<pre tabindex="0"><code>brew --version
...
Homebrew 4.0.28
</code></pre><h4 id="install--configure-aws-cli">Install &amp; Configure AWS CLI</h4>
<p>Install AWS CLI using Homebrew:</p>
<pre tabindex="0"><code>brew install awscli
</code></pre><p>Verify that the CLI was installed correctly:</p>
<pre tabindex="0"><code>aws --version
...
aws-cli/2.13.1 Python/3.11.4 Darwin/22.3.0 exe/x86_64 prompt/off
</code></pre><p>Next, we need to configure AWS CLI and authenticate it with our AWS account:</p>
<ol>
<li>
<p>Navigate to the security center of your AWS account: <a href="https://console.aws.amazon.com/iamv2/home#/security_credentials">console.aws.amazon.com/iamv2/home#/security_credentials</a></p>
</li>
<li>
<p>Scroll down to the <em>Access keys</em> section and select <strong>Create access key</strong>.</p>
</li>
</ol>
<p><img src="13.png" alt="13"></p>
<ol start="3">
<li>Note down both the <strong>Access key</strong> and <strong>Secret access key</strong> (the Secret access key will not be shown again after you leave this page). Click <strong>Done</strong>.</li>
</ol>
<p><img src="14.png" alt="14"></p>
<ol start="4">
<li>
<p>Run the following command to authenticate the AWS CLI using your Access key and Secret access key:</p>
<pre tabindex="0"><code>aws configure

AWS Access Key ID [None]: &lt;your-access-key-value&gt;
AWS Secret Access Key [None]: &lt;your-secret-access-key-value&gt;
Default region name [None]: &lt;your region, eg: ap-southeast-2&gt;
Default output format [None]: json
</code></pre></li>
<li>
<p>Check that your credentials were saved correctly:</p>
<pre tabindex="0"><code>aws configure list
...
      Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                &lt;not set&gt;             None    None
access_key     ****************ZYXW shared-credentials-file
secret_key     ****************abcD shared-credentials-file
    region           ap-southeast-2      config-file    ~/.aws/config
</code></pre></li>
</ol>
<h4 id="install-kubectl">Install <code>kubectl</code></h4>
<p>Install the latest version of <code>kubectl</code> using Homebrew:</p>
<pre tabindex="0"><code>brew install kubectl
</code></pre><p>Note that the version of <code>kubectl</code> must be within one minor version difference of the cluster. That is, if the cluster is configured to use v1.27, then we must use <code>kubectl</code> v1.26, v1.27, or v1.28.</p>
<p>To install a specific version of <code>kubectl</code>, see <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl-macos/">here</a>.</p>
<p>Verify that <code>kubectl</code> was installed correctly:</p>
<pre tabindex="0"><code>kubectl version --short --client
...
Client Version: v1.25.4
Kustomize Version: v4.5.7
</code></pre><h3 id="12---deploy-ubuntu-server-1604">1.2 - Deploy Ubuntu Server (16.04)</h3>
<h4 id="create-a-new-key-pair-to-access-the-vm">Create a new Key Pair to access the VM</h4>
<p>To start, we need to provide AWS with the public SSH key that we plan to use to securely log into the VM we will deploy. If you already have a key pair available in AWS, you can skip this step.</p>
<p>If you have an existing keypair on your local system, you can use that, otherwise follow the instructions <a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent">here</a> to generate a new keypair. The following steps will guide you through uploading the public key from your system into AWS so that we can assign it to our VM.</p>
<ol>
<li>
<p>Open the <a href="https://console.aws.amazon.com/kms">Key Management System (KMS) Console</a> of AWS.</p>
</li>
<li>
<p>Click the <strong>Actions</strong> button and select <strong>Import key pair</strong>.</p>
</li>
<li>
<p>Provide the key pair with a name (eg: <code>My AWS Key</code>). This is the name of the key that will be visible when selecting a key to assign to a new VM.</p>
</li>
<li>
<p>Next, select the <code>id_rsa.pub</code> file associated with your public key to upload, OR paste in the public key contents.</p>
</li>
</ol>
<ul>
<li>
<p>Assuming your keypair is saved in the default location (<code>~/.ssh/id_rsa.pub</code>), open Terminal and execute the following command to get the contents of the public key:</p>
<pre tabindex="0"><code>cat ~/.ssh/id_rsa.pub
</code></pre></li>
<li>
<p>The output should be similar to as follows (paste your own output into AWS):</p>
<pre tabindex="0"><code>ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQB/nAmOjTmezNUDKYvEeIRf2YnwM9/uUG1d0BYsc8/tRtx+RGi7N2lUbp728MXGwdnL9od4cItzky/zVdLZE2cycOa18xBK9cOWmcKS0A8FYBxEQWJ/q9YVUgZbFKfYGaGQxsER+A0w/fX8ALuk78ktP31K69LcQgxIsl7rNzxsoOQKJ/CIxOGMMxczYTiEoLvQhapFQMs3FL96didKr/QbrfB1WT6s3838SEaXfgZvLef1YB2xmfhbT9OXFE3FXvh2UPBfN+ffE7iiayQf/2XR+8j4N4bW30DiPtOQLGUrH1y5X/rpNZNlWW2+jGIxqZtgWg7lTy3mXy5x836Sj/6L

(this is not a real public key)
</code></pre></li>
</ul>
<p><img src="5.png" alt="5"></p>
<h4 id="deploy-the-vm">Deploy the VM</h4>
<ol>
<li>From the <a href="https://console.aws.amazon.com/ec2">AWS EC2 Console</a>, click <strong>Instances</strong> in the left side-bar, then and click <strong>Launch instances</strong>.</li>
<li>Set the name of the VM to <code>MongoDB</code></li>
<li>When prompted to select an OS / AMI image, select <strong>Browse more AMIs</strong>.</li>
</ol>
<p><img src="3.png" alt="3"></p>
<ol start="3">
<li>
<p>Click the <strong>Community AMIs</strong> tab, then search for <code>ami-0e554a91eb4e7b6d7</code> (the AMI ID of the Ubuntu Server 16.04 LTS image we need).</p>
<ul>
<li>
<p>Select the AMI <code>ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-20210721</code></p>
</li>
<li>
<p>Alternatively, search for <code>ubuntu 16.04 amd64</code> and select an available AMI. Be mindful of the publish dates: the more out-of-date, the better.</p>
</li>
</ul>
</li>
</ol>
<p><img src="1.png" alt="1"></p>
<ol start="4">
<li>Back on the main <strong>Launch an instance</strong> screen, under** <strong>Instance type</strong>, select the cheapest instance with 1 vCPU and 1GB memory. At the time of posting this is <code>t2.micro</code> which is also eligible for the AWS Free Tier.</li>
</ol>
<p><img src="2.png" alt="2"></p>
<ol start="5">
<li>
<p>Under the <strong>Key pair</strong> section, select either an existing public key, or the name of the public key you uploaded earlier.</p>
</li>
<li>
<p>Under <strong>Network Settings</strong>, click the <strong>Edit</strong> button.</p>
<ul>
<li>
<p>Ensure that <strong>Auto-assign public IP</strong> is set to enable (for now).</p>
</li>
<li>
<p>Create a new security group called <code>Mgmt Access</code> and put in two rules:</p>
<ol>
<li>Type: SSH
Source type: My IP</li>
<li>Type: All ICMP - IPv4
Source type: My IP</li>
</ol>
</li>
<li>
<p>These rules allow you to connect to your MongoDB VM (and test connectivity to it using <code>ping</code>) across the internet. To secure this access (somewhat), we are limiting connections to only those from your own IP address.</p>
<p>WARNING: In practice, this is not recommended for internal services and your should close off ALL public exposure to the VM to ensure it is secured. VMs should be managed via an inside-out ZTNA service like Cloudflare, Zscaler, or Tailscale to ensure that <em>nothing</em> is exposed directly to the internet.</p>
</li>
</ul>
</li>
</ol>
<p><img src="6.png" alt="6"></p>
<ol start="7">
<li>Under <strong>Configure storage</strong>, set the root volume to 15GB of <code>gp2</code> storage.</li>
<li>Finished! When you are ready to deploy the VM, click <strong>Launch instance</strong>.</li>
</ol>
<p><img src="7.png" alt="7"></p>
<h4 id="connect-to-the-vm">Connect to the VM</h4>
<ol>
<li>
<p>Return to the EC2 console where you should now see your <code>MongoDB</code> VM with an instance state of either <code>Pending</code> or <code>Running</code>. If it is <code>Pending</code>, wait a few moments before attempting the below.</p>
</li>
<li>
<p>Select the MongoDB VM from the instance list, and in the table that appears at the bottom of the screen, under the <strong>Details</strong> tab, take note of the <strong>Public IPv4 address</strong>.</p>
</li>
<li>
<p>Open a new terminal window and SSH to the public IP address of the VM. The default username will be <code>ubuntu</code>:</p>
<pre tabindex="0"><code>ssh ubuntu@&lt;your-vm-public-ip&gt;
</code></pre><p>You can also manually specify the path of the private key to use if you have multiple key pairs on your machine:</p>
<pre tabindex="0"><code>ssh -i ~/.ssh/your_private_key ubuntu@&lt;your-vm-public-ip&gt;
</code></pre></li>
</ol>
<h3 id="13---deploy-mongodb-445">1.3 - Deploy MongoDB (4.4.5)</h3>
<p>In this section, we will deploy an older version of MongoDB (<a href="https://www.mongodb.com/docs/upcoming/release-notes/4.4/#4.4.5---apr-8--2021">version 4.4.5</a>, released Apr 8, 2021) to the VM we deployed in the above section and configure the database so that it is ready to store data from our web app (Rocket.Chat).</p>
<p>The official documentation for MongoDB v4.4 is <a href="https://www.mongodb.com/docs/v4.4/tutorial/install-mongodb-on-ubuntu/">available here</a>.</p>
<h4 id="install-mongodb">Install MongoDB</h4>
<p>First, update the package list on the VM:</p>
<pre tabindex="0"><code>sudo apt-get update
</code></pre><p>Install <code>gnupg</code> and <code>curl</code>:</p>
<pre tabindex="0"><code>sudo apt-get install gnupg curl
</code></pre><p>Import the MongoDB public GPG key. This is required so we can access the software repository for v4.4:</p>
<pre tabindex="0"><code>curl -fsSL https://pgp.mongodb.com/server-4.4.asc | \
   sudo gpg -o /usr/share/keyrings/mongodb-server-4.4.gpg \
   --dearmor
</code></pre><p>Create the list file for Ubuntu 16.04:</p>
<pre tabindex="0"><code>echo &#34;deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-4.4.gpg ] https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.4 multiverse&#34; | sudo tee /etc/apt/sources.list.d/mongodb-org-4.4.list
</code></pre><p>Update the package database again. This time you will see it fetch data from <code>repo.mongodb.org</code>:</p>
<pre tabindex="0"><code>sudo apt-get update
</code></pre><p>Install MongoDB 4.4.5:</p>
<pre tabindex="0"><code>sudo apt-get install -y mongodb-org=4.4.5 mongodb-org-server=4.4.5 mongodb-org-shell=4.4.5 mongodb-org-mongos=4.4.5 mongodb-org-tools=4.4.5
</code></pre><p>Start the MongoDB service and set it to start at boot:</p>
<pre tabindex="0"><code>sudo systemctl daemon-reload
</code></pre><pre tabindex="0"><code>sudo systemctl start mongod &amp;&amp; sudo systemctl enable mongod
</code></pre><p>Check that the MongoDB service is now running:</p>
<pre tabindex="0"><code>sudo systemctl status mongod
...
● mongod.service - MongoDB Database Server
   Loaded: loaded (/lib/systemd/system/mongod.service; disabled; vendor preset: enabled)
   Active: active (running) since Sun 2023-07-16 06:30:13 UTC; 9s ago
     Docs: https://docs.mongodb.org/manual
 Main PID: 13891 (mongod)
    Tasks: 33
   Memory: 60.0M
      CPU: 791ms
   CGroup: /system.slice/mongod.service
           └─13891 /usr/bin/mongod --config /etc/mongod.conf
</code></pre><p>MongoDB listens on port TCP 27017 for incoming requests. To check that the port is correctly bound:</p>
<pre tabindex="0"><code>netstat -ln
...
    Active Internet connections (only servers)
    Proto Recv-Q Send-Q Local Address           Foreign Address         State
    tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
&gt;&gt;  tcp        0      0 127.0.0.1:27017         0.0.0.0:*               LISTEN
    tcp6       0      0 :::22                   :::*                    LISTEN
    udp        0      0 0.0.0.0:68              0.0.0.0:*
</code></pre><p>From the above we can see that MongoDB is only listening on localhost, meaning that it won&rsquo;t be able to accept connections from other machines. To fix this, we need to configure MongoDB to accept connections from all network interfaces, not just localhost. Open the MongoDB configuration file in a text editor:</p>
<pre tabindex="0"><code>sudo nano /etc/mongod.conf
</code></pre><p>Look for the <code>net</code> section in the config file. Change the <code>bindIP</code> from <code>127.0.0.1</code> to <code>0.0.0.0</code> so that it reflects the below:</p>
<pre tabindex="0"><code>net:
  port: 27017
  bindIp: 0.0.0.0
</code></pre><p>Save your changes (CTRL+X, then <code>Y</code>), then restart the MongoDB service:</p>
<pre tabindex="0"><code>sudo systemctl restart mongod
</code></pre><p>Verify that MongoDB is now listening on <code>0.0.0.0:27017</code> instead of <code>127.0.0.1:27017</code>:</p>
<pre tabindex="0"><code>netstat -ln
...
    Active Internet connections (only servers)
    Proto Recv-Q Send-Q Local Address           Foreign Address         State
    tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
&gt;&gt;  tcp        0      0 0.0.0.0:27017           0.0.0.0:*               LISTEN
    tcp6       0      0 :::22                   :::*                    LISTEN
    udp        0      0 0.0.0.0:68              0.0.0.0:*
</code></pre><p>Start a MongoDB shell to check that everything is working:</p>
<pre tabindex="0"><code>mongo
...
MongoDB shell version v4.4.5
connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodb
Implicit session: session { &#34;id&#34; : UUID(&#34;62b53e34-9d3b-4ed1-83c6-0f10c5a1dc2d&#34;) }
MongoDB server version: 4.4.5
Welcome to the MongoDB shell.
For interactive help, type &#34;help&#34;.
For more comprehensive documentation, see
	https://docs.mongodb.com/
Questions? Try the MongoDB Developer Community Forums
	https://community.mongodb.com
&gt;
</code></pre><p>You can press CTRL+C to quit the shell.</p>
<h4 id="create-a-user-and-database-for-the-web-app-to-use">Create a user and database for the web app to use</h4>
<p>Next, we need to create a user and database in MongoDB that our web app can use. Access to MongoDB shell:</p>
<pre tabindex="0"><code>mongo
</code></pre><p>Create and switch to the database for the web app (<code>rocketchat</code>):</p>
<pre tabindex="0"><code>use rocketchat
</code></pre><p>Paste in the below making sure to substitute the password and database name as needed:</p>
<pre tabindex="0"><code>db.createUser({user: &#34;rocketchat&#34;, pwd: &#34;youwillneverguess&#34;, roles: [{role: &#34;readWrite&#34;, db: &#34;rocketchat&#34;}]})
</code></pre><p>This command will create a user named  <code>rocketchat</code> with the insecure password <code>youwillneverguess</code> and grant it <code>readWrite</code> permissions on the <code>rocketchat</code> database. You will need the username/password combo later on when we deploy the webapp.</p>
<p>Check that the user was created sucessfully:</p>
<pre tabindex="0"><code>db.getUser(&#34;rocketchat&#34;)
</code></pre><p>The output should be similar to the below. If you see <code>null</code>, ensure you are using the right database (ie: <code>use rocketchat</code>):</p>
<pre tabindex="0"><code>&gt; use rocketchat
switched to db rocketchat
&gt; db.getUser(&#34;rocketchat&#34;)
{
	&#34;_id&#34; : &#34;rocketchat.rocketchat&#34;,
	&#34;userId&#34; : UUID(&#34;0e6e3c22-60de-4507-af9c-782821507b30&#34;),
	&#34;user&#34; : &#34;rocketchat&#34;,
	&#34;db&#34; : &#34;rocketchat&#34;,
	&#34;roles&#34; : [
		{
			&#34;role&#34; : &#34;readWrite&#34;,
			&#34;db&#34; : &#34;rocketchat&#34;
		}
	],
	&#34;mechanisms&#34; : [
		&#34;SCRAM-SHA-1&#34;,
		&#34;SCRAM-SHA-256&#34;
	]
}
</code></pre><h3 id="14---configure-an-amazon-eks-cluster">1.4 - Configure an Amazon EKS Cluster</h3>
<p>Kubernetes is an open-source platform designed to automate deploying, scaling, and operating application containers. Kubernetes orchestration allows you to build application services that span multiple containers, schedule those containers across a cluster, scale those containers, and manage the health of those containers over time.</p>
<p>Amazon EKS (Elastic Kubernetes Service) is a managed service used to run Kubernetes on AWS.</p>
<p>In this project, we&rsquo;ll be using using EKS to manage the deployment and scaling of our containerized web application and the underlying EC2 host VMs (AKA &ldquo;Workers&rdquo;) that the containers will run on.</p>
<h4 id="create-an-iam-role-for-the-eks-cluster">Create an IAM Role for the EKS Cluster</h4>
<p>Because the Kubernetes cluster managed by EKS makes calls to other AWS services on our behalf (like EC2 to bring up a worker), we need to create a role that restricts <em>what</em> EKS can do. Letting it have free reign within our entire AWS account would be very bad.</p>
<p>Amazon has instructions on how to do this for EKS <a href="https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html#create-service-role">here</a>, or you can follow the instuctions below:</p>
<ol>
<li>
<p>Open the <a href="https://console.aws.amazon.com/iam/home?#roles">AWS IAM Console</a>.</p>
</li>
<li>
<p>From the left-side menu, under <strong>Access Management</strong>, select <strong>Roles</strong>. On the next screen, select <strong>Create role</strong>:</p>
</li>
</ol>
<p><img src="4.png" alt="4"></p>
<ol start="3">
<li>For <em>Trusted entity type</em> select <strong>AWS service</strong>.</li>
<li>For <em>Use case</em> select <strong>EKS</strong> from the dropdown list, then select <strong>EKS - Cluster</strong>. Click <strong>Next</strong>.</li>
</ol>
<p><img src="31.png" alt="31"></p>
<ol start="5">
<li>On the <em>Add permissions</em> screen, don&rsquo;t change anything, just click <strong>Next</strong> again.</li>
<li>On the next screen, set the role name as <code>eksClusterRole</code> and make sure that you see <code>AmazonEKSClusterPolicy</code> listed as a policy name under the <em>Add permissions</em> table. Click <strong>Create role</strong> when you are ready to finish configuration.</li>
</ol>
<p><img src="32.png" alt="32"></p>
<h4 id="create-an-iam-role-for-the-worker-node-group">Create an IAM Role for the Worker Node Group</h4>
<p>We need to create a separate role with different permissions that will be assigned to the worker nodes that the Kubernetes cluster will manage.</p>
<ol>
<li>As we did in the previous step, open the <a href="https://console.aws.amazon.com/iam/home?#roles">IAM console</a>, and under <strong>Access Management &gt; Roles</strong>, click <strong>Create role</strong>.</li>
<li>For <em>Trusted entity type</em> select <strong>AWS service</strong>.</li>
<li>For <em>Use case</em> select <strong>EC2</strong>. Click <strong>Next</strong>.</li>
<li>Select the following permissions, the click <strong>Next</strong>:
<ul>
<li>AmazonEKS_CNI_Policy</li>
<li>AmazonEKSWorkerNodePolicy</li>
<li>AmazonEC2ContainerRegistryReadOnly</li>
</ul>
</li>
<li>Set the role name as <strong>EKSWorkerNodePolicy</strong> and click <strong>Create role</strong> to finish the configuration.</li>
</ol>
<h4 id="create-a-new-kms-key">Create a new KMS Key</h4>
<p><a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes secrets</a> allow sensitive information like passwords, credentials, and API keys that need to be leveraged by underlying services to be stored centrally within the Kubernetes API data store (etcd), and not within the application source code or config itself.</p>
<p>By default, secrets are stored in the Kubernetes API are unencrypted. EKS supports secrets encryption using an encryption key stored in the AWS Key Management Service (KMS), and it is best practice to enable this. To do so however, we need to create a symetrical encryption key within KMS</p>
<ol>
<li>Go to the AWS KMS Console: <a href="https://console.aws.amazon.com/kms">https://console.aws.amazon.com/kms</a></li>
<li>Click <strong>Create key</strong>.</li>
<li>Select <strong>Symmetric</strong> as they <em>Key type</em>, and <strong>Encrypt and decrypt</strong> for the <em>Key usage</em> option. Click <strong>Next</strong>.</li>
<li>Give the key a name and description, eg: <code>EKS_Secrets_Key</code>, and click <strong>Next</strong>.</li>
<li>Leave all key administrators as blank and de-select the option to allow admins to delete the key. Click <strong>Next</strong>.</li>
<li>For the <em>Key usage permissions</em> step, select the <code>eksClusterRole</code> you created above. Click <strong>Next</strong>.</li>
<li>Click <strong>Finish</strong> on the summary page to create the key.</li>
</ol>
<h4 id="create-a-new-eks-cluster">Create a new EKS Cluster</h4>
<ol>
<li>Open the <a href="https://console.aws.amazon.com/eks">AWS EKS Console</a>.</li>
<li>From the <strong>Add cluster</strong> dropdown menu, select <strong>Create</strong>.</li>
</ol>
<p><img src="33.png" alt="33"></p>
<ol start="3">
<li>For <em>Name</em>, enter <code>testing-cluster</code>.</li>
<li>For <em>Kubernetes version</em>, select the highest version available (1.27 at the time of writing)</li>
<li>For <em>Cluster service role</em>, select the <code>eksClusterRole</code> you created earlier.</li>
</ol>
<p>​		<img src="9.png" alt="9"></p>
<ol start="6">
<li>Under <em>Secrets encryption</em>, check <strong>Turn on envelope encryption of Kubernetes secrets using KMS</strong> and select the <code>EKS_Secrets_Key</code> that you created earlier from the <em>KMS key</em> dropdown. Click <strong>Next</strong> to proceed.</li>
</ol>
<p>​		<img src="10.png" alt="10"></p>
<ol start="7">
<li>Under <em>Networking</em> select:
<ul>
<li>The VPC that cluster resources will be provisioned in.</li>
<li>The subnet(s) to be used by the cluster.</li>
<li>The security group(s) to apply to worker nodes.</li>
</ul>
</li>
<li>Under <em>Cluster endpoint access</em>, select <strong>Public and private</strong> and enter an IP address (or block of IPs) to permit connections to the public API endpoint from. Click <strong>Next</strong> to continue.</li>
<li>Choose which logs (if any) to send into CloudWatch. Note that CloudWatch usage attracts <a href="https://aws.amazon.com/cloudwatch/pricing/">additional costs</a>. Click <strong>Next</strong> to continue.</li>
<li>For add-ons, leave the default <em>CoreDNS</em>, <em>kube-proxy</em>, and <em>Amazon VPC CNI</em> options selected and click <strong>Next</strong>. On the next screen, select the latest versions for your add-ons, and click <strong>Next</strong>.
<ul>
<li><strong>CoreDNS</strong> provides DNS services within your cluster allowing containers to discover and connect to each other.</li>
<li><strong>kube-proxy</strong> runs on each node in the cluster and allows access to the services defined in a cluster.</li>
<li><strong>Amazon VPC CNI</strong> allows pods to have the same IP address inside the pod as they do on the VPC network.</li>
</ul>
</li>
<li>On the summary page, click <strong>Create</strong> to provision your cluster.</li>
</ol>
<p>Your cluster will take several minutes to create, so now is the perfect time to take a break!</p>
<p><img src="11.png" alt="11"></p>
<p>Once your cluster is created, take note of the API server endpoint and the OpenID Connect provider URL:</p>
<p><img src="12.png" alt="12"></p>
<h4 id="copy-the-cluster-config-to-kubectl">Copy the cluster config to <code>kubectl</code></h4>
<p><code>kubectl</code> will be out primary way of interacting with the cluster, so we need to provide it with configuration to be able to securely authenticate and connect to the Kubernetes API of our cluster.</p>
<p>First, verify that your cluster is active and that your AWS CLI is authenticated correctly:</p>
<pre tabindex="0"><code>aws eks --region &lt;your-region&gt; describe-cluster --name &lt;your-cluster-name&gt; --query cluster.status
</code></pre><p>For example:</p>
<pre tabindex="0"><code>aws eks --region ap-southeast-2 describe-cluster --name testing-cluster --query cluster.status
...
&#34;ACTIVE&#34;
</code></pre><p>Next, use the AWS CLI to get the the required config from our cluster and apply it to <code>kubectl</code>:</p>
<pre tabindex="0"><code>aws eks update-kubeconfig --name &lt;cluster-name&gt;
...
Eg: aws eks update-kubeconfig --name testing-cluster
Added new context arn:aws:eks:ap-southeast-2:6200[REDACTED]:cluster/testing-cluster to /Users/nathan/.kube/config
</code></pre><p>Lastly, test <code>kubectl</code> to verify that it has the correct config and can interact with the cluster:</p>
<pre tabindex="0"><code>kubectl get svc
...
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.100.0.1   &lt;none&gt;        443/TCP   107m
</code></pre><h4 id="create-a-new-node-group">Create a new node group</h4>
<p>In this step we will create the worker nodes that the master kubernetes node (deployed above) will orchestrate. A node group is simply a collection of worker nodes.</p>
<ol>
<li>From the <code>testing-cluster</code> details page, click the <strong>Compute</strong> tab, then under <em>Node groups</em>, click <strong>Add node group</strong>:</li>
</ol>
<p><img src="15.png" alt="15"></p>
<ol start="2">
<li>Set the node group <em>name</em> to <strong>node_group1</strong>.</li>
<li>For <em>Node IAM role</em>, select the <strong>EKSWorkerNodePolicy</strong> role created earlier, then click <strong>Next</strong>.</li>
</ol>
<p><img src="34.png" alt="34"></p>
<ol start="4">
<li>On the next screen, under <em>Node group compute configuration</em>, leave <strong>Amazon Linux 2</strong> selected, but change the <em>Instance type</em> to <code>t3.medium</code> .  This is the instance type of the worker nodes that the cluster will spin up/down as needed.
<ul>
<li>When picking an instance size, don&rsquo;t overly skimp out on compute here to save costs. Kubernetes is finicky with resources and going to small will result in failed pod deployments due to a lack of resources.</li>
</ul>
</li>
</ol>
<p><img src="35.png" alt="35"></p>
<ol start="4">
<li>
<p>Under <em>Node group scaling configuration</em>, leave the default values as 2/2/2. Click <strong>Next</strong>.</p>
</li>
<li>
<p>For <em>Node group network configuration</em>:</p>
<ul>
<li>Select the subnets that the worker nodes will be deployed in. Normally you should deploy worker nodes to a separate subnet to the master node/EKS cluster, but for this project, we will keep them the same.</li>
<li>Check the box <strong>Configure remote access to nodes</strong>. This is useful for troubleshooting, but does increase our attack surface a bit. When prompted, select the same EC2 key pair used for the MongoDB VM from before, and the same security group, <strong>mgmt-access</strong>. The latter will restrict remote access to only our own IP address.</li>
<li>Click <strong>Next</strong> to continue.</li>
</ul>
</li>
</ol>
<p><img src="36.png" alt="36"></p>
<ol start="6">
<li>When you have finished reviewing the configuration, click <strong>Create</strong> to finish. This will begin the process to create the worker node(s) according to our config (which may take several minutes).</li>
</ol>
<p><img src="37.png" alt="37"></p>
<p>To verify that the worker nodes are active, we can use <code>kubectl</code>:</p>
<pre tabindex="0"><code>kubectl get nodes --watch
...
NAME                                               STATUS   ROLES    AGE   VERSION
ip-172-31-36-247.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   19m   v1.27.1-eks-2f008fe
ip-172-31-7-192.ap-southeast-2.compute.internal    Ready    &lt;none&gt;   19m   v1.27.1-eks-2f008fe
</code></pre><p>Likewise, if you return to the details page of the EKS cluster and select the <em>Compute</em> tab, you will now see the node group and the provisioned worker nodes:</p>
<p><img src="38.png" alt="38"></p>
<h3 id="14---create-a-public-amazon-s3-bucket">1.4 - Create a Public Amazon S3 Bucket</h3>
<p>In this section we will be creating a new S3 bucket to hold scripted backups from MongoDB, but the bucket will be configured to allow for Public Read; creating a point where data can be breached and siphoned.</p>
<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
NEVER DO THIS IN PRODUCTION OR IN A REAL ENVIRONMENT!
</div>

<h4 id="create-a-new-public-bucket">Create a new public bucket</h4>
<p>Go to the <a href="https://console.aws.amazon.com/s3/">S3 Management Console</a> and select <strong>Create Bucket</strong>.</p>
<p><img src="16.png" alt="16"></p>
<p>Provide a name for the bucket (eg: <code>totallysecurebucket</code>), select the region (eg: <code>ap-southeast-2</code>), and ensure (under <em>Object Ownership</em>) that ACLs are disabled.</p>
<p><img src="17.png" alt="17"></p>
<p>Under the section <em>Block Public Access settings for this bucket</em>, de-select the <strong>Block all public access</strong> checkbox and check the acknowledgement checkbox that appears at the bottom. This will make the bucket completely public.</p>
<h4 id="add-a-bucket-policy">Add a bucket policy</h4>
<p>To make objects in the bucket publicly readable, we need to create and apply a policy to the bucket that grants everyone accessing it the <code>s3:GetObject</code> permission.</p>
<p>From the S3 Management Console, click the name of the bucket created above and select the <strong>Permissions</strong> tab. Scroll down and under the <em>Bucket Policy</em> section, click <strong>Edit</strong>.</p>
<p><img src="18.png" alt="18"></p>
<p>Paste in the following (overwriting all existing text) and substitute <code>&lt;your-bucket-name&gt;</code> with the name of your S3 bucket:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&#34;Version&#34;</span>: <span style="color:#e6db74">&#34;2012-10-17&#34;</span>,
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">&#34;Statement&#34;</span>: [
</span></span><span style="display:flex;"><span>		{
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">&#34;Sid&#34;</span>: <span style="color:#e6db74">&#34;PublicReadGetObject&#34;</span>,
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">&#34;Effect&#34;</span>: <span style="color:#e6db74">&#34;Allow&#34;</span>,
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">&#34;Principal&#34;</span>: <span style="color:#e6db74">&#34;*&#34;</span>,
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">&#34;Action&#34;</span>: [
</span></span><span style="display:flex;"><span>			    <span style="color:#e6db74">&#34;s3:GetObject&#34;</span>
</span></span><span style="display:flex;"><span>			    ],
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">&#34;Resource&#34;</span>: <span style="color:#e6db74">&#34;arn:aws:s3:::&lt;your-bucket-name&gt;/*&#34;</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Click <strong>Save changes</strong> to finish.</p>
<p><img src="19.png" alt="19"></p>
<p>Your bucket will now have an orange <code>Publicly accessible</code> warning underneath it&rsquo;s name, and under the <strong>Permissions</strong> tab in the <em>Permissions overview</em> section, <em>Access</em> should now say <em>Public</em>.</p>
<p><img src="20.png" alt="20"></p>
<h3 id="15---deploy-a-public-web-app-rocketchat">1.5 - Deploy a Public Web App (Rocket.Chat)</h3>
<p>The moment of truth is finally here: We can now use everything we have done so far to deploy the Rocket.Chat web app to our Kubernetes cluster! Rocket.Chat will sit behind nginx which will handle TLS for all connections between users and the web app.</p>
<h4 id="about-ingresses-ingress-controllers-and-load-balancers">About Ingresses, Ingress Controllers, and Load Balancers</h4>
<p>In Kubernetes, an <strong>Ingress object</strong> is a set of rules to route external HTTP(S) traffic to internal services within the cluster. These rules can include things like &ldquo;send all traffic for <code>myapp.mydomain.com</code> to the <code>my-app</code> service running in k8s&rdquo;. In our context, we will have an ingress that routes <code>chat.domain.com</code> to our Rocket.Chat service so that external users can reach the UI.</p>
<p>An Ingress Controller is effectively the &ldquo;router&rdquo; that enforces and implements any routes (Ingresses) defined. It is essentially a type of load balancer that can interpret the Ingress rules. Ingress rules are essentially useless without an Ingress Controller to enforce them. In our context, we will be leveraging Nginx as the Ingress Controller.</p>
<p>To allow the outside world to reach our Nginx Ingress Controller, we will be creating a &ldquo;LoadBalancer&rdquo; service in Kubernetes. As our cluster is running in AWS, this results in an AWS Elastic Load Balancer (ELB) instance being created and used. The ELB distributes incoming application traffic across multiple targets, such as EC2 instances, and in this case, the NGINX Ingress Controller.</p>
<p>In summary and in relation to this exercise, the flow of our services will be:</p>
<pre tabindex="0"><code>External Traffic -&gt; AWS ELB -&gt; NGINX Ingress Controller (applies Ingress rules) -&gt; Internal Kubernetes services (Rocket.Chat)
</code></pre><h4 id="kubectl-common-commands-and-shortcuts"><code>kubectl</code>: Common commands and shortcuts</h4>
<p>This section will make heavy use of <code>kubectl</code> on our local machine. The following commands will come in handy.</p>
<p>Get all pods running in the default namespace, specific namespace, and across all namespaces:</p>
<pre tabindex="0"><code>kubectl get pods
kubectl get pods -n &lt;namespace&gt;
kubectl get pods --all-namespaces
</code></pre><p>If we run the last command, we should see pods relating to the add-ons we selected when we created our EKS cluster:</p>
<pre tabindex="0"><code>nathan@arcanum ~ % kubectl get pods --all-namespaces
NAMESPACE       NAME                                                    READY   STATUS    AGE
kube-system     aws-node-bp2c4                                          1/1     Running   6d17h
kube-system     aws-node-khrfq                                          1/1     Running   6d17h
kube-system     coredns-866c7d785-dwmlg                                 1/1     Running   6d17h
kube-system     coredns-866c7d785-wrwsj                                 1/1     Running   6d17h
kube-system     kube-proxy-cktrg                                        1/1     Running   6d17h
kube-system     kube-proxy-pnlqd                                        1/1     Running   6d17h
</code></pre><p>Show all worker nodes running:</p>
<pre tabindex="0"><code>kubectl get nodes
...
NAME                                               STATUS   ROLES    AGE
ip-172-31-10-103.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   6d17h
ip-172-31-38-215.ap-southeast-2.compute.internal   Ready    &lt;none&gt;   6d17h
</code></pre><p>Get logs for a specific pod (or previous instance of a pod) in a specific namespace:</p>
<pre tabindex="0"><code>kubectl logs -n &lt;namespace&gt; &lt;pod-name&gt; --previous
</code></pre><p>Provide details information about a specific pod in a specific namespace:</p>
<pre tabindex="0"><code>kubectl describe pod rocketchat-866fdd489-nwwzq --namespace rocket
</code></pre><p>Retrieve the details of the specified service in a specific namespace, and output the details in YAML.</p>
<pre tabindex="0"><code>kubectl get svc -n &lt;namespace&gt; &lt;servicename&gt; -o yaml
</code></pre><p>Create or update resources (ie: pods, services, etc) in a cluster as defined by the contents of the YAML file referenced:</p>
<pre tabindex="0"><code>kubectl apply -f &lt;deployment-name&gt;.yaml
</code></pre><p>Remove all resources in the cluster as defined by the contents of the YAML file referenced:</p>
<pre tabindex="0"><code>kubectl delete -f &lt;deployment-name&gt;.yaml
</code></pre><p>List all services in the specified namespace:</p>
<pre tabindex="0"><code>kubectl get svc -n &lt;namespace&gt;
</code></pre><p>Provide detailed information about a certificate object in a specific namespace:</p>
<pre tabindex="0"><code>kubectl describe certificate rocket-tls --namespace rocket
</code></pre><h4 id="install-helm-and-add-repositories">Install Helm and Add Repositories</h4>
<p>Helm is a package manager for Kubernetes. Helm Charts can be published to Helm and describe how a package should be deployed. Helm is installed on the <strong>local machine</strong> from which you are running <code>kubectl</code> commands from.</p>
<p>Install Helm (macOS):</p>
<pre tabindex="0"><code>brew install helm
</code></pre><p>Add the Rocket.Chat Helm Chart:</p>
<pre tabindex="0"><code>helm repo add rocketchat https://rocketchat.github.io/helm-charts
</code></pre><p>Update the Helm repository:</p>
<pre tabindex="0"><code>helm repo update
</code></pre><h4 id="install-the-nginx-ingress-controller">Install the Nginx Ingress Controller</h4>
<p>Nginx will front-end the Rocket.Chat service and secure the connectivity between the user and app with TLS.</p>
<p>Add the ingress-nginx Helm repo:</p>
<pre tabindex="0"><code>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx &amp;&amp; helm repo update
</code></pre><p>Install the Nginx Ingress Controller and set the service type to be a LoadBalancer. This will automatically create a new LoadBalancer in our AWS environment. As per the recommended configuration, the Ingress Controller will also be installed in it&rsquo;s own namespace:</p>
<pre tabindex="0"><code>helm install nginx-ingress ingress-nginx/ingress-nginx --set controller.service.type=LoadBalancer --namespace ingress-nginx --create-namespace
</code></pre><p>Run the following command and note down the external IP/hostname assigned to the ELB LoadBalancer under the <strong>EXTERNAL-IP</strong> column:</p>
<pre tabindex="0"><code>kubectl get svc -n ingress-nginx
...
NAME                                       TYPE           CLUSTER-IP       EXTERNAL-IP
nginx-ingress-nginx-controller             LoadBalancer   10.100.190.179   a51aca6bf603b441597c74851e09f1ef-206136540.ap-southeast-2.elb.amazonaws.com

nginx-ingress-nginx-controller-admission   ClusterIP      10.100.89.137    &lt;none&gt;
</code></pre><p>For example, in my case above the external hostname assigned to my LoadBalancer by ELB is:</p>
<pre tabindex="0"><code>a51aca6bf603b441597c74851e09f1ef-206136540.ap-southeast-2.elb.amazonaws.com
</code></pre><p>You will need this in the next step.</p>
<h4 id="configure-external-dns">Configure External DNS</h4>
<p>Next, we need to add a CNAME record for the domain/subdomain we wish to make the Rocket.Chat web app accessible at, eg: <code>chat.domain.com</code>. This record must point <code>chat.domain.com</code> to the ELB external hostname obtained above.</p>
<p>Note that you don&rsquo;t have to use <code>chat</code> as the subdomain. Use whatever you like as long as you own the domain and have access to the external DNS records for it.</p>
<p>In my case, I will be using the sub-domain <code>chat.lightwave.cloud</code>, so I would add a CNAME record to my <code>lightwave.cloud</code> domain&rsquo;s DNS that points <code>chat</code> to <code>a51aca6bf603b441597c74851e09f1ef-206136540.ap-southeast-2.elb.amazonaws.com</code>:</p>
<p><img src="21.png" alt="21"></p>
<p>You can check whether your record was added correctly by using <code>nslookup</code>:</p>
<pre tabindex="0"><code>nslookup chat.lightwave.cloud
...
Server:		10.0.100.20
Address:	10.0.100.20#53

Non-authoritative answer:
chat.lightwave.cloud	canonical name = a51aca6bf603b441597c74851e09f1ef-206136540.ap-southeast-2.elb.amazonaws.com.
Name:	a51aca6bf603b441597c74851e09f1ef-206136540.ap-southeast-2.elb.amazonaws.com
Address: 52.63.128.2
Name:	a51aca6bf603b441597c74851e09f1ef-206136540.ap-southeast-2.elb.amazonaws.com
Address: 13.54.214.128
</code></pre><p>You should see both your selected name and the ELB hostname present. DNS records can take some time to propagate (as long as 48 hours depending on configuration), so this might not resolve straight away.</p>
<h4 id="install-cert-manager">Install Cert-Manager</h4>
<p>Cert-Manager is a native Kubernetes certificate management controller which can help issue and manage SSL/TLS certificates from a variety of sources, such as Let&rsquo;s Encrypt, HashiCorp Vault, or Venafi. In our case, cert-manager will manage the SSL certificate for our Ingress controller (Nginx); allowing it to serve content securely over HTTPS.</p>
<p>Add the cert-manager Helm repository:</p>
<pre tabindex="0"><code>helm repo add jetstack https://charts.jetstack.io &amp;&amp; helm repo update
</code></pre><p>Install the cert-manager Helm chart into its own namespace:</p>
<pre tabindex="0"><code>helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --version v1.6.0 --set installCRDs=true
</code></pre><p>Check that cert-manager was installed correctly:</p>
<pre tabindex="0"><code>kubectl get pods --namespace cert-manager
...
NAME                                       READY   STATUS    RESTARTS   AGE
cert-manager-5fd7f4c668-8jsj5              1/1     Running   0          54s
cert-manager-cainjector-6548d8c645-t8nd5   1/1     Running   0          54s
cert-manager-webhook-6c8c98cc6-vmgpt       1/1     Running   0          54s
</code></pre><p>Next, we need to create configuration for cert-manager that tells it to use Let&rsquo;s Encrypt to issue certificates.</p>
<p>To do this, we will create and apply an <strong>Issuer</strong> configuration to cert-manager which Kubernetes uses to abstract certficate issuing details. Note that an <strong>Issuer</strong> is local to a specified namespace, whereas a <strong>ClusterIssuer</strong> works across all namespaces. In this case, because we only have the one app, we will use a standard <strong>Issuer</strong>.</p>
<p>Create a new yaml file:</p>
<pre tabindex="0"><code>nano issuer.yaml
</code></pre><p>Paste in the following; making sure to substitute <code>your-email@example.com</code> with your own email address:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">cert-manager.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Issuer</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">letsencrypt-prod</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">rocket</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">acme</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># The ACME server URL</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">server</span>: <span style="color:#ae81ff">https://acme-v02.api.letsencrypt.org/directory</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Email address used for ACME registration</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">email</span>: <span style="color:#ae81ff">your-email@example.com</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Name of a secret used to store the ACME account private key</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">privateKeySecretRef</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">letsencrypt-prod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Enable the HTTP-01 challenge provider</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">solvers</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">http01</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ingress</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">class</span>: <span style="color:#ae81ff">nginx</span>
</span></span></code></pre></div><p>Save the file (CTRL+X, then <code>Y</code>), then apply it with <code>kubectl</code>:</p>
<pre tabindex="0"><code>kubectl apply -f issuer.yaml --namespace rocket
</code></pre><h4 id="create-an-ingress">Create an Ingress</h4>
<p>The next step is to create an Ingress resource that references our web app (ie: Rocket.Chat). It will also use the Issuer we just created to handle the TLS certificate issuance.</p>
<p>Create a new yaml file called <code>rocket-ingress.yaml</code>:</p>
<pre tabindex="0"><code>nano rocket-ingress.yaml
</code></pre><p>Paste in the following ensuring that you substitute both instances of <code>chat.domain.com</code> with your actual domain/sub-domain:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocket-ingress</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">rocket</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">annotations</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">kubernetes.io/ingress.class</span>: <span style="color:#e6db74">&#34;nginx&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">cert-manager.io/issuer</span>: <span style="color:#e6db74">&#34;letsencrypt-prod&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">host</span>: <span style="color:#ae81ff">chat.domain.com</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">http</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">path</span>: <span style="color:#e6db74">&#34;/&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">backend</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">service</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">port</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">number</span>: <span style="color:#ae81ff">3000</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">tls</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">hosts</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#ae81ff">chat.domain.com</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">secretName</span>: <span style="color:#ae81ff">rocket-tls</span>
</span></span></code></pre></div><p>This file (when applied) creates an Ingress that routes incoming traffic to our Rocket.Chat service on port 3000 (Rocket.Chat is configured to listen on port 3000 for incoming connections by default).</p>
<p>Note that the configuration also includes a <code>tls</code> block that specifies a <code>secretName</code>. This secret, <code>rocket-tls</code>, is where cert-manager will store the issued certificate. The  certificate will be automatically renewed by cert-manager as long as the Ingress exists.</p>
<p>Apply the Ingress:</p>
<pre tabindex="0"><code>kubectl apply -f rocketchat-ingress.yaml
</code></pre><p>Cert-manager will see this new Ingress resource, and because it has the <code>cert-manager.io/issuer: &quot;letsencrypt-prod&quot;</code> annotation, cert-manager will reach out to Let&rsquo;s Encrypt and request a certificate for <code>chat.domain.com</code>. This certificate is then stored in the secret named <code>rocket-tls</code> in the <code>rocket</code> namespace. To review and check the status of the issued certificate, run the command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe certificate rocket-tls --namespace rocket
</span></span></code></pre></div><p>Note that the certificate may not be ready straight away. When it is, the status message will indicate <code>Certificate is up to date and has not expired</code>.</p>
<h4 id="deploy-the-web-app">Deploy the Web App</h4>
<p>For our last step, we need to actually deploy the Rocket.Chat web app. To ensure high-availability, we will deploy it using both <strong>Deployment</strong> and <strong>Service</strong> capabilities in Kubernetes.</p>
<p>A <strong>Deployment</strong> in Kubernetes is an object that orchestrates the creation and management of Pod instances. A Deployment describes the desired state for Pods, such as the Docker image to use, the number of Pod replicas you want running, and other configuration details. Deployments use a template to create the necessary Pods and keep track of their status. If a Pod goes down, the Deployment will automatically create a new one to keep the desired number of replicas.</p>
<p>A <strong>Service</strong> in Kubernetes is an abstraction which defines a logical set of Pods (typically operated by a Deployment) and a policy by which to access them (sometimes called a micro-service). Services enable communication between different parts of an application, or between different applications entirely, both inside and outside of the cluster. They can also provide discovery and load balancing features for micro-services.</p>
<p>Create a new yaml file called <code>rocketchat-deployment.yaml</code>:</p>
<pre tabindex="0"><code>nano rocketchat-deployment.yaml
</code></pre><p>Paste in the below content, ensuring that you substitute in the following values:</p>
<ol>
<li><code>&lt;mongodb-username&gt;</code> and <code>&lt;mongodb-password&gt;</code> with the username and password of the user you created in MongoDB in the <code>rocketchat</code> database.</li>
<li><code>&lt;mongodb-ip&gt;</code> with the IP address of the VM that the MongoDB deployment is running on.</li>
<li><code>chat.domain.com</code> with the domain you have been using to make Rocket.Chat accessible on.</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">rocket</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">rocket.chat:latest</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">MONGO_URL</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">mongodb://&lt;mongodb-username&gt;:&lt;mongodb-password&gt;@&lt;mongodb-ip&gt;:27017/rocketchat</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ROOT_URL</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">https://chat.domain.com</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">PORT</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;3000&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">3000</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">rocket</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">3000</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">3000</span>
</span></span></code></pre></div><p>Save the file (CTRL+X, then <code>Y</code>) and apply it to deploy Rocket.Chat:</p>
<pre tabindex="0"><code>kubectl apply -f rocketchat-deployment.yaml
</code></pre><p>Verify that the Rocket.Chat pod(s) are running:</p>
<pre tabindex="0"><code>kubectl get pods -n rocket
...
NAME                         READY   STATUS    RESTARTS   AGE
rocketchat-866fdd489-4j7zn   1/1     Running   0          48s
</code></pre><p>Optionally, review the details of the Rocket.Chat service:</p>
<pre tabindex="0"><code>kubectl describe service rocketchat -n rocket
</code></pre><h4 id="validate-that-the-web-app-is-live">Validate that the Web App is live</h4>
<p>We should not be able to go to visit our domain (<code>chat.domain.com</code>) in a browser to check that the web app is live. If everything is OK, then the Rocket.Chat UI should load and be secured with an SSL certificate issued from Let&rsquo;s Encrypt:</p>
<p><img src="22.png" alt="22"></p>
<hr>
<h2 id="20---weakening-security">2.0 - Weakening Security</h2>
<p>In this section we will further weaken the security of our deployment by opening up permissions on our containers and VMs, storing secrets insecurely on a container volume, and configuring MongoDB to backup to the public S3 bucket.</p>
<h3 id="21---configure-containers-as-cluster-admin">2.1 - Configure containers as cluster-admin</h3>
<p>In Kubernetes, permissions are set through Role-Based Access Control (RBAC). We are going to set apply cluster-admin privileges to Rocket.Chat, which will allow it to perform any action against the Kubernetes API - including viewing secrets and modifying permissions.</p>
<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
NEVER DO THIS IN PRODUCTION OR IN A REAL ENVIRONMENT!
</div>

<p>First, we need to create a new <strong>ClusterRoleBinding</strong>. A ClusterRoleBinding is an object that assigns a <strong>ClusterRole</strong> (essentially permissions at a cluster level) to a specified <strong>service account</strong>. A <strong>service account</strong> is a special kind of account that is intended to be used by a program running inside a Pod. Each Service Account is tied to a specific namespace, and it is automatically given an associated secret. This secret can be used to interact with the Kubernetes API.</p>
<p>In short: There is a service account that is already used by our Rocket.Chat app, so we need to elevate it&rsquo;s permissions to cluster-admin through the use of a ClusterRoleBinding.</p>
<h4 id="create-and-apply-a-new-clusterrolebinding">Create and apply a new ClusterRoleBinding</h4>
<p>To create a new ClusterRoleBinding (<code>rocket-admin</code>) and assign it to the approproate service account (<code>default</code>) in our <code>rocket</code> namespace:</p>
<pre tabindex="0"><code>kubectl create clusterrolebinding rocket-admin --clusterrole=cluster-admin --serviceaccount=rocket:default
</code></pre><p>If you aren&rsquo;t sure of which service account to use:</p>
<pre tabindex="0"><code>kubectl get serviceaccounts -n &lt;namespace&gt;
</code></pre><p>To specifically see which service account is used by the Rocket.Chat deployment:</p>
<pre tabindex="0"><code>kubectl describe deployment &lt;deployment-name&gt; -n &lt;namespace&gt;
</code></pre><p>To find the deployment name:</p>
<pre tabindex="0"><code>kubectl get deployment -n &lt;namespace&gt;
</code></pre><p>To see which service account is being used by a specific pod:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl describe pod &lt;pod-name&gt; -n rocket
</span></span></code></pre></div><h4 id="validate-the-clusterrolebinding">Validate the ClusterRoleBinding</h4>
<p>To verify that the ClusterRoleBinding was created and applied successfully, run the following command and look for the name you gave to your ClusterRoleBinding:</p>
<pre tabindex="0"><code>kubectl get clusterrolebindings
...
NAME                    ROLE                             AGE
[..snip..]
rocket-admin            ClusterRole/cluster-admin        1m34s
[..snip..]
</code></pre><p>Double check that the ClusterRoleBinding <code>rocket-admin</code> now has the <code>default</code> service account and <code>rocket</code> namespace as its subject:</p>
<pre tabindex="0"><code>kubectl describe clusterrolebinding rocket-admin
...
Name:         rocket-admin
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;
Role:
  Kind:  ClusterRole
  Name:  cluster-admin
Subjects:
  Kind            Name     Namespace
  ----            ----     ---------
  ServiceAccount  default  rocket
</code></pre><h3 id="22---set-the-mongodb-vm-to-have-elevated-privileges">2.2 - Set the MongoDB VM to have elevated privileges</h3>
<p>AWS uses a service called Identity and Access Management (IAM) to handle access control. An IAM role is an identity that can be assigned permissions and then attached to resources (like EC2 instances) so that these resources can take actions in AWS on your behalf.</p>
<p>In this section we will create a new IAM role with policy <code>ec2:*</code> which allows any action to be taken on any EC2 resource by anything assigned with this role (which is incredibly dangerous!). We will also assign <code>PutObject</code> and <code>GetObject</code> permissions towards our Public S3 bucket so that we can configure MongoDB to backup to the bucket (see section 2.4 further below).</p>
<h4 id="create-the-policy">Create the policy</h4>
<p>Open the AWS <a href="http://console.aws.amazon.com/iam/">IAM Console</a>, select <strong>Policies</strong> from the left sidebar, and click the <strong>Create policy</strong> button.</p>
<p>Click <strong>JSON</strong> and paste the following into the policy editor:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;Version&#34;</span>: <span style="color:#e6db74">&#34;2012-10-17&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;Statement&#34;</span>: [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Effect&#34;</span>: <span style="color:#e6db74">&#34;Allow&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Action&#34;</span>: <span style="color:#e6db74">&#34;ec2:*&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Resource&#34;</span>: <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Effect&#34;</span>: <span style="color:#e6db74">&#34;Allow&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Action&#34;</span>: [
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;s3:PutObject&#34;</span>,
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;s3:GetObject&#34;</span>
</span></span><span style="display:flex;"><span>            ],
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;Resource&#34;</span>: <span style="color:#e6db74">&#34;arn:aws:s3:::your-bucket-name/*&#34;</span>
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><img src="25.png" alt="25"></p>
<p>Click the <strong>Review policy</strong> button to continue.</p>
<p>On the next screen, name your policy <code>EC2FullAccess</code> and provide it with a meaningful description. Eg: <code>A very bad role that grants a resource full control of EC2 resources. For testing/demo purposes only.</code></p>
<p>Both <strong>EC2</strong> and <strong>S3</strong> should be referenced as services defined in the policy. AWS will have derived these up from the JSON entered above:</p>
<ul>
<li>For <strong>EC2</strong> ensure that the access level is <strong>Full access</strong>, and the resource is <strong>All resources</strong>.</li>
<li>For <strong>S3</strong> ensure that the access level is <strong>Limited: Read, Write</strong>, and the resource references your bucket name.</li>
</ul>
<p><img src="26.png" alt="26"></p>
<p>Once you are satisfied, click the <strong>Create policy button</strong>.</p>
<h4 id="create-the-role">Create the role</h4>
<p>From the IAM Console, this time select <strong>Roles</strong> in the left sidebar, then click the <strong>Create role</strong> button.</p>
<p>For <strong>Step 1 - Select trusted entity</strong>, ensure that <strong>AWS service</strong> is selected as the entity type, and <strong>EC2</strong> is selected as the use case.</p>
<p><img src="23.png" alt="23"></p>
<p>Click next to continue.</p>
<p>On the next screen (<em>Step 2 - Add permissions</em>), select the <strong>EC2FullAccess</strong> policy you created (you may need to search for it).</p>
<p><img src="24.png" alt="24"></p>
<p>Click next to continue.</p>
<p>On the final screen, name the role <strong>EC2FullAccessRole</strong>, optionally provide a description, then click the <strong>Create role</strong> button.</p>
<p><img src="27.png" alt="27"></p>
<h4 id="attach-the-role-to-the-vm">Attach the role to the VM</h4>
<p>In the EC2 Console, select the VM that you deployed MongoDB to. Click on the <strong>Actions</strong> button and navigate to <strong>Security &gt; Modify IAM role</strong>:</p>
<p><img src="28.png" alt="28"></p>
<p>In the <strong>IAM role</strong> dropdown, find and select the <strong>EC2FullAccessRole</strong> role that was created above. Click <strong>Update IAM role</strong> to save your changes.</p>
<p><img src="29.png" alt="29"></p>
<h3 id="23---store-a-set-of-credentials-insecurely">2.3 - Store a set of credentials insecurely</h3>
<p>Kubernetes Secrets exists as a means to securely communicate sensitive values (ie: passwords, API keys, private keys, etc) to pods; preventing the need to store these in ENV variables or config files within the container. To further increase the vulnerability of our deployment, we will do the latter and use a <strong>ConfigMap</strong> to store our MongoDB connection string. This ConfigMap will then be mounted to our Rocket.Chat container as a volume.</p>
<h4 id="create-a-configmap">Create a ConfigMap</h4>
<p>A <strong>ConfigMap</strong> allows configuration to be decoupled from image content, which helps keep containers portable. ConfigMaps are not secure however as they don&rsquo;t provide confidentiality or encryption.</p>
<p>Using the MongoDB connection string from earlier, run the following command to create a ConfigMap called <code>mongo-config</code>; making sure to substitute your own values in the string below:</p>
<pre tabindex="0"><code>kubectl create configmap mongodb-config --from-literal=connectionstring=&#39;mongodb://&lt;username&gt;:&lt;password&gt;@&lt;mongodb-ip&gt;:27017/rocketchat&#39; -n rocket
</code></pre><p>Note that the ConfigMap must be created in the same namespace as the Rocket.Chat pod, else it won&rsquo;t be able to see the ConfigMap and mounting the volume will fail.</p>
<h4 id="mount-the-configmap-as-a-volume">Mount the ConfigMap as a Volume</h4>
<p>Next, update your rocketchat-deployment.yaml file to include the ConfigMap as a volume and mount it to the container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">rocket</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">matchLabels</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">labels</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">containers</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">rocket.chat:latest</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">env</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">MONGO_URL</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">mongodb://rocketchat:kyCJeC48ebK8i2ok@172.31.15.204:27017/rocketchat</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">ROOT_URL</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#ae81ff">https://chat.lightwave.cloud</span>
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">PORT</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">value</span>: <span style="color:#e6db74">&#34;3000&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">3000</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">volumeMounts</span>:
</span></span><span style="display:flex;"><span>        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mongodb-config-volume</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/etc/credentials</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mongodb-config-volume</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">configMap</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mongodb-config</span>
</span></span><span style="display:flex;"><span>---
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">rocket</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">selector</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rocketchat</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">port</span>: <span style="color:#ae81ff">3000</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">3000</span>
</span></span></code></pre></div><p>Note the new <code>volumeMounts</code> and <code>volumes</code> sections. This will create a file at <code>/etc/credentials/connectionstring</code> with the contents being the full MongoDB connection string.</p>
<p>Apply the new configuration to the running pod:</p>
<pre tabindex="0"><code>kubectl apply -f rocketchat-deployment.yaml
</code></pre><p>Kubernetes will notice that the deployment configuration has changed, and it will start a rolling update. It will gradually take down the old pod and bring up a new pod with the updated configuration (resulting in a minimal disruption to service).</p>
<p>If <code>kubectl</code> responds to say that the yaml file is unchanged, you can force Kubernetes to replace the current deployment. Just note that this will cause disruption as old pods are deleted <em>first</em> before new ones are created.</p>
<pre tabindex="0"><code>kubectl replace --force -f rocketchat-deployment.yaml
</code></pre><h4 id="verify-the-credentials-are-visible-in-the-pod">Verify the credentials are visible in the pod</h4>
<p>To validate that ConfigMap and Volume are mounted correctly, we can connect to the pod and verify the file contents.</p>
<p>Find the name of the pod running:</p>
<pre tabindex="0"><code>kubectl get pods -n rocket
...
NAME                         READY   STATUS    RESTARTS   AGE
rocketchat-5878f57494-rcn9c  1/1     Running   0          6d22h
</code></pre><p>Connect to the container and start a bash session:</p>
<pre tabindex="0"><code>kubectl exec -it rocketchat-5878f57494-rcn9c -n rocket -- /bin/bash
</code></pre><p>View the contents of the <code>connectionstring</code> file and verify that it matches what you entered when defining the ConfigMap:</p>
<pre tabindex="0"><code>cat /etc/credentials/connectionstring
...
mongodb://rocketchat:youwillneverguess@172.31.15.204:27017/rocketchat
</code></pre><h3 id="24---configure-mongodb-to-backup-to-the-public-s3-bucket">2.4 - Configure MongoDB to Backup to the Public S3 Bucket</h3>
<p>We will now configure MongoDB to automatically backup to the S3 bucket we created at the start of this document (the one with public read access). The VM has already been configured with permissions to read and write to the bucket as part of the policy and role we assigned to it in Section 2.2. All that is left to do is create a script and cronjob to manage the backup. <code>mongodump</code> will be used to create the backups and this was automatically installed on the system alongside MongoDB.</p>
<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
Storing backups in a public bucket is a really dumb and stupid idea. <strong>Never do this!</strong>
</div>

<h4 id="install-aws-cli">Install AWS CLI</h4>
<p>Our backup script will leverage the AWS CLI to perform the upload to the S3 bucket, so it needs to be installed on the VM.</p>
<p>Connect to the MongoDB VM using your SSH keypair:</p>
<pre tabindex="0"><code>ssh ubuntu@&lt;your-vm-public-ip&gt;
</code></pre><p>Install AWS CLI:</p>
<pre tabindex="0"><code>sudo apt install awscli -y
</code></pre><h4 id="create-the-backup-script">Create the Backup Script</h4>
<p>Create a folder to store the backups:</p>
<pre tabindex="0"><code>mkdir $HOME/backups
</code></pre><p>Create a new script file called <code>backup_mongodb.sh</code>:</p>
<pre tabindex="0"><code>nano backup_mongodb.sh
</code></pre><p>Paste in the following, replacing <code>your-bucket-name</code> with the name of your target S3 bucket:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># specify date for backup</span>
</span></span><span style="display:flex;"><span>DATE<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>date +%Y%m%d%H%M<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># specify where backup will be stored locally</span>
</span></span><span style="display:flex;"><span>BACKUP_DIR<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span>$HOME<span style="color:#e6db74">/backups&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># specify your S3 bucket</span>
</span></span><span style="display:flex;"><span>S3_BUCKET<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;your-bucket-name&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create backup with mongodump</span>
</span></span><span style="display:flex;"><span>mongodump --out $BACKUP_DIR/mongodb-$DATE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create tarball of the backup</span>
</span></span><span style="display:flex;"><span>tar -zcvf $BACKUP_DIR/mongodb-$DATE.tar.gz $BACKUP_DIR/mongodb-$DATE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># remove the backup directory</span>
</span></span><span style="display:flex;"><span>rm -rf $BACKUP_DIR/mongodb-$DATE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># upload tarball to S3</span>
</span></span><span style="display:flex;"><span>aws s3 cp $BACKUP_DIR/mongodb-$DATE.tar.gz s3://$S3_BUCKET/
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># remove the local tarball</span>
</span></span><span style="display:flex;"><span>rm $BACKUP_DIR/mongodb-$DATE.tar.gz
</span></span></code></pre></div><p>Save and close the file (CTRL+X, then <code>Y</code>)</p>
<p>The script uses <code>mongodump</code> to create a backup of the MongoDB database. It then compresses the backup into a tarball with <code>tar -zcvf</code>, removes the uncompressed backup directory with <code>rm -rf</code>, uploads the tarball to your S3 bucket with <code>aws s3 cp</code>, and then removes the local tarball.</p>
<p>Because the VM was given an IAM role that included S3 read/write access to the bucket, there is no need to configure the AWS CLI or provide credentials: The AWS SDK and AWS CLI tools will automatically use the attached IAM role to get temporary credentials. AWS then automatically rotates these credentials multiple times per day to ensure on-going security.</p>
<h4 id="test-the-backup-script">Test the Backup Script</h4>
<p>Ensure that the script is executable:</p>
<pre tabindex="0"><code class="language-chmod" data-lang="chmod">chmod +x backup_mongodb.sh
</code></pre><p>Run the script and check the S3 bucket from the <a href="console.aws.amazon.com/s3/">S3 console</a> to make sure that the backup was successfully uploaded:</p>
<pre tabindex="0"><code>./backup_mongodb.sh
...
2023-07-24T07:34:15.438+0000	writing admin.system.users to /home/ubuntu/backups/mongodb-202307240734/admin/system.users.bson
2023-07-24T07:34:15.439+0000	done dumping admin.system.users (1 document)
2023-07-24T07:34:15.440+0000	writing admin.system.version to /home/ubuntu/backups/mongodb-202307240734/admin/system.version.bson
[..snip..]
upload: backups/mongodb-202307240734.tar.gz to s3://your-bucket-name/mongodb-202307240734.tar.gz
EOF
</code></pre><p><img src="30.png" alt="30"></p>
<h4 id="automate-the-backup-with-cron">Automate the Backup with Cron</h4>
<p>Currently the backup script must be manually invoked, however we can use <code>cron</code> to run the script on a schedule.</p>
<p>Check that <code>cron</code> is running:</p>
<pre tabindex="0"><code>sudo systemctl status cron
...
● cron.service - Regular background program processing daemon
   Loaded: loaded (/lib/systemd/system/cron.service; enabled; vendor preset: enabled)
   Active: active (running) since Sun 2023-07-16 05:48:21 UTC; 1 weeks 1 days ago
     Docs: man:cron(8)
 Main PID: 1160 (cron)
   CGroup: /system.slice/cron.service
           └─1160 /usr/sbin/cron -f
</code></pre><p>Edit the crontab (the configuration file that the <code>cron</code> service uses):</p>
<pre tabindex="0"><code>crontab -e
</code></pre><p>Paste the following at the bottom of the crontab:</p>
<pre tabindex="0"><code>0 3 * * * $HOME/backup_mongodb.sh &gt; $HOME/backup/backup.log 2&gt;&amp;1
</code></pre><p>Assuming <code>nano</code> is your text editor, save and exit using CTRL+X, then <code>Y</code>.</p>
<p>The text tells <code>cron</code> to automatically run a backup at 3am everyday. It redirect all output into a log file called <code>backup.log</code> which can be reviewed if troubleshooting is required.</p>
<hr>
<h2 id="finish">Finish</h2>
<p>🥳 Congratulations! You now have an insecure deployment of Rocket.Chat on a managed Kubernetes cluster in Amazon AWS.</p>
]]></content>
        </item>
        
        <item>
            <title>Deploy Netskope Cloud Exchange</title>
            <link>https://nathancatania.com/posts/deploy-netskope-cloud-exchange/</link>
            <pubDate>Fri, 09 Dec 2022 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploy-netskope-cloud-exchange/</guid>
            <description>The thoughts, and opinions in this post are my own and do not reflect those of Netskope. All content in this post is my own and is not endorsed by Netskope. Please follow this guide at your own risk.
Changelog:
1st Mar, 2022: Initial post 7th Dec, 2022: Updated guide for Cloud Exchange 4.0. What is Cloud Exchange? Cloud Exchange (CE) is a platform (free for all Netskope customers) that facilitates the exchange of information between your various security and operations platforms.</description>
            <content type="html"><![CDATA[<blockquote>
<p>The thoughts, and opinions in this post are my own and do not reflect those of Netskope. All content in this post is my own and is not endorsed by Netskope. Please follow this guide at your own risk.</p>
</blockquote>
<p>Changelog:</p>
<ul>
<li>1st Mar, 2022: Initial post</li>
<li>7th Dec, 2022: Updated guide for Cloud Exchange 4.0.</li>
</ul>
<h1 id="what-is-cloud-exchange">What is Cloud Exchange?</h1>
<p>Cloud Exchange (CE) is a platform (free for all Netskope customers) that facilitates the exchange of information between your various security and operations platforms.</p>
<p><img src="1.png" alt="1"></p>
<h1 id="what-can-cloud-exchange-do">What can Cloud Exchange do?</h1>
<p>4 modules make up the Cloud Exchange platform; each with a particular area of focus. You don&rsquo;t need to use every module: only the ones that make sense based on the vendors in your current environment.</p>
<h2 id="1-threat-exchange">1. Threat Exchange</h2>
<p>The Cloud Threat Exchange (CTE) module is designed to streamline and automate the sharing of threat indicators and intelligence between security platforms in use in your environment; reducing the likelihood of a successful attack.</p>
<h2 id="2-ticket-orchestrator">2. Ticket Orchestrator</h2>
<p>For incidents and alerts generated in the Netskope platform, the Cloud Ticket Orchestrator (CTO) module will automatically create tickets and/or notifications in 3rd-party ITSM and collaboration systems (like ServiceNow, JIRA, Slack, etc) to streamline incident response.</p>
<h2 id="3-risk-exchange">3. Risk Exchange</h2>
<p>The Cloud Risk Exchange (CRE) module facilitates the sharing and normalization of both <strong>user</strong> and <strong>SaaS application</strong> risk scores between security vendors. CRE is divided into two distinct sub-modules: User Risk Exchange (URE) and Application Risk Exchange (ARE).</p>
<h3 id="user-risk-exchange">User Risk Exchange</h3>
<p>The User &amp; Entity Behavior Analytics (UEBA) feature in the Netskope platform tracks anomolous user behaviour and provides a dynamic risk score for each user in the organization. This score is known as the User Confidence Index (UCI) and it can be leveraged in policy to trigger restrictions or access controls based on hightened user risk.</p>
<p>Other platforms, like Crowdstrike and Mimecast, also offer user risk scoring features of their own. The URE sub-module takes the user risk scores generated by Netskope and your other security vendors, and normalizes and weights them into a single score that can be used to trigger actions across vendors (eg: place the user into a &ldquo;high risk&rdquo; Active Directory group).</p>
<h3 id="application-risk-exchange">Application Risk Exchange</h3>
<p>The ARE sub-module collects the risk information for all SaaS apps accessed by users in the organization, and facilitates the sharing of this data with other security vendors.</p>
<h2 id="4-log-shipper">4. Log Shipper</h2>
<p>The Cloud Log Shipper (CLS) module extracts the raw event, alert, and log data from your Netskope tenant, and pushes it to one or more receivers, such as a Data Lake or SIEM solution like Splunk, Azure Sentinel, Exabeam, and so on.</p>
<hr>
<h1 id="deploying-cloud-exchange">Deploying Cloud Exchange</h1>
<p>Cloud Exchange is deployed as a series of Docker containers within your environment - hence as long as your system can run Docker (or Podman), it can also run Cloud Exchange!</p>
<p>This guide will focus on using Ubuntu 20.04 LTS as the host OS, but you may also wish to use Red Hat Enterprise Linux (RHEL).</p>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
RHEL leverages Podman instead of Docker for container management. Netskope has specific instructions for RHEL/Podman <a href="https://docs.netskope.com/en/system-requirements.html#idm45784491605296_body">here</a>.
</div>

<h2 id="requirements">Requirements</h2>
<p>You will need the following to install Cloud Exchange:</p>
<h3 id="operating-system">Operating System</h3>
<ul>
<li>A Linux system capable of supporting the docker.io release of Docker (v19.0.0 or higher), and Docker Compose (v1.29.0 or higher).
<ul>
<li>Ubuntu 20.04 LTS and RHEL 7.9 &amp; 8.0 are supported by Netskope.</li>
<li>This guide uses Ubuntu 20.04 LTS</li>
</ul>
</li>
</ul>
<h3 id="system-specification">System Specification</h3>
<p>The VM that Cloud Exchange is deployed to should meet the following minimum requirements:</p>
<ul>
<li>4 vCPUs</li>
<li>4 GB of memory</li>
<li>40 GB of storage</li>
<li>For example: Azure = <code>Standard B2ms</code>, AWS = <code>a1.xlarge</code>, GCP = <code>e2-highcpu-4</code>.</li>
</ul>
<p>For large enterprise environments with a high rate of Events Per Minute (EPM), the system requirements are higher. Netskope provides scaling numbers <a href="https://docs.netskope.com/en/system-requirements.html#UUID-92edc283-a3a0-2a63-1312-513929a52ed0_N1666326801974">here</a>.</p>
<h3 id="networking">Networking</h3>
<ul>
<li>Cloud Exchange requires <strong>outbound</strong> connectivity to GitHub, Docker Hub, your Netskope tenant, and any other vendor platform you plan to integrate it with (eg: Crowdstrike, Splunk, Mimecast, etc).
<ul>
<li><a href="https://docs.netskope.com/en/system-requirements.html#idm45784491624608">See here</a> for a list of URLs that Cloud Exchange requires access to.</li>
</ul>
</li>
<li>Deploying CE behind a HTTP(S) proxy is supported (if required).</li>
<li>Cloud Exchange requires inbound connectivity on 22 for installation/server management, and 443 for access to the admin UI (via HTTPS).
<ul>
<li>It is NOT recommended that you expose Cloud Exchange publicly on the internet.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="install-docker--docker-compose">Install Docker &amp; Docker Compose</h2>
<p>If you&rsquo;re using a fresh VM, you&rsquo;ll need to install Docker and Docker Compose. The below will install Docker CE (Community Edition), which is free but does not come with support. For a production environment, Docker Enterprise is recommended.</p>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
The commands below cover the installation of Docker on an Ubuntu host. <strong>For RHEL 8+, you will need to use Podman instead of Docker. Please see <a href="https://docs.netskope.com/en/install-netskope-cloud-exchange-on-a-red-hat-enterprise-8-x-linux-host.html">here</a> for instructions on how to deploy CE on RHEL.</strong>
</div>

<ol>
<li>Update the existing packages on the system:</li>
</ol>
<pre tabindex="0"><code>sudo apt update -y &amp;&amp; sudo apt upgrade -y
</code></pre><ol start="2">
<li>Install the pre-requisite packages. These allow <code>apt</code> to use a repository over HTTPS:</li>
</ol>
<pre tabindex="0"><code>sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release -y
</code></pre><ol start="3">
<li>Add the GPG key for the official Docker software repository:</li>
</ol>
<pre tabindex="0"><code>sudo mkdir -p /etc/apt/keyrings &amp;&amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
</code></pre><ol start="4">
<li>Add the Docker software repository:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;deb [arch=</span><span style="color:#66d9ef">$(</span>dpkg --print-architecture<span style="color:#66d9ef">)</span><span style="color:#e6db74"> signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu </span><span style="color:#66d9ef">$(</span>lsb_release -cs<span style="color:#66d9ef">)</span><span style="color:#e6db74"> stable&#34;</span> | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null
</span></span></code></pre></div><ol start="5">
<li>Update the package index:</li>
</ol>
<pre tabindex="0"><code>sudo apt update -y
</code></pre><div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
If you receive a GPG error, your default <a href="https://en.wikipedia.org/wiki/Umask">umask</a> may be incorrectly configured. Grant read permissions to the Docker public key (<code>sudo chmod a+r /etc/apt/keyrings/docker.gpg</code>) and try again.
</div>

<ol start="6">
<li>Install Docker:</li>
</ol>
<pre tabindex="0"><code>sudo apt install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y
</code></pre><ol start="7">
<li>Verify the installation:</li>
</ol>
<pre tabindex="0"><code>sudo docker run hello-world
</code></pre><p>If successful, this will pull a Docker container, print a confirmation message, and exit.</p>
<ol start="8">
<li>Install Docker Compose:</li>
</ol>
<p>Cloud Exchange currently uses the older <code>docker-compose</code> syntax instead of <code>docker compose</code> (note the missing <code>-</code>), so we need to install the standalone version of Docker Compose which uses the older syntax:</p>
<pre tabindex="0"><code>sudo curl -SL https://github.com/docker/compose/releases/download/v2.14.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
</code></pre><ol start="9">
<li>Make the Docker Compose binary executable:</li>
</ol>
<pre tabindex="0"><code>sudo chmod +x /usr/local/bin/docker-compose
</code></pre><ol start="10">
<li>Validate that Docker Compose is installed correctly:</li>
</ol>
<pre tabindex="0"><code>docker-compose --version
...
&gt;&gt; Docker Compose version v2.14.0
</code></pre><ol start="11">
<li>Set the Docker process to start at boot:</li>
</ol>
<pre tabindex="0"><code>sudo systemctl enable docker &amp;&amp; sudo systemctl start docker
</code></pre><ol start="12">
<li>Check that the Docker service is running:</li>
</ol>
<pre tabindex="0"><code>sudo systemctl status docker

● docker.service - Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
     Active: active (running) since Wed 2022-12-07 05:49:10 UTC; 1min 14s ago
TriggeredBy: ● docker.socket
       Docs: https://docs.docker.com
   Main PID: 838 (dockerd)
      Tasks: 8
     Memory: 91.6M
     CGroup: /system.slice/docker.service
             └─838 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
</code></pre><p>After the install, if you attempt to run the <code>docker</code> command without <code>sudo</code>, you will get the following error:</p>
<pre tabindex="0"><code>ERROR: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:
</code></pre><p>If you don&rsquo;t mind this, you can jump ahead. Otherwise, you can add your username to the <code>docker</code> group that was created on install. This will allow you to use the <code>docker</code> command without <code>sudo</code>.</p>
<pre tabindex="0"><code>sudo usermod -aG docker ${USER}
</code></pre><p>You will then need to log out of the system, then log back in again for the updated membership to take effect.</p>
<hr>
<h2 id="clone-the-netskope-cloud-exchange-repository">Clone the Netskope Cloud Exchange Repository</h2>
<p>Clone the Cloud Exchange repository from <a href="https://github.com/netskopeoss/ta_cloud_exchange">Netskope on GitHub</a>.</p>
<pre tabindex="0"><code>mkdir netskope &amp;&amp; cd netskope
git clone https://github.com/netskopeoss/ta_cloud_exchange
cd ta_cloud_exchange
</code></pre><p>The scripts in this repository will pull the containers from the Netskope repository on <a href="https://hub.docker.com/u/netskopetechnicalalliances">Docker Hub</a>, bring them up using Docker Compose, and perform the initial setup of Cloud Exchange. Before executing the setup command however, thought needs to be given as to how Cloud Exchange will be secured… read on!</p>
<hr>
<h2 id="installing-cloud-exchange">Installing Cloud Exchange</h2>
<p>Install Cloud Exchange:</p>
<pre tabindex="0"><code>python3 ./setup
</code></pre><div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
Special characters (including, but not limited to <code>#</code>, <code>$</code>, <code>/</code>, etc) <strong>are not supported</strong> when setting the maintenance password for CE. Using these characters may cause some internal processes to fail.
</div>

<p>When prompted:</p>
<ul>
<li>
<p>Type <code>1</code> to install the latest version.</p>
</li>
<li>
<p>Specify whether you are using a HTTP(S) proxy for outbound traffic. If you are not sure, type <code>N</code></p>
</li>
<li>
<p>Enter the <strong>Tenant ID</strong> of your Netskope tenant. <strong>Do not enter the <code>.goskope.com</code> part</strong>. For example:</p>
<ul>
<li>If your tenant URL is: <code>https://mycompany.goskope.com</code>, enter <code>mycompany</code></li>
<li>If your tenant URL is: <code>https://mycompany.au.goskope.com</code> (or similar), enter <code>mycompany.au</code></li>
</ul>
</li>
<li>
<p>Type <code>HTTPS</code> to access Cloud Exchange securely (don&rsquo;t use HTTP… just don&rsquo;t.)</p>
</li>
<li>
<p>Enter <code>443</code> when prompted for a port.</p>
<ul>
<li>This is the port that the admin interface is accessible on. Make sure you have an appropriate firewall rule in place to allow access.</li>
</ul>
</li>
<li>
<p>Enter a secret password that will be used to sign any generated authentication tokens. You don&rsquo;t need to remember this - just make it long and complex.</p>
</li>
<li>
<p>Enter a maintenance password for the RabbitMQ and MongoDB services.</p>
<ul>
<li><strong>WARNING: This password can only be set once! Make sure you make it complex and note it down.</strong></li>
<li><strong>Remember: Don&rsquo;t use special characters like <code>#</code>, <code>$</code>, and <code>/</code>.</strong></li>
</ul>
</li>
<li>
<p>Press ENTER or type <code>No</code> when prompted to enable TLS 1.2. TLS 1.3 is used by default.</p>
</li>
</ul>
<p>To see example usage of the setup script, see the GitHub Gist <a href="https://gist.github.com/nathancatania/a08639b42b081dcd30c8af1693358320">here</a>.</p>
<hr>
<h2 id="launching-cloud-exchange">Launching Cloud Exchange</h2>
<p>To start Cloud Exchange:</p>
<pre tabindex="0"><code>./start
</code></pre><p>To stop Cloud Exchange:</p>
<pre tabindex="0"><code>./stop
</code></pre><p>On first run, the Cloud Exchange containers will be pulled from Docker Hub so it may take some time to come up.</p>
<pre tabindex="0"><code>nathan1@ce:~/netskope/ta_cloud_exchange$ ./start
Docker Compose version v2.14.0
[+] Running 5/5
 ⠿ watchtower Pulled
 ⠿ rabbitmq-stats Pulled
 ⠿ core Pulled
 ⠿ mongodb-primary Pulled
 ⠿ ui Pulled
[+] Running 5/5
 ⠿ Network ta_cloud_exchange_default              Created
 ⠿ Container ta_cloud_exchange_rabbitmq-stats_1   Started
 ⠿ Container ta_cloud_exchange_mongodb-primary_1  Started
 ⠿ Container ta_cloud_exchange_watchtower_1       Started
 ⠿ Container ta_cloud_exchange_core_1             Started
 ⠿ Container ta_cloud_exchange_ui_1               Started
</code></pre><p>When complete, you will be able to access the Cloud Exchange UI in your browser:</p>
<pre tabindex="0"><code>https://&lt;host ip address&gt;
</code></pre><div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
<p>At this point, you should receive an untrusted SSL warning in your browser. <strong>This is normal</strong>: The CE setup script automatically generated a self-signed SSL certificate to secure connectivity to the admin UI. Your connection is secure.</p>
<p>You can whitelist the CE URL in your browser to remove this error OR you can replace the self-signed SSL certificate with one that is trusted/signed by a trusted CA. The latter is covered in the next section.</p>

</div>

<p><img src="2.png" alt="2"></p>
<p>If you can&rsquo;t access the UI, make sure that any host firewall (eg: <code>ufw</code>), network firewall, and/or Network Security Group (NSG) permits port 443 inbound towards the host IP address.</p>
<div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
Inbound exposure should be local only: We do not recommend exposing Cloud Exchange to the internet. Ideally, you should site CE behind a ZTNA solution like Netskope Private Access (NPA).
</div>

<p>If you want to be able to access Cloud Exchange from a nice domain name (eg: cloudexchange.company.com), you can create an A record in your DNS (or hosting provider) pointing towards the IP address of your Cloud Exchange host.</p>
<hr>
<h2 id="optional-changing-the-ssl-certificate">(Optional) Changing the SSL Certificate</h2>
<p>When you opted to use HTTPS to access the Cloud Exchange UI, the setup script automatically generated a self-signed SSL certificate to secure access to the admin UI. However, this results in untrusted SSL certificate warnings in your browser.</p>
<p>The self-signed certificate can be optionally swapped out for one that is signed by a trusted CA to prevent the SSL warning.</p>
<p>To do so, follow these steps:</p>
<ol>
<li>Stop the Cloud Exchange service:</li>
</ol>
<pre tabindex="0"><code>cd ~/netskope/ta_cloud_exchange
./stop
</code></pre><ol start="2">
<li>Remove the existing certificate and private key in the <code>ta_cloud_exchange/data/ssl_certs/</code> directory:</li>
</ol>
<pre tabindex="0"><code>cd ~/netskope/ta_cloud_exchange/data/ssl_certs/
rm -rf cte_cert.crt
rm -rf cte_cert_key.key
</code></pre><ol start="3">
<li>Rename your certificate and private key to <code>cte_cert.crt</code> and <code>cte_cert_key.key</code> and copy them to <code>ta_cloud_exchange/data/ssl_certs/</code>:</li>
</ol>
<pre tabindex="0"><code>cp your_certificate.crt ~/netskope/ta_cloud_exchange/data/ssl_certs/cte_cert.crt
...
cp your_private_key.key ~/netskope/ta_cloud_exchange/data/ssl_certs/cte_cert_key.key
</code></pre><ol start="4">
<li>Restart Cloud Exchange:</li>
</ol>
<pre tabindex="0"><code>cd ~/netskope/ta_cloud_exchange
./start
</code></pre><div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
Ensure that you rename your public and private key to <code>cte_cert.crt</code> and  <code>cte_cert_key.key</code> respectively, or your certificate will not be used!
</div>

<h3 id="troubleshooting">Troubleshooting</h3>
<p>After changing the certificate, if the UI is no longer accessible, check the logs for the UI container (this will typically be called <code>ta_cloud_exchange_ui_1</code>):</p>
<pre tabindex="0"><code>docker logs ta_cloud_exchange_ui_1
</code></pre><p>The issue is likely due to the format of the certificate or private key. Cloud Exchange uses NGINX underneath, so that is what you are aiming for in terms of compatibility. There should be no need to use a CA Bundle: just the certificate on it&rsquo;s own will suffice.</p>
<pre tabindex="0"><code>nathan1@ce:~/$ docker logs ta_cloud_exchange_ui_1
[...]
2022/12/09 00:52:41 [emerg] 11#11: SSL_CTX_use_PrivateKey(&#34;/etc/nginx/nginx-privatekey.key&#34;) failed (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch)
nginx: [emerg] SSL_CTX_use_PrivateKey(&#34;/etc/nginx/nginx-privatekey.key&#34;) failed (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch)
</code></pre><hr>
<h1 id="configure-cloud-exchange">Configure Cloud Exchange</h1>
<p>Now that you have deployed Cloud Exchange, we need to perform some initial configuration steps.</p>
<h2 id="logging-into-cloud-exchange">Logging into Cloud Exchange</h2>
<p>The default username/password for the Super Administrator for Cloud Exchange is <code>admin</code>/<code>admin</code>.</p>
<p>Once you accept the EULA, you will be prompted to change the default password. There can only be one Super Administrator and the username cannot be changed.</p>
<h2 id="enabling-cloud-exchange-modules--updates">Enabling Cloud Exchange Modules &amp; Updates</h2>
<p>Once you are logged in, Cloud Exchange will place you into the <strong>Settings &gt; General</strong> menu.</p>
<p><img src="3.png" alt="3"></p>
<p>You should enable all 5 of the Cloud Exchange modules under the <strong>General</strong> tab. Only the Super Administrator (the <code>admin</code> user) can turn these modules on/off: Regular admins are not able to see the settings to enable/disable these modules.</p>
<p>Under <strong>System Updates</strong>, toggle ON <em><code>Periodically check for updates</code></em>.</p>
<h2 id="optional-setting-a-proxy">(Optional) Setting a Proxy</h2>
<p>If you require the Cloud Exchange modules themselves to communicate through a proxy, you can configure this under the <em>Proxy</em> tab under <strong>Settings &gt; General</strong>.</p>
<h2 id="adding-users--configuring-sso">Adding Users &amp; Configuring SSO</h2>
<p>By default, Cloud Exchange uses a local login mechanism where users sign into CE directly.</p>
<p>User Management is located under <strong>Settings &gt; Users</strong></p>
<p>To create a user, click the plus button on the top right-hand side of the Users table.</p>
<p><img src="4.png" alt="4"></p>
<p>There are two roles available for assignment: <strong>Admin</strong> and <strong>Read-Only</strong>. Currently, it is not possible to create additional roles in Cloud Exchange.</p>
<p>The Super Administrator role is only assigned to the default <code>admin</code> user. Only the default <code>admin</code> user can add/remove users, add/remove CE modules, and change CE module-specific config.</p>
<p>While local login may be acceptable for some smaller organizations, most will want to configure Single-Sign On (SSO) so that the login can utilize federated identity.</p>
<p>To configure SSO, click the <em>SSO</em> tab under <strong>Settings &gt; Users</strong>, and enable the SSO checkbox.</p>
<p>I will post a separate guide linked below on how to configure SSO for Cloud Exchange with both Okta and Azure Active Directory (AAD).</p>
<ul>
<li>[Guide] <a href="/posts/sso-cloud-exchange">How-to setup SSO for Netskope Cloud Exchange (Okta &amp; Azure AD)</a></li>
</ul>
<h2 id="add-your-netskope-tenants">Add Your Netskope Tenant(s)</h2>
<p>The last configuration step is to pair your Netskope tenant with your Cloud Exchange deployment in order for data to be synchronized. Multiple tenants are supported.</p>
<h3 id="get-an-api-key">Get an API Key</h3>
<p>You will need to get an API key from within your Netskope tenant. For this guide, we will use API v1. API v2 will not be used (for now).</p>
<p>Log into your Netskope tenant, and navigate to <strong>Settings (bottom-left corner) &gt; Tools &gt; REST API v1</strong>.</p>
<p><img src="5.png" alt="5"></p>
<p><img src="6.png" alt="6"></p>
<p>Copy the API token displayed. If this is your first time using the API, you may need to generate a new one.</p>
<h3 id="add-your-netskope-tenants-in-cloud-exchange">Add your Netskope Tenant(s) in Cloud Exchange</h3>
<p>Navigate to <strong>Settings &gt; Netskope Tenants</strong> and click the <strong>Add Tenant</strong> button.</p>
<p><img src="7.png" alt="7"></p>
<p>Fill in the fields according to the table below:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>Enter an easy to remember name for the tenant. Can be whatever you like.</td>
</tr>
<tr>
<td>Tenant Name</td>
<td>Enter the subdomain of your Netskope tenant - this is everything <strong>before</strong> the <code>.goskope.com</code> in the URL of your Netskope tenant. Eg: For <code>lightwave.goskope.com</code>, enter <code>lightwave</code>. For <code>lightwave.eu.goskope.com</code>, enter <code>lightwave.eu</code>.</td>
</tr>
<tr>
<td>V1 API Token</td>
<td>Enter the API token copied from your tenant in the step above.</td>
</tr>
<tr>
<td>V2 API Token</td>
<td>Optional. Leave this blank for now.</td>
</tr>
<tr>
<td>Initial Range</td>
<td>Number of days of historical data to sync with CE initially. Enter any value between 1-60. 7-14 is a good default number if you are unsure.</td>
</tr>
<tr>
<td>Use System Proxy</td>
<td>Check this if you would like the connection between CE and Netskope to use the configured system proxy.</td>
</tr>
</tbody>
</table>
<p>Click <strong>Save</strong> to complete your configuration.</p>
<p><img src="8.png" alt="8"></p>
<h3 id="verify-the-netskope-tenant-configuration">Verify the Netskope Tenant Configuration</h3>
<p>Navigate to <strong>Logging</strong> in the bottom-left corner of the UI.</p>
<p>If your Netskope tenant was successfully added, you will start to see events synchronized (provided your tenant has alerts to sync).</p>
<p><img src="9.png" alt="9"></p>
<h1 id="configure-plugins">Configure Plugins</h1>
<p>Cloud Exchange uses the concept of &ldquo;plugins&rdquo; to determine where to send and receive data from.</p>
<p>You can have multiple inputs and multiple outputs: Naturally, you will want to sync data to and from your Netskope tenant(s) in addition to your other vendors.</p>
<p>Navigate to <strong>Settings &gt; Plugins</strong></p>
<p><img src="10.png" alt="10"></p>
<p>Here you will see a list of supported plugins; tagged according to the CE module the plugin aligns to data-wise:</p>
<table>
<thead>
<tr>
<th>CE Tag</th>
<th>Associated CE Module</th>
</tr>
</thead>
<tbody>
<tr>
<td>CTO</td>
<td>Cloud Threat Exchange. Synchronize threat intel, including IOCs, between vendors.</td>
</tr>
<tr>
<td>CRE</td>
<td>Cloud Risk Exchange (User Risk Scoring): Normalize and aggregate user risk scoring between vendors.</td>
</tr>
<tr>
<td>CTO</td>
<td>Cloud Ticket Orchestrator. Automatically raise tickets and alerts in apps like Jira, ServiceNow, and Slack.</td>
</tr>
<tr>
<td>CLS</td>
<td>Cloud Log Shipper. Automatically pull and push logs to SIEM and data lake applications like Splunk and Sentinel.</td>
</tr>
<tr>
<td>ARE</td>
<td>Application Risk Exchange. Send Netskope SaaS app risk information to other security vendors.</td>
</tr>
</tbody>
</table>
<p>To start, you will want to configure the Netskope plugins for the associated modules you wish to use. For example, if you wish to share IOCs between Netskope and Crowdstrike, ensure you configure the Netskope CTE plugin in addition to the Crowdstrike CTE plugin.</p>
<p>Vendors could potentially have multiple plugins depending on the CE modules supported. For example, Crowdstrike has both CTE and CRE plugins for sharing both threat and risk intel.</p>
<hr>
<h1 id="finish">Finish</h1>
<p>Congratulations! You&rsquo;ve just deployed Cloud Exchange! Where to from here? It&rsquo;s time to start exploring the different plugins across each of the Cloud Exchange modules.</p>
<ul>
<li><a href="https://docs.netskope.com/en/netskope-cloud-exchange.html">Cloud Exchange Netskope documentation</a></li>
<li><a href="https://docs.netskope.com/en/supported-3rd-party-plugins.html">List of 3rd party plugins</a> (see the Cloud Exchange UI for the most up-to-date list)</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Netskope Quick Start Guide</title>
            <link>https://nathancatania.com/posts/netskope-quick-start/</link>
            <pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/netskope-quick-start/</guid>
            <description>Disclaimer: Any thoughts or opinions in this article are my own and do not reflect those of Netskope. I am a Netskope SE who worte this guide in his own time to assist Netskope customers. Please lodge a PR on GitHub to correct any mistakes or inaccuracies.
The Quick Quick Start There are 2 fundamental steps required to deploy Netskope in your environment:
1. Add users to the platform. This is typically done by integrating with your Identity Service (ie: Azure AD, Okta) using SCIM (API), or synchronizing your on-premise Active Directory using the Directory Importer Tool.</description>
            <content type="html"><![CDATA[<blockquote>
<p><strong>Disclaimer:</strong> Any thoughts or opinions in this article are my own and do not reflect those of Netskope. I am a Netskope SE who worte this guide in his own time to assist Netskope customers. Please lodge a PR on GitHub to correct any mistakes or inaccuracies.</p>
</blockquote>
<h1 id="the-quick-quick-start">The Quick Quick Start</h1>
<p>There are 2 fundamental steps required to deploy Netskope in your environment:</p>
<h2 id="1-add-users-to-the-platform">1. Add users to the platform.</h2>
<p>This is typically done by integrating with your Identity Service (ie: Azure AD, Okta) using SCIM (API), or synchronizing your on-premise Active Directory using the Directory Importer Tool.</p>
<p>Having users and identity attributes in the Netskope platform is critical for 2 reasons:</p>
<ol>
<li>Traffic is tied back to user identity; allowing you to have visibility on <em>who</em> is accessing <em>what</em> within your organization.</li>
<li>Policies are primarily centred around user identity attributes; eg: Block WeTransfer EXCEPT for those in the Marketing team.</li>
</ol>
<h2 id="2-deploy-the-netskope-client-to-devices">2. Deploy the Netskope Client to devices</h2>
<p>There are numerous methods to steer traffic to the Netskope cloud for enforcement, but the primary one among them is the Netskope Client. This is a piece of software deployed to a user&rsquo;s device that will:</p>
<ol>
<li>Automatically connect to the closest Netskope POP and forward all internet-bound traffic for inspection and enforcement.</li>
<li>Attribute traffic entering and leaving the device with the identity of the user (<a href="mailto:user@company.com">user@company.com</a>).</li>
</ol>
<p>The Netskope client is incredibly lightweight as all inspection happens within the Netskope cloud: There is no traffic processing that occurs on the user machine.</p>
<p>The default configuration of the Netskope client is to steer web traffic to Netskope for inspection, so there is no baseline configuration needed to get the client to function out of the box.</p>
<h2 id="using-this-guide">Using this Guide</h2>
<p>The full guide below covers everything that a typical enterprise will need to do to get Netskope up and running effectively in their environment; including accessing the Admin Console, ensuring that your firewalls allow the Netskope client to connect, ensuring that you have the traffic steering bypasses you need in place, and customizing the configuration of the client.</p>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-1---access-the-admin-console">Step 1 - Access the Admin Console</h1>
<p>The Netskope Administrator Console provides a central interface for configuring the settings of every aspect and feature the Netskope Cloud Security Platform has to offer; including creating policies, reviewing reports, and managing incidents.</p>
<figure><img src="1.png"
         alt="The Netskope Administrator Console - Dashboard"/><figcaption>
            <p>The Netskope Administrator Console - Dashboard</p>
        </figcaption>
</figure>

<p>The login URL to the admin console is unique for your company and different for every Netskope tenant. It will be of the form:</p>
<ul>
<li>https://<strong>&lt;tenant-name&gt;</strong>.goskope.com</li>
<li>https://<strong>&lt;tenant-name&gt;</strong>.au.goskope.com</li>
<li>https://<strong>&lt;tenant-name&gt;</strong>.eu.goskope.com</li>
</ul>
<p>For example:</p>
<ul>
<li><a href="https://lightwave.goskope.com">https://lightwave.goskope.com</a></li>
<li><a href="https://lightwave.goskope.com">https://lightwaveindustries.au.goskope.com</a></li>
</ul>
<p>You will receive your login URL along with administrator credentials from your Netskope account representative upon creation of your account. If you have not received these, please contact support or your Netskope account team.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/admin-console.html">About the Netskope Admin Console</a></li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-2---create-administrators">Step 2 - Create Administrators</h1>
<p>Within the Admin Console, navigate to <strong>Settings</strong> (bottom-left) <strong>&gt; Administration &gt; Admins</strong>, and click the <strong>New Admin</strong> button.</p>
<figure><img src="2.png"
         alt="The Administrator management page"/><figcaption>
            <p>The Administrator management page</p>
        </figcaption>
</figure>

<p>Enter the email address of the administrator you would like to add, and select an appropriate role. For full <em>read-write</em> access, select the <strong>Tenant Admin</strong> role. For <em>read-only</em> access, select the <strong>Restricted Admin</strong> role.</p>
<figure><img src="3.png"
         alt="Adding a new administrator"/><figcaption>
            <p>Adding a new administrator</p>
        </figcaption>
</figure>

<p>For more information on administrator roles, including custom roles, see the links below.</p>
<ul>
<li><a href="https://docs.netskope.com/en/managing-administrators.html">Managing Administrators</a></li>
<li><a href="https://docs.netskope.com/en/create-roles-for-restricted-administrators.html">Create Roles for Restricted Administrators</a></li>
</ul>
<p>Longer-term, it is recommended that you integrate admin authentication with your company&rsquo;s SSO provider (eg: Azure AD, Okta, etc). This can be managed via <strong>Settings &gt; Administration &gt; SSO</strong>.</p>
<ul>
<li><a href="https://docs.netskope.com/en/configure-single-sign-on-for-the-netskope-ui.html">Configure Single Sign On for the Netskope UI</a></li>
</ul>
<p>IP Whitelisting can also be applied to the Netskope Admin Portal to restrict the permitted source IP addresses that are allowed to connect to your Admin Console. This can be managed via <strong>Settings &gt; Administration &gt; IP Allowlist</strong>.</p>
<ul>
<li><a href="https://docs.netskope.com/en/ip-allowlisting.html">IP Allowlisting</a></li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-3---integrate-an-identity-provider-idp">Step 3 - Integrate an Identity Provider (IdP)</h1>
<p>Integrating with an IdP (eg: Azure AD, Okta) is a crucial part in configuring your Netskope tenant for use. Users and Groups that are within your IdP&rsquo;s directory will be synchronized to Netskope for use in security policies and access controls.</p>
<blockquote>
<p><strong>For example:</strong> Block SSH as a protocol for every user except those in the IT, CloudOps, and SecOps teams.</p>
</blockquote>
<p>This allows your IdP to become the single-source-of-truth from a security perspective once you have all of your policies defined within the Netskope portal.</p>
<blockquote>
<p><strong>For example:</strong> When you on-board a new employee, you will add them to the company directory and appropriate AD/Security Groups. This information is immediately synchronized to Netskope where your security policies (based on identity attributes) are instantly enforced for that user.</p>
</blockquote>
<p>There are two methods available for synchronizing your users and groups:</p>
<ol>
<li>
<p><strong>SCIM Provisioning (recommended)</strong><br>
This API link between your IdP and Netskope that automatically synchronises user and group information.</p>
</li>
<li>
<p><strong>Directory Importer Tool</strong><br>
Directory Importer is a tool, run locally, that synchronises your directory information from your on-premise Active Directory Domain Controller to Netskope. This is only recommended if you don&rsquo;t have a cloud-based identity service like Azure AD or Okta.</p>
</li>
</ol>
<p>If you don&rsquo;t have a user directory or identity provider, users and groups can also be manually created within the Netskope Admin Portal.</p>
<h2 id="scim-user-provisioning">SCIM User Provisioning</h2>
<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
It is Netskope best practice to use the <a href="https://docs.netskope.com/en/scim-based-user-provisioning.html">SCIM</a> protocol (an API link between the IdP and Netskope) to synchronize users to your Netskope tenant.
</div>

<blockquote>
<p><strong>System for Cross-domain Identity Management (SCIM)</strong> is a standard for automating the exchange of user identity information between identity domains, or IT systems. - <a href="https://en.wikipedia.org/wiki/System_for_Cross-domain_Identity_Management">Wikipedia</a></p>
</blockquote>
<p>SCIM is supported by all major cloud IdPs, including Azure Active Directory (Azure AD), and Okta. Click the link below corresponding to your IdP for a guide on how to integrate it with Netskope:</p>
<ul>
<li><a href="https://docs.netskope.com/en/configure-azure-scim-integration-to-onboard-users-to-netskope.html">Azure Active Directory (Azure AD)</a></li>
<li><a href="https://docs.netskope.com/en/configure-okta-scim-integration-to-onboard-users-to-netskope.html">Okta</a></li>
<li><a href="https://docs.netskope.com/en/user-and-user-group-provisioning-with-onelogin.html">OneLogin</a></li>
</ul>
<p>Once completed, you can verify if your users are being synchronized to Netskope correctly by navigating to <strong>Settings &gt; Security Cloud Platform</strong>, and clicking <strong>Users</strong> under the <em>Netskope Client</em> section.</p>
<figure><img src="4.png"
         alt="Confirm that the users have been successfully synchronized and imported into Netskope."/><figcaption>
            <p>Confirm that the users have been successfully synchronized and imported into Netskope.</p>
        </figcaption>
</figure>

<p>You can validate that group membership has also successfully synchronized by clicking on the username of a user to see which groups they belong to.</p>
<figure><img src="5.png"
         alt="Validate that the group membership has also been correctly synchronized for a user by clicking on their username."/><figcaption>
            <p>Validate that the group membership has also been correctly synchronized for a user by clicking on their username.</p>
        </figcaption>
</figure>

<h2 id="directory-importer">Directory Importer</h2>
<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        This method should only be used if you do not have an IdP that supports SCIM.<br>
    </strong>

</div>

<p>If your organization does not use a cloud IdP, you can use Netskope&rsquo;s <strong>Directory Importer</strong> tool to synchronize users from your on-premise Active Directory servers, or JumpCloud.</p>
<ul>
<li><a href="https://docs.netskope.com/en/configure-directory-importer.html">Configure Directory Importer</a></li>
<li><a href="https://docs.netskope.com/en/user-provisioning-with-secure-ldap-and-jumpcloud.html">User Provisioning with Secure LDAP and JumpCloud</a></li>
</ul>
<h2 id="manual-import">Manual Import</h2>
<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        This method should only be used if you do not have an IdP that supports SCIM.<br>
    </strong>

</div>

<p>If you operate a smaller organization that does not have a cloud IdP or operate Active Directory server, Netskope also supports manual user creation via the Admin Console UI or CSV Import.</p>
<ul>
<li><a href="https://docs.netskope.com/en/provisioning-users-for-netskope-client.html#UUID-ee11bd95-61e2-fc5a-243c-033038b5de42_section-5dd6b402e7cf6-idm45284539592336">Adding Users via Manual Entry or Bulk Upload</a></li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-4---check-firewall-policy">Step 4 - Check Firewall Policy</h1>
<p>We will shortly be installing the Netskope Client (which is used to automatically forward traffic to the Netskope cloud) to user devices, and you must ensure that it is able to communicate to the Netskope Cloud.</p>
<p>Ensure that the following are permitted through both any installed Endpoint firewall software (eg: Windows Firewall, Crowdstrike, etc) and any on-premise network firewall (Palo Alto, Fortinet, etc):</p>
<ul>
<li>TCP 443 towards the Netskope IP range: <code>163.116.128.0/17</code></li>
<li>TCP 53 &amp; UDP 53 (DNS) towards <code>dns.google</code> (<code>8.8.8.8</code> and <code>8.8.4.4</code>).</li>
</ul>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
Google DNS is used for geo-location purposes to determine the closest Netskope datacenter to connect the user to.
</div>

<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
<p>You should ensure that the Netskope IP range is <strong>bypassed</strong> from any SSL decryption/inspection mechanisms you are running on perimeter security appliances or internal proxy servers.</p>
<p>All connections between the Netskope Client and Netskope cloud are Certificate Pinned to prevent Man-in-the-Middle attacks; hence attempting to inspect this connection will cause it to fail.</p>

</div>

<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-5---bypass-netskope-from-your-vpn">Step 5 - Bypass Netskope from your VPN</h1>
<blockquote>
<p><strong>You only need to follow this step if you operate a VPN in Full Tunnel mode</strong></p>
<p>i.e: All traffic (internal and internet-bound) is captured by the VPN and sent back to the corporate network.</p>
</blockquote>
<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
<p>Netskope <strong>strongly recommends</strong> changing your VPN configuration to run in <strong>split tunnel mode</strong> when operating alongside the Netskope Client.</p>
<p>In split tunnel mode, the VPN is only used for internal traffic (i.e. RFC1918 ranges) and explicit routes, while all internet-bound traffic bypasses the VPN and is captured by Netskope.</p>

</div>

<p>You must include a bypass/exclude the Netskope IP range <code>163.116.128.0/17</code> from the VPN tunnel so that the Netskope Client can connect to the Netskope Cloud and the closest Netskope datacenter directly.</p>
<div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
<p>Failure to bypass the Netskope IP range means that the Netskope Client will establish connectivity to the Netskope Cloud via the VPN tunnel and your corporate internet egress point.</p>
<p>This will introduce additional hops and latency to the transaction, and will prevent users from connecting to any Netskope data center <em>except</em> for the one closest to your internet egress point.</p>

</div>

<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-6---configure-a-steering-profile">Step 6 - Configure a Steering Profile</h1>
<p>A Steering Profile tells the Netskope Client <em>what</em> traffic it needs to capture and send towards Netskope, and what traffic it needs to bypass and let through directly.</p>
<p>Steering Profiles can be global (applied for all users) or targeted to specific user groups. The latter can be useful for testing, or for use with specific groups of users that may require more granular configuration (eg: developers).</p>
<p>Every Netskope tenant has a <em>default steering configuration</em> that is used as a fallback should no other Steering Profiles be present or matched on. You can simply continue to use the default steering profile if you wish (with a few small tweaks), or create your own from scratch.</p>
<p>To start, navigate to <strong>Settings &gt; Security Cloud Platform &gt; Steering Configuration</strong>.</p>
<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
On the Steering Configuration page, change the <strong>Bypassed Traffic</strong> setting to <strong>Log</strong>. This ensures that you retain visibility on traffic that is not send to Netskope for inspection.
</div>

<figure><img src="6.png"
         alt="The Steering Configuration page is where you manage what traffic should be sent to Netskope for inspection."/><figcaption>
            <p>The Steering Configuration page is where you manage what traffic should be sent to Netskope for inspection.</p>
        </figcaption>
</figure>

<h2 id="create-or-edit-a-steering-profile">Create or Edit a Steering Profile</h2>
<h3 id="using-the-existing-default-configuration">Using the Existing Default Configuration</h3>
<p>If you simply wish to leverage the existing default steering profile, click the <strong>Default tenant config</strong> profile to edit it&rsquo;s configuration, and select the <strong>Edit</strong> button at the top-right.</p>
<figure><img src="7.png"
         alt="To edit the settings of the default steering configuration, select the profile and click Edit at the top-right."/><figcaption>
            <p>To edit the settings of the default steering configuration, select the profile and click Edit at the top-right.</p>
        </figcaption>
</figure>

<h3 id="creating-a-new-steering-configuration">Creating a New Steering Configuration</h3>
<p>You may want to create a separate profile and target your IT team (or the team will be managing the Netskope platform) as a way of testing traffic steering changes in isolation before pushing them to the rest of your organization.</p>
<p>To create a new profile, click <strong>New Configuration</strong>, and if prompted, select <strong>User Group</strong>. Configure the new steering profile by giving it a name (eg: Testing), and assigning a user group.</p>
<p>The User Group field is a list of Active Directory/Security Groups that have been synchronized from the identity provider.</p>
<h2 id="configure-the-steering-profile">Configure the Steering Profile</h2>
<figure><img src="8.png"
         alt="The configuration window for the steering configuration."/><figcaption>
            <p>The configuration window for the steering configuration.</p>
        </figcaption>
</figure>

<h3 id="select-the-type-of-traffic-to-be-sent-to-netskope">Select the type of traffic to be sent to Netskope</h3>
<p>In the configuration window, select the option for the type of traffic that you would like the Netskope Client to capture and and send to the Netskope Cloud.</p>
<p>Depending on your subscription, some options may not be visible to you:</p>
<ul>
<li>
<p><strong>Cloud Apps Only</strong> - Steer only selected applications to Netskope for deep analysis. You can make exceptions and allow special accommodations for custom applications. If you are a Cloud Inline or CASB-only customer, you should select this option.</p>
</li>
<li>
<p><strong>Web Traffic</strong> - Steer all <em>web</em> traffic (HTTP and HTTPS) to Netskope for deep analysis. You can make exceptions for traffic that have personal or private content. Most organizations should select this option.</p>
</li>
<li>
<p><strong>All Traffic</strong> - Steer <em>all</em> traffic (web and non-web) to Netskope for deep analysis. You can make exceptions for traffic that have personal or private content. If you are subscribed to Cloud Firewall, you should select this option.</p>
</li>
</ul>
<p>If you are subscribed to Netskope Private Access (NPA), ensure that the <strong>Steer Private Apps</strong> checkbox is also selected.</p>
<p>Click <strong>Save</strong> when you are done.</p>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
You can click the <strong>Non-Standard Ports</strong> tab to specify ports other than 80 and 443 to be forwarded to the Netskope proxy
</div>

<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
The <strong>Dynamic Steering</strong> setting can be used to change the way traffic is forwarded by the Netskope Client based on whether the user is working from within the company network, or remotely.
</div>

<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/dynamic-steering.html">Dynamic Steering</a></li>
</ul>
<h3 id="cloud-apps-only-set-the-applications-to-be-sent-to-netskope">(Cloud Apps Only) Set the applications to be sent to Netskope</h3>
<p>If you selected the <strong>Cloud-Apps Only</strong> option above, then you now need to specify which cloud applications (eg: Dropbox, Teams, Sharepoint, etc) that the Netskope Client should intercept and send to Netskope.</p>
<p>Click <strong>Add Steered Item</strong>, and specify the applications required.</p>
<h3 id="bypassing-traffic">Bypassing Traffic</h3>
<p>Traffic can also be explicitly bypassed from being sent to Netskope entirely. This is managed under the <strong>Exceptions</strong> tab of the steering profile.</p>
<p>RFC1918 traffic (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16) is always bypassed from Netskope by default, and Netskope also maintains a list of applications that typically need to be bypassed (due to certificate pinning), eg: Crowdstrike.</p>
<p>Adding bypasses is covered in more detail in the next section.</p>
<h2 id="enable-the-steering-profile">Enable the Steering Profile</h2>
<p>If you created a new steering profile, you will need to enable it before it can be used. On the <strong>Steering Configuration</strong> page (<strong>Settings &gt; Security Cloud Platform &gt; Steering Configuration</strong>), click the &ldquo;<strong>&hellip;</strong>&rdquo; menu next to the steering profile you wish to enable, and select <strong>Enable</strong>.</p>
<p><strong>Note:</strong> The default steering config profile is always enabled.</p>
<figure><img src="9.png"
         alt="You must enable a new steering profile before it will be actively used by the Netskope Client."/><figcaption>
            <p>You must <em>enable</em> a new steering profile before it will be actively used by the Netskope Client.</p>
        </figcaption>
</figure>

<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
When a steering profile is enabled, it will be made available to all targeted users in production. You should always ensure that you have tested your steering profile with a smaller set of users before enabling it more broadly across the organization.
</div>

<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
<p>The Netskope Client calls home every ~15 minutes to check for updated configuration, so it may take some time before your users see any updated steering profiles or settings.</p>
<p>You can force the Netskope client to check immediately by selecting the Netskope icon in the system tray (or Menu Bar) and clicking &ldquo;<em>Configuration</em>&rdquo;.</p>

</div>

<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/steering-configuration.html">Steering Configuration</a></li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-7---add-bypasses-in-netskope">Step 7 - Add Bypasses in Netskope</h1>
<p>There are two types of bypasses when it comes to Netskope: Steering Bypasses and SSL Bypasses.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Steering Bypass</td>
<td>Traffic is bypassed entirely from Netskope at the device level and is sent direct to the destination. It will never reach the Netskope Cloud.</td>
</tr>
<tr>
<td>SSL Decryption Bypass</td>
<td>Applicable to Web &amp; SSL/TLS encrypted traffic only. The traffic is sent to the Netskope Cloud, but bypassed from SSL Inspection. This can be useful when an application is certificate pinned (and breaks when inspected), but you still want Netskope to attempt to filter and scan the traffic.</td>
</tr>
</tbody>
</table>
<p>It is recommended to use SSL Bypasses over Steering Bypasses where possible.</p>
<div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
Excessive steering bypasses can expose your organization to higher risk.
</div>

<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
<p>Netskope automatically maintains a bypass list of applications that employ SSL Certificate Pinning so that you don&rsquo;t have to add them yourself (eg: Crowdstrike, Dropbox, iCloud, etc).</p>
<p>This list can be reviewed under <strong>Settings &gt; Security Cloud Platform &gt; Steering Configuration</strong>. Select a steering profile and navigate to the &ldquo;Exceptions&rdquo; tab to review the bypassed application list.</p>

</div>

<h2 id="ssl-bypasses">SSL Bypasses</h2>
<p>To add an SSL Bypass, in the Netskope Admin Portal navigate to <strong>Policies &gt; SSL Decryption</strong>, and click <strong>Add Policy</strong>.</p>
<p><img src=".gitbook/assets/quickstart-sslbypass.png" alt="Adding a new SSL Bypass Policy. Multiple different criteria can be used."></p>
<p>On the <strong>New SSL Decryption Policy</strong> page, click the <strong>Add Criteria</strong> button. The following criteria can be used for an SSL Bypass:</p>
<ul>
<li>Source Network Location (eg: <code>10.0.10.5/32</code>, <code>10.0.65.0/24</code>)</li>
<li>Destination Network Location (eg: <code>1.2.3.4/32</code>)</li>
<li>Category (eg: <code>Finance</code>)</li>
<li>User (eg: <code>user@company.com</code>)</li>
<li>User Group (eg: <code>SSLBypassGroup</code>)</li>
<li>Organization Unit (eg: <code>Marketing</code>)</li>
<li>App Suite (eg: <code>Amazon</code>)</li>
<li>Application (eg: <code>Microsoft Teams</code>)</li>
</ul>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
To define named Source and Destination Network Locations, navigate to <strong>Policy &gt; Network Location</strong>, and create a new named Network Location with your desired IP ranges.
</div>

<p>Ensure you select the action <strong>Do Not Decrypt</strong> in order to bypass the above criteria from SSL Inspection.</p>
<p>Provide the policy a name, ensure it is set to <strong>Enabled</strong>, and click <strong>Save</strong> at the top-right.</p>
<div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
Don&rsquo;t forget to click <strong>Apply Changes</strong> under <strong>Policy &gt; SSL Decryption</strong> once you have added a bypass. This is required for your changes to take effect.
</div>

<figure><img src="10.png"
         alt="Make sure you click Apply Changes else your policy change will not be pushed live."/><figcaption>
            <p>Make sure you click Apply Changes else your policy change will not be pushed live.</p>
        </figcaption>
</figure>

<h2 id="steering-bypasses">Steering Bypasses</h2>
<p>To add a Steering Bypass, navigate to <strong>Settings &gt; Cloud Security Platform &gt; Steering Configuration</strong>, and click to edit the <strong>default tenant steering configuration</strong> (or any other steering configuration present).</p>
<figure><img src="10.png"
         alt="Steering Bypasses are added by modifying the steering configuration profiles assigned to the Netskope Client."/><figcaption>
            <p>Steering Bypasses are added by modifying the steering configuration profiles assigned to the Netskope Client.</p>
        </figcaption>
</figure>

<p>Click the <strong>Exceptions</strong> tab, then the <strong>New Exception</strong> button.</p>
<figure><img src="11.png"
         alt="To add a steering exception, go to the Exceptions tab and click New Exception."/><figcaption>
            <p>To add a steering exception, go to the <em>Exceptions</em> tab and click <em>New Exception</em>.</p>
        </figcaption>
</figure>

<p>The following criteria can be used when adding a Steering Bypass:</p>
<ul>
<li>Application (eg: <code>Microsoft Teams</code>)</li>
<li>Category (eg: <code>Finance</code>)</li>
<li>Certificate Pinned Applications (list of known apps that are certificate pinned)</li>
<li>Domains (eg: <code>app.company.com</code>)</li>
<li>Source Locations (eg: <code>10.0.0.5/32</code>, <code>10.0.65.0/24</code>)</li>
<li>Destination Locations (eg: <code>1.1.1.1/32</code>)</li>
<li>Source Countries (eg: <code>China</code>, <code>Russia</code>)</li>
</ul>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
To define named Source and Destination Locations, in the main Netskope Admin Console, navigate to <strong>Policy &gt; Network Location</strong>, and create a new named Network Location with your desired IP ranges.
</div>

<p>Steering Bypasses are added to policy immediately and applied automatically to the Netskope Client on next check-in (every 15 minutes).</p>
<h2 id="recommended-bypasses">Recommended Bypasses</h2>
<p>Netskope recommends that you put the following bypasses in place at a minimum:</p>
<table>
<thead>
<tr>
<th>Bypass</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Authentication Bypass / SSO Login Page</td>
<td>Steering Bypass</td>
<td>It is best practice to bypass the URL of your SSO provider&rsquo;s login page to prevent authentication issues. This is typically a <strong>domain</strong> based bypass, eg: <code>login.microsoftonline.com</code> for AzureAD, or <code>*.okta.com</code> + <code>*.oktacdn.com</code> for Okta. If you use Conditional Access policies, you MUST include this bypass or the traffic will appear to come from a Netskope IP address; potentially causing the Conditional Access policy to fail/deny access.</td>
</tr>
<tr>
<td>VPN Gateways</td>
<td>Steering Bypass</td>
<td>It is important that all of your VPN hostnames and destination IPs are bypassed from Netskope. If Netskope intercepts and inspects these connections, connectivity to the VPN is likely to fail. These bypasses may be both <strong>domain</strong> based (eg: <code>vpn.corp.company.com</code>) and/or <strong>Destination Network</strong> (eg: <code>203.0.113.7/32</code>) based.</td>
</tr>
<tr>
<td>Security Vendor Agent / Client</td>
<td>SSL Bypass</td>
<td>Security vendors typically certificate pin the connections their software clients/agents make back to their cloud to prevent tampering. You should ensure that these are bypassed from SSL inspection. These bypasses will typically be Domain based, eg: <code>*.cloudsink.net</code>. Consult your vendor&rsquo;s documentation for more information.</td>
</tr>
</tbody>
</table>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-8---configure-settings-for-the-netskope-client">Step 8 - Configure Settings for the Netskope Client</h1>
<p>The Netskope Client has a range of settings that are controlled centrally by administrators; ie: Tamperproofing settings, Software Update settings, and on-premise detection.</p>
<p>Settings profiles can be applied globally or targeted towards specific groups of users. Just like the Steering Profile Configuration, there is a default settings configuration present that is used as a fallback or in the absence of any other profiles.</p>
<p>Navigate to <strong>Settings &gt; Security Cloud Platform &gt; Devices</strong>, and click the <strong>Client Configurations</strong> button at the top-right.</p>
<figure><img src="13.png"
         alt="The Devices page show a list of all devices that have been deployed with the Netskope Client."/><figcaption>
            <p>The Devices page show a list of all devices that have been deployed with the Netskope Client.</p>
        </figcaption>
</figure>

<h2 id="create-or-edit-a-client-configuration-profile">Create or Edit a Client Configuration Profile</h2>
<p>Click <strong>Default tenant config</strong> to edit the default configuration profile, or <strong>New Client Configuration</strong> to create a new one.</p>
<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
If you plan to enable tamperproofing (ie: disabling the ability for users to turn off the Netskope Client), you may wish to create a second configuration profile that targets your your IT team (or the team that manages your Netskope deployment) that allows the client to be turned off for troubleshooting purposes.
</div>

<p>It is recommended that you leave most of the settings under the <strong>Traffic Steering</strong> tab as the default unless you have a specific need or reason to change them.</p>
<p>For full details on each option available under the Client Configuration settings, see here:</p>
<ul>
<li><a href="https://docs.netskope.com/en/netskope-client-configuration.html">Configuring the Netskope Client</a></li>
</ul>
<h2 id="set-software-update-preferences">Set Software Update Preferences</h2>
<p>The <strong>Install &amp; Troubleshoot</strong> tab allows control over how and when the Netskope Client is automatically updated as releases are made available.</p>
<figure><img src="14.png"
         alt="The Netskope Client should be set to automatically update to the latest Golden Release as best practice."/><figcaption>
            <p>The Netskope Client should be set to automatically update to the latest Golden Release as best practice.</p>
        </figcaption>
</figure>

<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
<p>Netskope strongly recommends that you set the client to upgrade automatically to the <strong>Latest Golden Release</strong>. </p>
<p>Golden Releases run a few versions behind the latest release, but are more thoroughly tested and supported for longer.</p>

</div>

<div class="bd-callout bd-callout-danger">
    <strong class="text-danger">
        <i class="bi bi-x-octagon-fill"></i>&nbsp; 
        
        Warning!<br>
    </strong>
Changing the <strong>Log Level</strong> (under <em>Advanced</em>) to <strong>Debug</strong> will negatively impact performance and throughput of the Netskope Client. This setting should only be used at the direction of Netskope Support for troubleshooting purposes.
</div>

<h2 id="set-tamperproof-preferences">Set Tamperproof Preferences</h2>
<p>The <strong>Tamperproof</strong> tab allows control over whether end-users can freely enable/disable/stop the Netskope Client.</p>
<figure><img src="15.png"
         alt="Tamperproof settings can be used to prevent users from disabling the Netskope Client."/><figcaption>
            <p>Tamperproof settings can be used to prevent users from disabling the Netskope Client.</p>
        </figcaption>
</figure>

<p>For general end-users, it is recommended to prevent the disabling of the Netskope Client (<strong>uncheck</strong> the <strong>Allow disabling of Clients</strong> option).</p>
<p>You should also enable password protection for client uninstallation and service stop (this can be helpful in environments where users still have local administrator rights on their machines).</p>
<div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
<p>No software tamperproofing is 100% effective if the end-user has local administrator privileges on their machine (as this provides them with ultimate control over the device).</p>
<p>Netskope recommends that you disable administrator privileges on corporate managed machines where possible.</p>

</div>

<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/netskope-client-configuration.html">Netskope Client Configuration</a></li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-9---deploy-the-netskope-client">Step 9 - Deploy the Netskope Client</h1>
<p>The Netskope Client is the primary method of steering traffic to the Netskope cloud for real-time inspection, and can be deployed using multiple methods:</p>
<ul>
<li>Email Invite</li>
<li>Packaging the Application (eg: SCCM, Intune, JAMF) (recommended)</li>
</ul>
<h2 id="email-invite">Email Invite</h2>
<ul>
<li>The user receives an email from your Netskope tenant containing a unique link (with embedded enrollment token) to download the client.</li>
<li>On installation, the client is automatically enrolled and authenticated.</li>
<li>Use this method for PoCs, initial testing, one-off users, or for certain small M&amp;A scenarios.</li>
</ul>
<p>&#x1f44d; <strong>Pros:</strong></p>
<ul>
<li>This method is quick and easy.</li>
<li>No MDM or Software Push is required.</li>
</ul>
<p>&#x1f44e; <strong>Cons:</strong></p>
<ul>
<li>The user needs to initiate installation of the client themselves.</li>
<li>The user needs local admin privileges to be able to install the client.</li>
<li>By default, users added via this method are not part of any group.</li>
</ul>
<p><strong>To send an email invite:</strong></p>
<ol>
<li>Navigate to <strong>Settings &gt; Security Cloud Platform &gt; Users</strong></li>
<li>Select the user you wish to send the invite to</li>
<li>Click the &ldquo;<strong>&hellip;</strong>&rdquo; next to their name, and select &ldquo;<strong>Send Invitation</strong>&rdquo;.</li>
</ol>
<figure><img src="16.png"
         alt="Sending an email invite to a user can be completed in just a few clicks."/><figcaption>
            <p>Sending an email invite to a user can be completed in just a few clicks.</p>
        </figcaption>
</figure>

<p>The email the user receives can be customized by going to <strong>Settings &gt; Tools &gt; Templates</strong>, and editing the <strong>Email Invitation</strong> template.</p>
<figure><img src="17.png"
         alt="Example of an email invite that a user will receive"/><figcaption>
            <p>Example of an email invite that a user will receive</p>
        </figcaption>
</figure>

<h2 id="packaging-the-application">Packaging the Application</h2>
<ul>
<li>This is the best method for production deployment and full-scale rollout.</li>
<li>Requires SCIM integration with a cloud identity provider (eg: Azure AD, Okta)</li>
<li>Relies on the UPN of the logged in user to authenticate. This must match the identity provider.</li>
</ul>
<p>&#x1f44d; <strong>Pros:</strong></p>
<ul>
<li>Installation is silent: Users do not know that an agent is pushed and no interaction from the user is required.</li>
<li>No requirement for a user to have local admin priviliges</li>
<li>Use of the client can be enforced through MDM, Group, or Company policy.</li>
<li>The client can be installed within multi-user environments (eg: Citrix) and is fully supported.</li>
</ul>
<p>&#x1f44e; <strong>Cons:</strong></p>
<ul>
<li>Company change control process typically needs to be followed before the client can be pushed (and this can take time).</li>
<li>Some smaller companies may not have the software to push the client or manage devices.</li>
</ul>
<p>If the UPN of the logged in user <strong>does not</strong> match what was synchronized from the directory, the client can instead be rolled out to authenticate the user via SAML / SSO. <a href="https://docs.netskope.com/en/deploy-netskope-client-via-idp.html">See here for more information</a>.</p>
<p>To package the client, follow one of the links below:</p>
<ul>
<li><a href="https://docs.netskope.com/en/microsoft-endpoint-configuration-manager.html">Microsoft Endpoint Configuration Manager / SCCM</a></li>
<li><a href="https://docs.netskope.com/en/microsoft-intune.html">Microsoft Intune</a></li>
<li><a href="https://docs.netskope.com/en/microsoft-group-policy-object--gpo-.html">Microsoft Group Policy Object (GPO)</a></li>
<li><a href="https://docs.netskope.com/en/vmware-workspace-one.html">VMware Workspace One (AirWatch)</a></li>
<li><a href="https://docs.netskope.com/en/jamf.html">JAMF</a></li>
<li><a href="https://docs.netskope.com/en/kandji.html">Kandiji</a></li>
<li><a href="https://docs.netskope.com/en/xenmobile.html">XenMobile</a></li>
<li>MobileIron <a href="https://docs.netskope.com/en/mobileiron-core.html">Core</a> / <a href="https://docs.netskope.com/en/mobileiron-cloud.html">Cloud</a></li>
</ul>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
You <strong>do not</strong> need to use the Directory Importer tool if you have synchronized your users using SCIM in Step 3 of this guide (despite what the linked documentation might say otherwise).
</div>

<p><strong>Sample CLI to install the MSI:</strong></p>
<pre tabindex="0"><code>msiexec /I C:\Netskope\InstallerPkg\nsclient-&lt;ver&gt;.msi token=&lt;orgid&gt; host=addon-&lt;tenant-name&gt;.goskope.com mode=peruserconfig /l*v %PUBLIC%\nscinstall.log
</code></pre><ul>
<li>
<p> <code>&lt;ver&gt;</code> is the version of the Netskope client package downloaded.</p>
</li>
<li>
<p><code>&lt;orgid&gt;</code> is your Organization ID. This is located at <strong>Settings &gt; Security Cloud Platform &gt; MDM Distribution</strong>. Under &ldquo;<strong>Create VPN Configuration</strong>&rdquo;, copy the <strong>Organization ID</strong> string.</p>
</li>
<li>
<p><code>&lt;tenant-name&gt;</code> is the name of your tenant from Step 1. This is the subdomains proceeding the <code>goskope.com</code> in the URL used to access the Admin Control. For example, if you access the Admin Console at <code>https://lightwave.goskope.com</code>, then your tenant name would be <code>lightwave</code>. If you access the Admin Console at <code>https://lightwave.au.goskope.com</code>, then your tenant name would be <code>lightwave.au</code></p>
</li>
<li>
<p>For a full list of command line parameters, see Table 15 <a href="https://docs.netskope.com/en/microsoft-endpoint-configuration-manager.html#idm46406087492976">here</a>.</p>
</li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-10---whitelist-the-netskope-client-process">Step 10 - Whitelist the Netskope Client Process</h1>
<p>Some endpoint security software may mark the Netskope Client as malicious because it attempts to intercept all internet-bound traffic (for the purposes of forwarding it to the Netskope Cloud), and can block it from running as a result.</p>
<p>Therefore it is important to whitelist/permit the Netskope Client&rsquo;s <code>stAgentAvc.exe</code> process in any AV and/or other security agents running on the endpoint to prevent this from happening.</p>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-11---validate-traffic-steering">Step 11 - Validate Traffic Steering</h1>
<p>Now that the Netskope Client has been deployed, it is time to check that it is enabled, working, and correctly forwarding traffic to the Netskope Cloud.</p>
<h2 id="check-that-the-client-is-installed-and-enabled">Check that the client is installed and enabled</h2>
<h3 id="desktop-operating-systems">Desktop Operating Systems</h3>
<p>For Windows, macOS, ChromeOS, and Linux, if the Netskope client is running, you will see it located in the device&rsquo;s system tray or Menu Bar (look for the Netskope logo).</p>
<ul>
<li>If the client is <strong>enabled</strong> and <strong>connected,</strong> the client icon will be colored <img src="nsclient-enabled.png" alt="nsclient-enabled.png"></li>
<li>If the client is <strong>disabled</strong> and <strong>disconnected</strong>, the client icon will be greyed out <img src="nsclient-disabled.png" alt="nsclient-disabled.png"></li>
</ul>
<p>There are variations of the icon that may be displayed to indicate an error or fail close scenario.</p>
<p>If the icon is missing, check the Start Menu or Application list on your device and check to see if the Netskope client is installed.</p>
<p>If the client is disabled, you can right-click on the icon and click <strong>Enable Netskope Client</strong> to have it connect and start forwarding traffic. Likewise, when connected, you can right-click and select <strong>Disable Netskope Client</strong> to turn the client off (depending on the Netskope Client settings you configured, this option (along with others) may not be present).</p>
<figure><img src="nsclient-menu.png"
         alt="The right-click menu of the Netskope Client. Certain options may not be present based on your settings."/><figcaption>
            <p>The right-click menu of the Netskope Client. Certain options may not be present based on your settings.</p>
        </figcaption>
</figure>

<p>To check information about the Netskope connection and device profile, right-click on the Netskope client icon and select <strong>Configuration</strong>. Here you will be able to see:</p>
<ul>
<li>
<p>The authenticated user (traffic will be tracked as coming from this username)</p>
</li>
<li>
<p>The Netskope gateway IP address and Netskope POP the user is connected to.</p>
</li>
<li>
<p>Whether the device is currently marked as <em>managed</em> or <em>unmanaged</em>.</p>
</li>
<li>
<p>The Steering Configuration and Client Configuration profiles currently in use on the device.</p>
</li>
<li>
<p>The protocol used to tunnel traffic to the Netskope Cloud (ie: TLS, DTLS).</p>
</li>
<li>
<p>The last time the configuration of the Netskope client was updated. The Netskope client will periodically phone home to check for updated configuration (this includes the notification messaged displayed to the user when a destination or activity is blocked).</p>
</li>
</ul>
<figure><img src="nsclient-config.png"
         alt="The Configuration panel of the Netskope client shows relevant settings and connection information."/><figcaption>
            <p>The <em>Configuration</em> panel of the Netskope client shows relevant settings and connection information.</p>
        </figcaption>
</figure>

<h3 id="mobile-operating-systems">Mobile Operating Systems</h3>
<p>For iOS and Android devices, check that a Netskope VPN profile has been installed and is enabled on the device.</p>
<p>If you wish to enforce the use of the profile and prevent users from disabling it, you will need to ensure you deploy the Netskope client using a Mobile Device Manager (MDM) like Intune.</p>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
<p>If you installed Netskope on the mobile device using an Email Invite, the Netskope certificate (required for SSL inspection) will be present on the device, but untrusted. You will need to tell your device to trust the certificate before browsing the web.</p>
<p>Failure to do will result in your browser throwing &ldquo;<em>Insecure Connection</em>&rdquo; or &ldquo;<em>This Connection is not Private</em>&rdquo; errors. On iOS, navigate to <strong>Settings &gt; General &gt; About &gt; Certificate Trust Settings</strong>, and enable the certificate. </p>
<p><strong>You DO NOT need to do this if you installed Netskope via MDM.</strong></p>

</div>

<h2 id="validate-that-the-netskope-client-is-forwarding-traffic">Validate that the Netskope Client is forwarding traffic</h2>
<p>Open a new browser window and navigate to <a href="http://notskope.com">http://notskope.com</a> or <a href="https://notskope.com">https://notskope.com</a> (accessible over both HTTP and HTTPS). This website will tell you whether you are passing through the Netskope Cloud or not, and if so, which POP you are connected to.</p>
<figure><img src="notskope.png"
         alt="notskope.com will tell you whether or not your traffic is reaching the Netskope Cloud, and the POP you are connected to."/><figcaption>
            <p>notskope.com will tell you whether or not your traffic is reaching the Netskope Cloud, and the POP you are connected to.</p>
        </figcaption>
</figure>

<p>If your connection does not load, try opening the page in a Private Browser or Incognito window to bypass the browser cache and try again.</p>
<p>To check whether content is being SSL inspected correctly, examine the certificate of <a href="https://notskope.com">https://notskope.com</a> (or any other HTTPS site that isn&rsquo;t bypassed, eg: <a href="https://www.wikipedia.org/">https://www.wikipedia.org</a>). If the connection is being correctly SSL inspected, you will see an intermediate certificate with the name <code>ca.&lt;tenant-name&gt;.goskope.com</code></p>
<figure><img src="notskopecert.png"
         alt="You can validate that a connection was SSL inspected by reviewing the certificate. If you see ca.&amp;lt;tenant-name&amp;gt;.goskope.com, then your connection was SSL inspected."/><figcaption>
            <p>You can validate that a connection was SSL inspected by reviewing the certificate. If you see <code>ca.&lt;tenant-name&gt;.goskope.com</code>, then your connection was SSL inspected.</p>
        </figcaption>
</figure>

<p>If this isn&rsquo;t present, then the connection is not being SSL inspected, and you should check that there is not a steering bypass or SSL decryption bypass in place preventing this.</p>
<p>Installation and management of the Netskope root certificate required for SSL inspection into the system certificate trust store and Firefox trust store is automated by the Netskope Client.</p>
<div class="bd-callout bd-callout-warning">
    <strong class="text-warning">
        <i class="bi bi-exclamation-diamond-fill"></i>&nbsp; 
        
        Caution!<br>
    </strong>
<p>Some thick/native applications (namely apps and tools used for development) use their own certificate trust stores to check certificate validity (eg: Git CLI, Azure Storage Manager, etc).</p>
<p>Internet connections over HTTPS using these apps will fail due to an untrusted SSL error; even through the Netskope root certificate is installed in the system trust.</p>
<p>In these scenarios, you will need to manually install the Netskope root into the trust store used by the application. There is a community script available to assist with installation for the most common tools <a href="https://gist.github.com/nathancatania/2c25ad1d663d25b5677d51bba3d1681c">available here</a>.</p>
<p>The Netskope certificate can be downloaded for distribution from the Admin Console under <strong>Settings &gt; Manage &gt; Certificates</strong>. Click the <strong>Signing CA</strong> tab and download the <strong>Netskope Root Certificate</strong> (first option listed).</p>

</div>

<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="step-12---add--validate-a-security-policy">Step 12 - Add &amp; Validate a Security Policy</h1>
<p>You have almost finished your Netskope deployment and are now ready to test the enforcement of a basic policy.</p>
<p>All policies within Netskope, regardless of the feature (CASB, SWG, Firewall, ZTNA, etc) all follow the same structure:</p>
<ul>
<li>Source Attributes (User, AD Group, OS, Device Posture, Country, etc)</li>
<li>Destination Attributes (Category, App, Instance, etc)</li>
<li>Destination Contraints
<ul>
<li>Activities/Actions (Browse, Download, Upload, Share, Like, Delete, Edit, etc)</li>
<li>Application Tag (Sanctioned, Unsanctioned, Test, etc)</li>
<li>App Instance Tag (Production, QA, 3rd Party, etc)</li>
<li>Destination Country</li>
<li>App Risk / Cloud Confidence Level (CCL) (Low, High, Medium, etc)</li>
</ul>
</li>
<li>Action (Block, Allow, Coach, Isolate, Alert, etc)</li>
<li>Profile (DLP, Threat Scan)</li>
</ul>
<p>Netskope policies operate on the principe of first match, top-to-bottom.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/inline-policies.html">Netskope Real-time Protection Policies</a></li>
</ul>
<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
<p>When configuring policies, you should start with your very broad / organisation-wide rules <strong>before</strong> creating deeper and more specific rules.</p>
<p>The more constraints/attributes that a rule has, the tricker it can be to validate. It is important that your organisation has a number of baseline rules in place that will affect every user regardless of attributes (globally block adult sites and P2P for example).</p>

</div>

<h2 id="create-a-test-policy">Create a test policy</h2>
<p>From the main Netskope Admin Console, navigate to <strong>Policies &gt; Real-time Protection:</strong> Your Netskope tenant will already have some policies in place by default (such as malware scanning).</p>
<p>Click <strong>New Policy</strong>, and then either <strong>Web Access</strong>, or <strong>Cloud App Access</strong> (depending on what is available to you based on your subscription).</p>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
Selecting Web Access, Cloud App Access, Firewall, Private App, or any other option, only presets the destination field in the policy creation workflow and you can change this as you see fit. In reality, it does not matter what you select from this dropdown menu as long as the destination type selected on the policy creation workflow is accurate.
</div>

<figure><img src="18.png"
         alt="Create a new policy under Policies &amp;gt; Real-time Protection"/><figcaption>
            <p>Create a new policy under Policies &gt; Real-time Protection</p>
        </figcaption>
</figure>

<p>Create a basic policy to test as you see fit. The example below covers the creation of a rule that coaches the user on access to gambling-related websites, and alerts them that such content is non-business related and may be against acceptable use.</p>
<ul>
<li>For the <strong>Source</strong> field, set the user to be yourself.
<ul>
<li>Note that you can also add other Source criteria that must be validated during policy evaluation, such as the source country the user is connecting from, the operating system of their device, or whether the device is classified as <em>managed</em> or <em>unmanaged</em>.</li>
</ul>
</li>
<li>For the <strong>Destination</strong> field, either set it to <strong>Category</strong> or <strong>Cloud App</strong> (depending on your subscription).
<ul>
<li>If <strong>Category</strong>, set the targeted category as <strong>Gambling.</strong></li>
<li>If <strong>Cloud App</strong>, set the targeted application as <strong>WeTransfer.</strong></li>
</ul>
</li>
<li>For the Activities field, select <strong>Browse.</strong></li>
<li>For <strong>Profile &amp; Action</strong>, set the action to <strong>User Alert.</strong>
<ul>
<li>The template you are prompted to select what the notification that is displayed to the user will say. You can customize these as you see fit under <strong>Policies &gt; User Notifications</strong>.</li>
<li>The <strong>User Alert</strong> action is a &ldquo;coaching&rdquo; prompt. The user is allowed to proceed through the warning that is displayed, and (depending on the template used) may be forced to enter a justification reason as to why they need to proceed.</li>
</ul>
</li>
<li>Give the policy the name <code>[Access Control] Test Policy Coaching on Gambling Sites</code> (or similar)</li>
<li>Ensure the <strong>Status</strong> is set to <strong>Enabled</strong> and click <strong>Save</strong> at the top-right.</li>
<li>When prompted, save the policy at the top.</li>
</ul>
<div class="bd-callout bd-callout-success">
    <strong class="text-success">
        <i class="bi bi-check-circle-fill"></i>&nbsp; 
        
        Best Practice Tip!<br>
    </strong>
<p>It is a good idea to prefix a label/tag to your policies that describes the type of policy it is or feature that is used.</p>
<p>For example: <strong>[DLP] Prevent Download of Sharepoint Data</strong>, or <strong>[Access Control] Block access to non-business sites</strong>.</p>

</div>

<figure><img src="21.png"
         alt="Example of a policy that provides a coaching/warning prompt to a specific user when they browse to a Gambling site."/><figcaption>
            <p>Example of a policy that provides a coaching/warning prompt to a specific user when they browse to a Gambling site.</p>
        </figcaption>
</figure>

<p>Back on the Real-time Protection page, you should now see your new policy at the top of the list. Click <strong>Apply Changes</strong> at the top right to commit and push the policy to production. Changes will only take a few seconds to apply globally to all users.</p>
<div class="bd-callout bd-callout-info">
    <strong class="text-info">
        <i class="bi bi-info-circle-fill text-primary"></i>&nbsp; 
        
        Heads Up!<br>
    </strong>
Policies do not take effect until your changes are applied. This is to prevent adverse impacts to your production environment as you create and edit policies.
</div>

<figure><img src="19.png"
         alt="Your policy changes will not take effect until you click Apply Changes."/><figcaption>
            <p>Your policy changes will not take effect until you click Apply Changes.</p>
        </figcaption>
</figure>

<h2 id="test-your-policy">Test your policy</h2>
<p>Navigate to either <a href="https://www.gambling.com">https://www.gambling.com</a> or <a href="https://wetransfer.com">https://wetransfer.com</a> (depending on what you selected in your policy).</p>
<p>You should receive a Netskope notification page that allows you to proceed (as the action selected in the policy was <em>User Alert</em> (coach) and not <em>Block</em>). The contents of the notification page will depend on the template you selected in the policy.</p>
<figure><img src="20.png"
         alt="An example of a customized User Alert notification with justification required to proceed."/><figcaption>
            <p>An example of a customized <em>User Alert</em> notification with justification required to proceed.</p>
        </figcaption>
</figure>

<h2 id="troubleshooting">Troubleshooting</h2>
<p>If you don&rsquo;t receive a user notification when navigating to the above sites, try again using an Incognito or Private Browser Window. If this fixes the issue, then the problem was related to the Browser Cache.</p>
<p>If the notification fails to display even inside a private window, check that the traffic is being SSL inspected correctly by examining the certificate of the site. You will see an intermediate certificate with the name <code>ca.&lt;tenant-name&gt;.goskope.com</code> if inspection is working correctly. If this certificate is missing, then it is likely that the site is bypassed from steering or SSL Inspection - in this case, you should review your bypasses (<a href="#step-7---add-bypasses-in-netskope">see Step 7</a>).</p>
<p>You should also confirm that you applied the configuration changes you made under <strong>Policies &gt; Real-time Protection</strong>. If any of your rules have a yellow exclamation warning icon (&#x26a0;&#xfe0f;) next to them, or if the <strong>Apply Changes</strong> button at the top-right is <strong>not</strong> greyed out, then you have not committed your changes and your policy won&rsquo;t have applied.</p>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="partying_face-finish">&#x1f973; Finish</h1>
<p>Congratulations! You&rsquo;ve just finished your deployment of Netskope!</p>
<p>Stand up, have a stretch, pat yourself on the back, and go and take a break: you&rsquo;ve earned it!</p>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="recommended-next-steps">Recommended Next Steps</h1>
<h2 id="review-the-default-real-time-protection-policies-in-your-netskope-admin-console">Review the default Real-Time Protection policies in your Netskope Admin Console.</h2>
<p>The default policies in your Netskope configuration will cover the following:</p>
<ul>
<li>Block undesirable sites (such as adult content and P2P) globally for all users.</li>
<li>Warn and require justification for access to unknown/miscellaneous content and newly registered domains.</li>
<li>Block known and suspected malicious domains and phishing</li>
<li>Ensure all uploads/downloads are checked for malware.</li>
</ul>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/real-time-protection.html">About Real-time Protection Policies</a></li>
<li><a href="https://docs.netskope.com/en/inline-policies.html">Configure Real-time Protection Policies</a></li>
<li><a href="https://docs.netskope.com/en/creating-a-threat-protection-policy-for-real-time-protection.html">Threat Protection Policy for Real-time Protection</a></li>
<li><a href="https://docs.netskope.com/en/inline-monitoring-for-cloud-apps.html">Policy Examples for Cloud Apps</a></li>
</ul>
<h2 id="create-and-customize-your-user-notification-templates">Create and customize your User Notification templates</h2>
<p>The messages that appear to users when a block/coaching rule is hit can be customized under <strong>Policies &gt; User Notification</strong>. Each policy can have a different template; allowing you to coach users on appropriate behaviors across a wide variety of scenarios.</p>
<figure><img src="22.png"
         alt="An example of a coach/user alert notification that directs the user to the correct sanctioned application to use."/><figcaption>
            <p>An example of a coach/user alert notification that directs the user to the correct sanctioned application to use.</p>
        </figcaption>
</figure>

<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/policy-notification-templates.html">Policy Notification Templates</a></li>
</ul>
<h2 id="establish-global-guardrails-and-build-out-policies">Establish global guardrails and build out policies</h2>
<p>Netskope recommends that you expand on the global block (included as a default policy) and add additional sites/categories that you may also want to block globally, eg: Online Ads.</p>
<p>You should also consider implementing a coaching policy with action &ldquo;User Alert&rdquo; that covers the applications and categories that you consider &ldquo;non-business&rdquo; related, but safe for employees to consume; eg: Streaming Media, and/or Gambling.</p>
<p>Access Control rules should take creation priority and you should start with the most simple rules first. Once you have baseline rules in place, slowly add rules of additional complexity; incorporating risk scores, instance awareness, and/or DLP rules.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/create-a-real-time-protection-policy-for-web-categories.html">Create a Real-time Protection policy for web categories</a></li>
<li><a href="https://docs.netskope.com/en/profiles.html">Policy Profiles</a></li>
<li><a href="https://docs.netskope.com/en/create-custom-categories.html">Custom URL Categories</a></li>
</ul>
<h2 id="sanction-your-business-applications">Sanction your business applications</h2>
<p>The Netskope Cloud Confidence Index™ (CCI) is a database of more than 54,000 cloud apps that Netskope has evaluated based on 48+ objective criteria adapted from Cloud Security Alliance Guidance. These criteria measure apps enterprise-readiness, taking into consideration an apps security, audit-ability, and business continuity.</p>
<p>Each app is assigned a score of 0-100, and based on that score, is placed into one of five Cloud Confidence Levels (CCL): Poor, Low, Medium, High, or Excellent. You can use the CCI score to make an app selection decision, as well as set policies based on level. For example, you can decide whether to let users share content in cloud storage or file converter apps rated Medium or below.</p>
<p>Access the CCI from the main panel of the Netskope Admin Console, lookup your key business applications (eg: Sharepoint, Teams, Slack, etc) and mark them as &ldquo;sanctioned&rdquo; (all apps are &ldquo;unsanctioned&rdquo; by default) - eg: Sharepoint, Teams, Dropbox, Zoom, Slack, etc. You can then leverage the <code>sanctioned</code> and <code>unsanctioned</code> tags in policy: For example, block upload to all high risk, unsanctioned, cloud storage applications.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/cloud-confidence-index.html">Using Cloud Confidence Index</a></li>
<li><a href="https://docs.netskope.com/en/tag-apps.html">Tagging Applications</a></li>
<li><a href="https://docs.netskope.com/en/inline-protection-of-cloud-apps.html">Using CCI in Real-time Protection Policies</a></li>
</ul>
<h2 id="deploy-to-a-broader-subset-of-users">Deploy to a broader subset of users</h2>
<p>Once your baseline policies are in place, you are ready to expand your rollout to additional users.</p>
<h2 id="deploy-netskope-publishers-npa-customers-only">Deploy Netskope Publishers (NPA Customers Only)</h2>
<p>If you are a Netskope Private Access (NPA) / ZTNA customer, you will need to deploy Netskope Publishers throughout your environment to facilitate access to your internal apps.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/deploy-a-publisher.html">Deploy a Publisher</a></li>
</ul>
<h2 id="establish-ipsecgre-tunnels-to-netskope-to-secure-clientless-devices-guest-wi-fi-and-servers">Establish IPsec/GRE tunnels to Netskope to secure clientless devices, Guest Wi-Fi, and servers</h2>
<p>The Netskope Client is only one of many methods to steer traffic to the Netskope Cloud.</p>
<p>Another common method used in conjunction with the Netskope Client is the establishment of IPsec or GRE tunnels from your internet egress points (including public cloud). This allows your security policies to be extended and applied to users and devices that can&rsquo;t run the Netskope Client: Guest Wi-Fi, Servers, and IoT/smart devices for example.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/ipsec-129296.html">IPsec</a></li>
<li><a href="https://docs.netskope.com/en/gre-127075.html">GRE</a></li>
</ul>
<h2 id="deploy-netskope-cloud-exchange">Deploy Netskope Cloud Exchange</h2>
<p>Cloud Exchange (CE) is a platform (free for all Netskope customers) that facilitates the exchange of information between your various security and operations platforms; including threat intel, risk data, and logs.</p>
<p>See more:</p>
<ul>
<li><a href="https://community.netskope.com/t5/Blogs/A-Guide-to-Deploy-Netskope-Cloud-Exchange/ba-p/1143">A guide to deploy Cloud Exchange</a></li>
<li><a href="https://docs.netskope.com/en/netskope-cloud-exchange.html">About Cloud Exchange</a></li>
</ul>
<h2 id="configure-administrator-single-sign-on">Configure Administrator Single Sign-On</h2>
<p>Currently, your Netskope Admin Console is authenticated using separately managed username and passwords. It is strongly recommended that you configure Single Sign-On for the Admin Console so that authentication is centrally controlled via your company&rsquo;s identity service.</p>
<p>See more:</p>
<ul>
<li><a href="https://docs.netskope.com/en/configure-single-sign-on-for-the-netskope-ui.html">Configure Single Sign-On (Netskope Admin Console)</a></li>
</ul>
<hr>
<h1 id="feedback">Feedback</h1>
<p>If you notice any mistakes or inaccuracies in this guide, please <a href="https://www.linkedin.com/in/nathancatania/">get in touch with me</a>, or <a href="https://github.com/nathancatania/website/issues/new/choose">raise an issue on GitHub</a>.</p>
]]></content>
        </item>
        
        <item>
            <title>Deploy Apache Guacamole with SSL &amp; SAML (Azure AD &amp; Okta) integration</title>
            <link>https://nathancatania.com/posts/deploy-guacamole-ssl-saml/</link>
            <pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploy-guacamole-ssl-saml/</guid>
            <description>Introduction This post will cover how to configure Single-Sign-On (SSO) using SAML for Apache Guacamole while also ensuring that your deployment is secured behind auto-renewing SSL.
This is a BIG guide as I cover off an automated installation method (using cloud-init), a manual install method, and instructions for both Azure AD and Okta - so you might want to leverage the table of contents above to jump to the sections most approproate to you.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>This post will cover how to configure Single-Sign-On (SSO) using SAML for Apache Guacamole while also ensuring that your deployment is secured behind auto-renewing SSL.</p>
<p>This is a BIG guide as I cover off an automated installation method (using <code>cloud-init</code>), a manual install method, and instructions for both Azure AD and Okta - so you might want to leverage the table of contents above to jump to the sections most approproate to you.</p>
<p>Anyway, let&rsquo;s go!</p>
<h1 id="what-is-guacamole">What is Guacamole?</h1>
<blockquote>
<p><em>Apache Guacamole</em> is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. We call it <em>clientless</em> because no plugins or client software are required. Thanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser.</p>
<p>&ndash; <a href="https://guacamole.apache.org/">Apache.org</a></p>
</blockquote>
<p>Guacamole allows you to access servers, workstations, and infrastructure (essentially anything that connects using SSH or RDP) via a web browser.</p>
<p>It also provides a layer of isolation as the user is not directly connected to the resource themselves: rather Guacamole connects to the resource and the user interacts with a HTML5 canvas of what is on-screen; allowing you to control actions such as the ability to copy &amp; paste between the remote host and user machine.</p>
<p>Gucamole is particularly useful in instances where you want to provide access to internal company resources to 3rd parties (such as MSPs or contractors), but don&rsquo;t want them to be able to connect to the resource directly.</p>
<h1 id="why-bother-with-sso-integration">Why bother with SSO Integration?</h1>
<p>SSO authentication for Guacamole is valuable as it means that the visibility of internal resources (ie: what servers/workstations a user can see and connect to within the Gucamole UI) can be entirely managed within your existing Identity Provider (IdP), rather than within Guacamole itself.</p>
<p><strong>That is, by simply assigning users to different Groups within the IdP, you can control what internal resources they have access to; without having to touch Guacamole itself.</strong></p>
<p>This has two benefits:</p>
<ol>
<li>A reduction of operational overhead in having to manage system access in more than one location.</li>
<li>Ensuring that your IdP is the single-source of truth for validation of identity (critical if you moving your business towards a <a href="https://www.nist.gov/publications/zero-trust-architecture">Zero Trust Architecture</a>)</li>
</ol>
<p>If you are a &ldquo;homelabber&rdquo; and want to start dabbling with SSO, Azure Active Directory&rsquo;s free tier will work fine for this guide.</p>
<hr>
<h1 id="requirements">Requirements</h1>
<p>You will need the following to install Guacamole and configure SAML integration:</p>
<ul>
<li>A Linux system capable of supporting the docker.io release of Docker, and Docker Compose.
<ul>
<li>I recommend Ubuntu Server 20.04 LTS.</li>
<li>This guide will use Ubuntu Server 20.04 LTS running in AWS (t2.micro instance == 1 vCPU, 1GB memory)</li>
</ul>
</li>
<li>An Identity Provider (IdP) that supports SAML 2.0, such as Azure AD or Okta.
<ul>
<li>The Azure AD free tier is sufficient.</li>
<li>This guide will use Azure AD, but the steps will be applicable to any SAML 2.0 IdP (eg: Okta).</li>
</ul>
</li>
<li>The FQDN/domain you wish to use to access Guacamole, eg: <code>guac.company.local</code>
<ul>
<li>The domain must resolve internally to the IP address of the system that Guacamole is running on; eg: <code>guac.company.local</code> <code>-&gt;</code> <code>10.0.10.7</code></li>
<li>If you will be accessing Guacamole through a Clientless ZTNA solution like Netskope Private Access, <strong>then the domain you choose MUST be an external one and the same one that users will use to access it remotely</strong>; eg: <code>guac.company.com</code>. You CANNOT use a local/internal domain like <code>.local</code></li>
</ul>
</li>
</ul>
<p>This guide will deploy Guacamole as a series of Docker containers - hence as long as your system can run Docker, it will be able to run Guacamole.</p>
<h1 id="prepare-your-saml-idp-azure-ad-okta">Prepare your SAML IdP (Azure AD, Okta)</h1>
<h2 id="azure-active-directory-azure-ad">Azure Active Directory (Azure AD)</h2>
<p><img src="guacaad.png" alt="guacaad"></p>
<h3 id="1-create-a-new-enterprise-application">1. Create a new Enterprise Application</h3>
<p>Log into the Azure AD <a href="https://portal.azure.com/">portal</a>, and go to “Enterprise Applications”. You may need to search for this at the top of the portal.</p>
<p><img src="1.png" alt="1"></p>
<p>Click <strong>New application</strong>.</p>
<p><img src="2.png" alt="2"></p>
<p>Click <strong>Create your own application</strong> and name the application <code>Apache Guacamole SSO</code>.</p>
<p>Select the 3rd option to create a non-gallery app: <strong>Integrate any other application you don’t find in the gallery</strong>.</p>
<p>Click <strong>Create</strong> when you are done.</p>
<p><img src="3.png" alt="3"></p>
<h3 id="2-configure-the-guacamole-enterprise-app-in-azure-ad">2. Configure the Guacamole Enterprise App in Azure AD</h3>
<p>From the left-side menu, click Properties, and set the &ldquo;<strong>Visible to Users?</strong>&rdquo; option to <strong>No</strong>.</p>
<p><img src="4.png" alt="4"></p>
<p>Next, click <strong>Single sign-on</strong> from the left-side menu, and select <strong>SAML</strong> when prompted.</p>
<p><img src="5.png" alt="5"></p>
<h3 id="3-provide-the-saml-configuration">3. Provide the SAML Configuration</h3>
<p>Under <strong>Basic SAML Configuration</strong>, click the <em>Edit</em> button and fill in the fields as follows. Substitute <code>&lt;fqdn-of-your-guacamole-instance&gt;</code> with the domain you wish to use to access the Guacamole UI. For example: <code>guac.company.com</code>:</p>
<ul>
<li><strong>Identifier (Entity ID)</strong> &ndash;&gt; <code>https://&lt;fqdn-of-your-guacamole-instance&gt;</code>
<ul>
<li>Eg: <code>https://guac.company.com</code></li>
</ul>
</li>
<li><strong>Reply URL (Assertion Consumer Service URL)</strong> &ndash;&gt; <code>https://&lt;fqdn-of-your-guacamole-instance&gt;/guacamole/api/ext/saml/callback</code>
<ul>
<li>Eg: <code>https://guac.company.com/guacamole/api/ext/saml/callback</code></li>
</ul>
</li>
</ul>
<p>Leave all the other fields blank (Sign on URL, Relay State, etc).</p>
<p>Save your configuration when done.</p>
<p><img src="6.png" alt="6"></p>
<h3 id="4-copy-the-azure-ad-metadata-url">4. Copy the Azure AD Metadata URL</h3>
<p>Scroll down. Under <em><strong>Section 3 - SAML Signing Certificate</strong></em>, note down the <strong>App Federation Metadata URL</strong>. You will need this later. This will be of the form:</p>
<pre tabindex="0"><code>https://login.microsoftonline.com/a1b2c3d4-e5f6-0a1b-2c3d-4e5f6a1b2c3d/federationmetadata/2007-06/federationmetadata.xml?appid=a1b2c3d4-e5f6-0a1b-2c3d-4e5f6a1b2c3d
</code></pre><p><img src="7.png" alt="7"></p>
<h3 id="5-add-users--groups-to-the-enterprise-application">5. Add Users &amp; Groups to the Enterprise Application</h3>
<p>The last step we need to perform in Azure AD is to assign users and/or groups to the <em>Apache Guacamole SSO</em> app to provide them with access. Any user or group added here will be permitted to SSO through to and access your Guacamole instance; so be careful!</p>
<p>From the left-side menu within the <em>Apache Guacamole SSO</em> Enterprise Application, select <strong>Users and groups</strong>, then click <strong>Add user/group</strong>.</p>
<p><img src="8.png" alt="8"></p>
<p>Select the users and/or groups that are permitted to access your Guacamole instance. Note that nested groups are not supported.</p>
<p><img src="9.png" alt="9"></p>
<p>If you are deploying Guacamole to provide clientless access for 3rd parties/contractors to access internal resources via a ZTNA solution (like Netskope NPA), then you may want to create a group/security group specifically for these individuals and assign it to the Guacamole app; for example: <code>sg-External</code>. <strong>Note down the groups you select here as these will be the same groups that you add to ZTNA policy later on</strong> in order for the users in those groups to be able to reach your instance of Guacamole in the first place.</p>
<p>Note: If you are using Azure AD&rsquo;s free tier, you might not be able to correctly use Groups. Stick to assigning individual users only.</p>
<p>After assigning users/groups and applicable roles, your user/group list should look similar to the below:</p>
<p><img src="10.png" alt="10"></p>
<h3 id="6-azure-ad-saml-configuration-finished">6. Azure AD SAML Configuration Finished</h3>
<p>You&rsquo;ve now finished the configuration in Azure AD and can proceed to installing Guacamole.</p>
<p>Don&rsquo;t forget that you will need the  <strong>App Federation Metadata URL</strong> to properly configure Guacamole, so go back and copy this down now if you haven&rsquo;t already.</p>
<p>Jump to:</p>
<ul>
<li><a href="#automated-guacamole-installation-azure-aws-gcp">Automated Guacamole Installation (AWS, Azure, GCP)</a></li>
<li><a href="#manual-gucamole-installation">Manual Guacamole Installation</a></li>
<li><a href="#toc">Table of Contents</a></li>
</ul>
<hr>
<h2 id="okta">Okta</h2>
<p><img src="guac-okta.png" alt="guac-okta"></p>
<h3 id="1-create-a-new-app-integration">1. Create a new App Integration</h3>
<p>Log in to your Okta administrator console and from the left-side menubar, navigate to <strong>Applications &gt; Applications</strong>.</p>
<p>Select <strong>Create App Integration</strong>.</p>
<p><img src="11.png" alt="11"></p>
<p>Select <strong>SAML 2.0</strong> as the sign-in method and click <strong>Next</strong>.</p>
<p><img src="12.png" alt="12"></p>
<p>On the next screen, name the application <code>Apache Gucamole SSO</code> and check both of the app visibility boxes to hide the app icon from users. Click <strong>Next</strong> when you are done on this screen.</p>
<p><img src="18.png" alt="18"></p>
<h3 id="2-configure-okta-saml-integration">2. Configure Okta SAML Integration</h3>
<p>Under <strong>SAML Settings</strong>, fill in the fields as follows. Substitute <code>&lt;fqdn-of-your-guacamole-instance&gt;</code> with the domain you wish to use to access the Guacamole UI. For example: <code>guac.company.com</code>:</p>
<ul>
<li><strong>Single sign on URL</strong> &ndash;&gt; <code>https://&lt;fqdn-of-your-guacamole-instance&gt;/guacamole/api/ext/saml/callback</code>
<ul>
<li>Eg: <code>https://guac.company.com/guacamole/api/ext/saml/callback</code>**</li>
</ul>
</li>
<li><strong>Audience URI (SP Entity ID)</strong> &ndash;&gt; <code>https://&lt;fqdn-of-your-guacamole-instance&gt;</code>
<ul>
<li>Eg: <code>https://guac.company.com</code>**</li>
</ul>
</li>
<li><strong>Name ID format</strong> &ndash;&gt; Set this to <code>EmailAddress</code></li>
</ul>
<p>Leave all the other fields blank or as their default values (Default RelayState, App username, etc).</p>
<p><img src="19.png" alt="19"></p>
<p>Scroll down and click <strong>Next</strong> when done.</p>
<p>On the next page, check the box “<em>I’m an Okta customer adding an internal app</em>” and click <strong>Finish</strong>.</p>
<h3 id="3-get-the-okta-idp-metadata-url">3. Get the Okta IdP Metadata URL</h3>
<p>On the next page, ensure you are on the <strong>Sign On</strong> tab, and click the &ldquo;<strong>View Setup Instructions</strong>&rdquo; button on the right-side of the screen. You may need to scroll down.</p>
<p><img src="20.png" alt="20"></p>
<p>Extract your <code>tenant ID</code> and <code>App ID</code> from the  <strong>Identity Provider Single Sign-On URL</strong>. This will be of the form:</p>
<pre tabindex="0"><code>https://&lt;tenant-id&gt;.okta.com/app/dev-01234567_apacheguacamolesso_1/&lt;app-id&gt;/sso/saml
</code></pre><p>For example, if your URL is:</p>
<pre tabindex="0"><code>https://dev-01234567.okta.com/app/dev-01234567_apacheguacamolesso_1/ezk5zbw26xt3cSSEC5d7/sso/saml
</code></pre><ul>
<li>The <code>tenant ID</code> is <code>dev-01234567</code></li>
<li>The <code>app ID</code> is <code>ezk5zbw26xt3cSSEC5d7</code></li>
</ul>
<p>Copy these into the below URL to form the Okta IdP Metadata URL:</p>
<pre tabindex="0"><code>https://&lt;tenant-id&gt;.okta.com/app/&lt;app-id&gt;/sso/saml/metadata
</code></pre><p>For example:</p>
<pre tabindex="0"><code>https://dev-01234567.okta.com/app/ezk5zbw26xt3cSSEC5d7/sso/saml/metadata
</code></pre><p><img src="22.png" alt="22"></p>
<p><strong>Note down this URL! You will need it to configure Guacamole later.</strong></p>
<p>You will know your URL is correct if you visit it in your browser and it loads a bunch of XML:</p>
<p><img src="23.png" alt="23"></p>
<h3 id="4-add-users--groups-to-the-application">4. Add Users &amp; Groups to the Application</h3>
<p>The last step we need to perform in Okta is to assign users and/or groups to the <em>Apache Guacamole SSO</em> app to provide them with access. Any user or group added here will be permitted to SSO through to and access your Guacamole instance; so be careful!</p>
<p>Click on the <strong>Assignments</strong> tab within the <em>Apache Guacamole SSO</em> app. Use the <strong>Assign</strong> button to select either the individual users or groups that are permitted to access your Guacamole instance.</p>
<p><img src="21.png" alt="21"></p>
<p>If you are deploying Guacamole to provide clientless access for 3rd parties/contractors to access internal resources via a ZTNA solution (like Netskope NPA), then you may want to create a group/security group specifically for these individuals and assign it to the Guacamole app; for example: <code>sg-External</code>. <strong>Note down the groups you select here as these will be the same groups that you add to ZTNA policy later on</strong> in order for the users in those groups to be able to reach your instance of Guacamole in the first place.</p>
<h3 id="5-okta-configuration-finished">5. Okta Configuration Finished</h3>
<p>You&rsquo;ve now finished the configuration in Okta and can proceed to installing Guacamole.</p>
<p>Don&rsquo;t forget that you will need the  <strong>Okta IdP Metadata URL</strong> that you created to properly configure Guacamole, so go back and copy it down if you haven&rsquo;t already.</p>
<p>Jump to:</p>
<ul>
<li><a href="#automated-guacamole-installation-azure-aws-gcp">Automated Guacamole Installation (AWS, Azure, GCP)</a></li>
<li><a href="#manual-gucamole-installation">Manual Guacamole Installation</a></li>
<li><a href="#">Table of Contents</a></li>
</ul>
<hr>
<h1 id="automated-guacamole-installation-azure-aws-gcp">Automated Guacamole Installation (Azure, AWS, GCP)</h1>
<p>We can piggyback onto the <code>cloud-init</code> process that is used to configure a fresh VM in public cloud environments (AWS, Azure, GCP, etc) and tell it to also bring up Guacamole at the same time.</p>
<h2 id="1-get-the-config-file">1. Get the Config File</h2>
<p>Copy the content of this file into a text editor like VS Studio or Atom: <a href="https://github.com/nathancatania/guacamole-sso-cloud-init/blob/main/user-data.yml">https://github.com/nathancatania/guacamole-sso-cloud-init/blob/main/user-data.yml</a></p>
<p>If you are wondering what this configuration does, see the <strong>Manual Guacamole Installation</strong> section of this guide. It wraps every step up into one script that is automatically applied on boot of a fresh VM.</p>
<p>You can also review the <a href="https://github.com/nathancatania/guacamole-sso-cloud-init">git repo for it here</a>.</p>
<h2 id="2-configure-the-required-settings">2. Configure the Required Settings</h2>
<p>Before you can use the <code>user-data.yml</code> file to configure your VM, there are some values you will need to set/change.</p>
<p><strong>As a minimum, you MUST set the FQDN and Metadata URL:</strong></p>
<ul>
<li>The FQDN is the domain you&rsquo;ve chosen to access your Gucamole instance at. This should be the same one you used in your SAML IdP configuration, eg: <code>guac.company.com</code></li>
<li>The Metadata URL is obtained from the IdP (see the instructions for Azure AD or Okta above).</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># {# ####### START SETTINGS ####### #}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# REQUIRED - Provide the FQDN that Guacamole will be accessed at! #}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# Leaving this as the default value will generate SSL certs for guac.company.local which you don&#39;t want! #}</span>
</span></span><span style="display:flex;"><span>{<span style="color:#ae81ff">% set fqdn = &#34;guac.company.local&#34; %}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# REQUIRED - IdP (Azure AD / Okta) Metadata URL #}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# Leaving this as the default value cause the SSO module to fail! #}</span>
</span></span><span style="display:flex;"><span>{<span style="color:#ae81ff">% set metadata_url = &#34;https://example.com/metadata.xml&#34; %}</span>
</span></span></code></pre></div><p>It is also recommended that you set the following:</p>
<ul>
<li>Change the default database password from something other than the default value. This database is used to store Guacamole configuration data.</li>
<li>Assign an SSH key for the default user (<code>guacamole</code>). You can also optionally change the default user from <code>guacamole</code> to something else.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># {# RECOMMENDED - Change the default Guacamole DB password #}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# The Guacamole DB is used to store settings/config data #}</span>
</span></span><span style="display:flex;"><span>{<span style="color:#ae81ff">% set dbpass = &#34;Y0u%$h0UlD%R3@Lly%CH@ng3%tH1$%P@$sW0rD&#34; %}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# OPTIONAL - Import an SSH key from a public keyserver (GitHub). Enter your GitHub username, eg: &#34;nathancatania&#34; #}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# Leave default if not needed #}</span>
</span></span><span style="display:flex;"><span>{<span style="color:#ae81ff">% set gh_identity = &#34;username&#34; %}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# OPTIONAL - Add an authorized public SSH key to permit access to the Publisher host via npa username #}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# Leave default if not needed #}</span>
</span></span><span style="display:flex;"><span>{<span style="color:#ae81ff">% set ssh_key = &#34;ssh-rsa AAAABBBBCCCC...&#34; %}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# OPTIONAL - Set the default user/username for the system. This will be who you first SSH to the VM as #}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {# Default: guacamole@vm-hostname #}</span>
</span></span><span style="display:flex;"><span>{<span style="color:#ae81ff">% set default_user = &#34;guacamole&#34; %}</span>
</span></span></code></pre></div><h2 id="3-paste-the-entire-configuration">3. Paste the entire configuration</h2>
<p>When you are done, paste the entire configuration into the <strong>User-Data</strong>, <strong>Custom Data</strong>, or <strong>Metadata</strong> fields when configuring a fresh Ubuntu VM on AWS/Azure/GCP. For specific instructions for each cloud provider, <a href="https://github.com/nathancatania/publisher-cloud-init#how-do-i-use-this">see here</a>.</p>
<p>Finish provisioning as per the normal workflow for AWS/Azure/GCP.</p>
<h2 id="4-deployment-finish">4. Deployment Finish</h2>
<p>When your fresh VM comes up, even if you can SSH to it, <code>cloud-init</code> will still be running and executing our configuration in the background. You may need to wait up to 10 minutes for <code>cloud-init</code> to finish.</p>
<p>To check the status of <code>cloud-init</code>, run the command <code>cloud-init status</code>:</p>
<pre tabindex="0"><code>npa@i-097b1b0c65d4ef774:~$ cloud-init status
status: done
</code></pre><p>If the status shows <code>status: running</code>, cloud-init is still configuring the VM.</p>
<p>The configuration will be successfully complete if you can run the <code>docker ps</code> command and see multiple containers present.</p>
<pre tabindex="0"><code>guacamole@guactest:~$ docker ps
CONTAINER ID   IMAGE   NAME
c28788e9970e   guacamole/guacamole:1.4.0   guacamole
642b183e2dba   caddy:2.5.2                 caddy
1b41e5548211   guacamole/guacd:1.4.0       guacd
57acc7868cb7   mariadb/server:latest       guacdb
</code></pre><p>If the <code>cloud-init status</code> command returns <code>status: done</code>, but you don&rsquo;t see any containers (or if Guacamole is not accessible); <a href="https://github.com/nathancatania/guacamole-sso-cloud-init#validation--troubleshooting-steps">troubleshooting steps are covered in the git repo here</a>.</p>
<p>Jump to:</p>
<ul>
<li><a href="#access-your-guacamole-instance">Access your Guacamole Instance</a></li>
<li><a href="https://github.com/nathancatania/guacamole-sso-cloud-init#validation--troubleshooting-steps">Troubleshooting Cloud-Init (GitHub)</a></li>
<li><a href="#troubleshooting">Troubleshooting Guacamole</a></li>
<li><a href="#">Table of Contents</a></li>
</ul>
<hr>
<h1 id="manual-gucamole-installation">Manual Gucamole Installation</h1>
<p>If you are deploying outside of an IaaS environment (VMware, KVM, etc), or if you&rsquo;d rather configure things yourself (or at least understand what the scripts above are doing), then read on below.</p>
<h2 id="1-install-docker--docker-compose">1. Install Docker &amp; Docker Compose</h2>
<p>If you&rsquo;re using a fresh VM, you&rsquo;ll need to install Docker and Docker Compose. The below will install Docker CE (Community Edition), which is free but does not come with support. For a production environment, I recommend Docker Enterprise.</p>
<p>The commands below cover the installation of Docker on an Ubuntu host. <strong>For RHEL 8+, you will need to use Podman instead of Docker (#justredhatthings).</strong></p>
<h3 id="a-note-for-netskope-users">A Note for Netskope Users</h3>
<p>If you are planning on running Guacamole on the same host as an NPA Publisher, and the Publisher was deployed using the OVA or AWS/Azure Marketplace image: You only need to install Docker Compose - Docker itself will already be installed.</p>
<p>You should consider deploying Guacamole on it&rsquo;s own dedicated Publisher if you go down this route.</p>
<h3 id="installing-docker">Installing Docker</h3>
<ol>
<li>Update the existing packages on the system:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt update -y <span style="color:#f92672">&amp;&amp;</span> sudo apt upgrade -y
</span></span></code></pre></div><ol start="2">
<li>Install Docker</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://get.docker.com -o get-docker.sh
</span></span><span style="display:flex;"><span>sudo sh get-docker.sh
</span></span></code></pre></div><p>Note: You should never run a script from the internet with sudo without vetting it first. Docker make information on the installation script <a href="https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script">available here</a>. Alternatively, if you wish to run the installation commands manually yourself, <a href="https://docs.docker.com/engine/install/#server">see here</a>.</p>
<ol start="3">
<li>(Optional) Allow the <code>docker</code> command to be used without <code>sudo</code>. You will need to log out of the system and back in again for the change to take effect.</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo usermod -aG docker <span style="color:#e6db74">${</span>USER<span style="color:#e6db74">}</span>
</span></span></code></pre></div><h3 id="installing-docker-compose">Installing Docker Compose</h3>
<p>If you just installed Docker via the above, you will already have Docker Compose installed.</p>
<p>If not, install Docker Compose using the below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt update -y <span style="color:#f92672">&amp;&amp;</span> sudo apt upgrade -y <span style="color:#f92672">&amp;&amp;</span> sudo apt install docker-compose-plugin
</span></span></code></pre></div><p>If (for whatever reason) the above does not work for you, you can also manually download and install the Docker Compose binary, although note that this will change the command from <code>docker compose</code> to <code>docker-compose</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>DOCKER_CONFIG<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>DOCKER_CONFIG<span style="color:#66d9ef">:-</span>$HOME/.docker<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p $DOCKER_CONFIG/cli-plugins
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>curl -SL https://github.com/docker/compose/releases/download/v2.6.1/docker-compose-linux-x86_64 -o DOCKER_CONFIG/cli-plugins/docker-compose
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chmod +x $DOCKER_CONFIG/cli-plugins/docker-compose
</span></span></code></pre></div><p>Validate Docker Compose is installed:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker compose version
</span></span><span style="display:flex;"><span>&gt; Docker Compose version v2.6.0
</span></span></code></pre></div><h2 id="2-create-folders-to-store-container-data">2. Create Folders to Store Container Data</h2>
<p>Once Docker is installed, we need to create the folders that will house that data and configuration for our containers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir -p $HOME/configs/guacdb <span style="color:#f92672">&amp;&amp;</span> mkdir -p $HOME/configs/caddy <span style="color:#f92672">&amp;&amp;</span> mkdir -p $HOME/configs/guac/extensions
</span></span></code></pre></div><h2 id="3-create-the-docker-compose-file">3. Create the Docker Compose File</h2>
<p><code>docker-compose.yml</code> is a manifest of the containers, networks, and volumes used to bring up a complete service.</p>
<p>Open a text editor and create a file called <code>docker-compose.yml</code>:</p>
<pre tabindex="0"><code>nano ~/docker-compose.yml
</code></pre><p>Paste the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#39;3.9&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">networks</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">web</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">internal</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">guacdb</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env_file</span>: <span style="color:#ae81ff">.env</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">guacdb</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#39;mariadb/server:latest&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">unless-stopped</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">environment</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_ROOT_PASSWORD</span>: <span style="color:#e6db74">&#39;${ROOTDBPASS}&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_DATABASE</span>: <span style="color:#e6db74">&#39;${DB}&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_USER</span>: <span style="color:#e6db74">&#39;${DBUSER}&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_PASSWORD</span>: <span style="color:#e6db74">&#39;${DBPASS}&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/guacdb:/docker-entrypoint-initdb.d:ro&#39;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/guacdb:/var/lib/mysql&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">networks</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">internal</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">guacd</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env_file</span>: <span style="color:#ae81ff">.env</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">guacd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#ae81ff">guacamole/guacd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">unless-stopped</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">networks</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">internal</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">guacamole</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env_file</span>: <span style="color:#ae81ff">.env</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">guacamole</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#39;guacamole/guacamole:latest&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">unless-stopped</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/guac:/etc/guacamole&#39;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/guac/server.xml:/usr/local/tomcat/conf/server.xml&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;8080&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">environment</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">GUACD_HOSTNAME</span>: <span style="color:#e6db74">&#34;guacd&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">EXTENSION_PRIORITY</span>: <span style="color:#e6db74">&#34;saml&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">SKIP_IF_UNAVAILABLE</span>: <span style="color:#e6db74">&#34;saml&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">GUACAMOLE_HOME</span>: <span style="color:#e6db74">&#39;/etc/guacamole&#39;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_HOSTNAME</span>: <span style="color:#e6db74">&#34;guacdb&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_DATABASE</span>: <span style="color:#e6db74">&#34;${DB}&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_USER</span>: <span style="color:#e6db74">&#34;${DBUSER}&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">MYSQL_PASSWORD</span>: <span style="color:#e6db74">&#34;${DBPASS}&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">depends_on</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">guacdb</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">guacd</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">networks</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">internal</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">caddy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env_file</span>: <span style="color:#ae81ff">.env</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">caddy</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#39;caddy:latest&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">unless-stopped</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;80:80&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;443:443&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/caddy/Caddyfile:/etc/caddy/Caddyfile&#39;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/caddy/data:/data&#39;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/caddy/config:/config&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">networks</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">web</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">internal</span>
</span></span></code></pre></div><p>Press <code>CTRL+X</code> to exit and <code>Y</code> to save changes.</p>
<h3 id="container-information">Container Information</h3>
<p>Guacamole itself requires 3 containers (<code>guacdb</code>, <code>guacd</code>, <code>guacamole</code>), and in addition we will be using Caddy as a reverse proxy to handle SSL for the Guacamole UI.</p>
<table>
<thead>
<tr>
<th>Container</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>guacdb</code></td>
<td>The SQL database where our Guacamole config will be stored</td>
</tr>
<tr>
<td><code>guacd</code></td>
<td>The main Guacamole service responsible for facilitating access between our browser window and backend SSH/RDP services</td>
</tr>
<tr>
<td><code>guacamole</code></td>
<td>The guacamole admin interface</td>
</tr>
<tr>
<td><code>caddy</code></td>
<td>A reverse proxy used to uplift the Guacamole UI to SSL/HTTPS</td>
</tr>
</tbody>
</table>
<h3 id="network-information">Network Information</h3>
<p>The compose file creates two Docker networks:</p>
<ul>
<li><code>internal</code> - Interconnects the Guacamole and Caddy containers together - not accessible to the outside world.</li>
<li><code>web</code> - Exposes the Caddy reverse proxy on the host so that we can send it requests and access the Guacamole UI.</li>
</ul>
<h2 id="4-create-the-env-config-file">4. Create the <code>.env</code> Config File</h2>
<p>Our <code>docker-compose.yml</code> file contains a number of variables that we need to set to ensure the service functions correctly. We can set these environmental variables in a hidden file called <code>.env</code> that will sit in the same directory as our <code>docker-compose.yml</code> file.</p>
<p>Create the <code>.env</code> file:</p>
<pre tabindex="0"><code>nano ~/.env
</code></pre><p>Paste the following; changing the <code>ROOTDBPASS</code> and <code>DBPASS</code> fields to something different (these are used to secure the SQL database which contains our Guacamole configuration).</p>
<pre tabindex="0"><code>BASEDIR=$HOME/configs

# Database
ROOTDBPASS=Y0u%$h0UlD%R3@Lly%CH@ng3%tH1$%P@$sW0rD
DBPASS=Y0u%$h0UlD%CH@ng3%tH1$%P@$sW0rD
DB=guacdb
DBUSER=guacdbuser
</code></pre><p>Press <code>CTRL+X</code> to exit and <code>Y</code> to save changes.</p>
<h2 id="5-create-the-caddyfile">5. Create the Caddyfile</h2>
<p>A <code>Caddyfile</code> contains the configuration that Caddy will use to reverse proxy the Guacamole UI and uplift it to SSL.</p>
<p>Create the <code>Caddyfile</code></p>
<pre tabindex="0"><code>nano ~/configs/caddy/Caddyfile
</code></pre><p>Paste and edit the following:</p>
<pre tabindex="0"><code>guac.company.com {
    reverse_proxy guacamole:8080 {
        trusted_proxies private_ranges
        flush_interval -1
    }
    tls internal
}
www.guac.company.com {
    redir https://guac.company.com{uri}
    tls internal
}
</code></pre><p>Replace the 3 instances of <code>guac.company.com</code> with the FQDN you wish to use to access the Guacamole UI. <strong>This must be resolve to the IP of the VM that is running Caddy, so ensure you have appropriate DNS entries in place!</strong> Caddy will automatically generate SSL certificates for this domain and serve it up over HTTPS.</p>
<p>When you are finished, press <code>CTRL+X</code> to exit and <code>Y</code> to save.</p>
<h3 id="self-signed-or-ca-signed-ssl">Self-Signed or CA Signed SSL?</h3>
<p>By default, Caddy will generate and use self-signed SSL certificates to secure the Guacamole UI. This is perfectly fine, but if you&rsquo;re accessing Guacamole directly, this will result in an untrusted SSL error in your browser - nothing to worry about, as we trust the backend service in this case, but this can be annoying.</p>
<p>If you will be using a clientless ZTNA service (like NPA Browser Access) to access Guac, then you can disregard these SSL warnings, as the ZTNA service&rsquo;s own reverse proxy should be able to ignore any self-signed certificate warnings.</p>
<p><a href="#appendix-use-signed-ssl-certificates-with-caddy">See the appendix</a> at the end of this guide if you wish to use valid SSL certs signed by an appropriate root CA.</p>
<h2 id="6-create-the-guacamoleproperties-configuration-file">6. Create the <code>guacamole.properties</code> configuration file</h2>
<p><code>gucamole.properties</code> contains configuration that will tell Gucamole to use SAML for authentication and information about the IdP to be used (eg: Azure AD, Okta)</p>
<p>Create <code>guacamole.properties</code>:</p>
<pre tabindex="0"><code>nano ~/configs/guac/guacamole.properties
</code></pre><p>Paste and edit the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># SAML Metadata URL from IdP (Azure AD, Okta, etc)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">saml-idp-metadata-url</span>: <span style="color:#ae81ff">&lt;metadata-URL-from-AzureAD-or-Okta&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Alternative: Single Sign On URL</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># saml-idp-url: https://login.microsoftonline.com/a1b2c3d4-e5f6-0a1b-2c3d-4e5f6a1b2c3d/saml2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># These must match what was entered into Azure AD or Okta</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">saml-entity-id</span>: <span style="color:#ae81ff">https://guac.company.com</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">saml-callback-url</span>: <span style="color:#ae81ff">https://guac.company.com/guacamole/</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Change this to true if SSO is not working</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">saml-debug</span>: <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Automatically redirect to SSO portal for sign-on</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">extension-priority</span>: <span style="color:#ae81ff">saml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Alternative: Go to Guacamole local login before SSO</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># extension-priority: *, saml</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># SAML attribute/claim for group membership</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">saml-group-attribute</span>: <span style="color:#ae81ff">groups</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># If SAML extension fails, default back to local login</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">skip-if-unavailable</span>: <span style="color:#ae81ff">saml</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">saml-strict</span>: <span style="color:#66d9ef">false</span>
</span></span></code></pre></div><p>A description of the required values for each of these fields is below:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>saml-idp-metadata-url</code></td>
<td>The URL of the XML metadata file that from the SAML IdP (eg: Azure AD, Okta) that contains all of the information the SAML extension needs in order to know how to authenticate with the IdP. For <strong>Azure AD</strong> this is the <em><strong>App Federation Metadata URL</strong></em>. For Okta, this is the <strong>IdP Metadata URL</strong> that you created.</td>
</tr>
<tr>
<td><code>saml-idp-url</code></td>
<td>This field is ignored if you use the above metadata file. If you don&rsquo;t have a metadata file, you can specify the URL here that Guacamole will use to redirect to when requesting SAML authentication. For <strong>Azure AD</strong>, this is the &ldquo;<em><strong>Login URL</strong></em>&rdquo;. For <strong>Okta</strong>, this is the &ldquo;<em><strong>Identity Provider Single Sign-On URL</strong></em>&rdquo;. Always use a metadata file if available.</td>
</tr>
<tr>
<td><code>saml-entity-id</code></td>
<td>The entity ID of the Guacamole SAML client. This must match what was entered into Azure AD or Okta and will be the FQDN you used in the Caddyfile. Eg: <code>https://guac.company.com</code></td>
</tr>
<tr>
<td><code>saml-callback-url</code></td>
<td>The URL that the IdP will use once authentication has succeeded to return the user to the Guacamole app. This must match what was entered into Azure AD or Okta and will be the FQDN you used in the Caddyfile, followed by <code>/guacamole/</code>. Eg: <code>https://guac.company.com/guacamole/</code></td>
</tr>
<tr>
<td><code>saml-group-attribute</code></td>
<td>The name of the attribute/claim provided by the SAML IdP that contains group membership of the user. These groups will be parsed and used to map group membership of the user logging in, which can be used for permissions management within Guacamole. This is optional and defaults to <code>groups</code></td>
</tr>
<tr>
<td><code>saml-debug</code></td>
<td>If you are having issues with your SAML configuration, set this to <code>true</code>. The Guacamole logs will then contain additional information to help you troubleshoot.</td>
</tr>
<tr>
<td><code>extension-priority</code></td>
<td>Set this to <code>saml</code>. If you want your users to hit the local login screen for Guacamole and have the option of using SSO, set this to <code>*, saml</code></td>
</tr>
<tr>
<td><code>skip-if-unavailable</code></td>
<td>If the SAML module for Guacamole fails to load or encounters an error, Guac will redirect to the local login page so an administrator can still access the UI.</td>
</tr>
</tbody>
</table>
<h2 id="7-download-the-saml-extension-for-guacamole">7. Download the SAML extension for Guacamole</h2>
<p>Select the latest version of the SSO extension for Gucamole (currently 1.4.0):</p>
<pre tabindex="0"><code>wget https://dlcdn.apache.org/guacamole/1.4.0/binary/guacamole-auth-sso-1.4.0.tar.gz
</code></pre><p>For newer releases, see here: <a href="https://guacamole.apache.org/releases/">https://guacamole.apache.org/releases/</a></p>
<p>Extract the archive:</p>
<pre tabindex="0"><code>tar -xvf guacamole-auth-sso-1.4.0.tar.gz
</code></pre><p>Copy the <code>.jar</code> file inside the <code>saml</code> directory of the archive to <code>~/configs/guac/extensions</code></p>
<pre tabindex="0"><code>cp guacamole-auth-sso-1.4.0/saml/guacamole-auth-sso-saml-1.4.0.jar $HOME/configs/guac/extensions
</code></pre><h2 id="8-initialize-the-database">8. Initialize the database</h2>
<p>We need to initialize Gucamole&rsquo;s configuration database first before bringing up the service, or it will fail. Luckily we can do this in one simple command:</p>
<pre tabindex="0"><code>docker run --rm guacamole/guacamole:latest /opt/guacamole/bin/initdb.sh --mysql &gt; $HOME/configs/guacdb/guacdb.sql
</code></pre><h2 id="9-update-the-config-file-for-tomcat">9. Update the config file for Tomcat</h2>
<p>Because the Gucamole service will be behind a reverse proxy (Caddy), every user that connects to the service will appear to be coming from the same IP address (the IP of the Caddy container).</p>
<p>The original IP address of the user will be added to the header of the HTTP request by Caddy however, and we can tell Tomcat (the service Guacamole uses for its interface) to use this when logging the IP addresses of users that connect to Guacamole.</p>
<p>We will take the original <code>server.xml</code> file that Tomcat uses and append the following under the <code>&lt;host&gt;</code> section:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;Valve</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.valves.RemoteIpValve&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#a6e22e">remoteIpHeader=</span><span style="color:#e6db74">&#34;x-forwarded-for&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#a6e22e">remoteIpProxiesHeader=</span><span style="color:#e6db74">&#34;x-forwarded-by&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#a6e22e">protocolHeader=</span><span style="color:#e6db74">&#34;x-forwarded-proto&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span></code></pre></div><p>Create the <code>server.xml</code> file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>nano $HOME/configs/guac/server.xml
</span></span></code></pre></div><p>Paste in the following (no edits required):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#75715e">&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">&lt;!--
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  Licensed to the Apache Software Foundation (ASF) under one or more
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  contributor license agreements.  See the NOTICE file distributed with
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  this work for additional information regarding copyright ownership.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  The ASF licenses this file to You under the Apache License, Version 2.0
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  (the &#34;License&#34;); you may not use this file except in compliance with
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  the License.  You may obtain a copy of the License at
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">      http://www.apache.org/licenses/LICENSE-2.0
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  Unless required by applicable law or agreed to in writing, software
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  See the License for the specific language governing permissions and
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  limitations under the License.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">--&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;Server</span> <span style="color:#a6e22e">port=</span><span style="color:#e6db74">&#34;8005&#34;</span> <span style="color:#a6e22e">shutdown=</span><span style="color:#e6db74">&#34;SHUTDOWN&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;Listener</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.startup.VersionLoggerListener&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">&lt;!-- APR library loader. Documentation at /docs/apr.html --&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;Listener</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.core.AprLifecycleListener&#34;</span> <span style="color:#a6e22e">SSLEngine=</span><span style="color:#e6db74">&#34;on&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">&lt;!-- Prevent memory leaks due to use of particular java/javax APIs--&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;Listener</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.core.JreMemoryLeakPreventionListener&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;Listener</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;Listener</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.core.ThreadLocalLeakPreventionListener&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;GlobalNamingResources&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;Resource</span> <span style="color:#a6e22e">name=</span><span style="color:#e6db74">&#34;UserDatabase&#34;</span> <span style="color:#a6e22e">auth=</span><span style="color:#e6db74">&#34;Container&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">type=</span><span style="color:#e6db74">&#34;org.apache.catalina.UserDatabase&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">description=</span><span style="color:#e6db74">&#34;User database that can be updated and saved&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">factory=</span><span style="color:#e6db74">&#34;org.apache.catalina.users.MemoryUserDatabaseFactory&#34;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">pathname=</span><span style="color:#e6db74">&#34;conf/tomcat-users.xml&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;/GlobalNamingResources&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;Service</span> <span style="color:#a6e22e">name=</span><span style="color:#e6db74">&#34;Catalina&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;Connector</span> <span style="color:#a6e22e">port=</span><span style="color:#e6db74">&#34;8080&#34;</span> <span style="color:#a6e22e">protocol=</span><span style="color:#e6db74">&#34;HTTP/1.1&#34;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#a6e22e">connectionTimeout=</span><span style="color:#e6db74">&#34;20000&#34;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#a6e22e">URIEncoding=</span><span style="color:#e6db74">&#34;UTF-8&#34;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#a6e22e">redirectPort=</span><span style="color:#e6db74">&#34;8443&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;Engine</span> <span style="color:#a6e22e">name=</span><span style="color:#e6db74">&#34;Catalina&#34;</span> <span style="color:#a6e22e">defaultHost=</span><span style="color:#e6db74">&#34;localhost&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;Realm</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.realm.LockOutRealm&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;Realm</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.realm.UserDatabaseRealm&#34;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#a6e22e">resourceName=</span><span style="color:#e6db74">&#34;UserDatabase&#34;</span><span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;/Realm&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;Host</span> <span style="color:#a6e22e">name=</span><span style="color:#e6db74">&#34;localhost&#34;</span>  <span style="color:#a6e22e">appBase=</span><span style="color:#e6db74">&#34;webapps&#34;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#a6e22e">unpackWARs=</span><span style="color:#e6db74">&#34;true&#34;</span> <span style="color:#a6e22e">autoDeploy=</span><span style="color:#e6db74">&#34;true&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;Valve</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.valves.AccessLogValve&#34;</span> <span style="color:#a6e22e">directory=</span><span style="color:#e6db74">&#34;logs&#34;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#a6e22e">prefix=</span><span style="color:#e6db74">&#34;localhost_access_log&#34;</span> <span style="color:#a6e22e">suffix=</span><span style="color:#e6db74">&#34;.txt&#34;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#a6e22e">pattern=</span><span style="color:#e6db74">&#34;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;Valve</span> <span style="color:#a6e22e">className=</span><span style="color:#e6db74">&#34;org.apache.catalina.valves.RemoteIpValve&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#a6e22e">remoteIpHeader=</span><span style="color:#e6db74">&#34;x-forwarded-for&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#a6e22e">remoteIpProxiesHeader=</span><span style="color:#e6db74">&#34;x-forwarded-by&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#a6e22e">protocolHeader=</span><span style="color:#e6db74">&#34;x-forwarded-proto&#34;</span> <span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;/Host&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/Engine&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;/Service&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/Server&gt;</span>
</span></span></code></pre></div><p>Press <code>CTRL+X</code> to save and <code>Y</code> to confirm.</p>
<h2 id="10-bring-up-the-guacamole-instance">10. Bring up the Guacamole Instance</h2>
<p>Our configuration is done and it is finally time to bring online our Guacamole Instance. Ensure you are in the same directory as the <code>docker-compose.yml</code> file you created above and run:</p>
<pre tabindex="0"><code>docker compose up -d
</code></pre><p>Docker will pull down the latest versions of the MariaDB, Guacd, Guacamole, and Caddy containers, bring them online, and handle all of the networking for us.</p>
<p>To check everything is going smoothly, review the logs of the Gucamole container:</p>
<pre tabindex="0"><code>docker logs guacamole
</code></pre><p>Jump to:</p>
<ul>
<li><a href="#access-your-guacamole-instance">Access your Guacamole Instance</a></li>
<li><a href="#troubleshooting">Troubleshooting Guacamole</a></li>
<li><a href="#">Table of Contents</a></li>
</ul>
<hr>
<h1 id="access-your-guacamole-instance">Access your Guacamole Instance</h1>
<p>You should now be able to type into your browser <code>https://&lt;fqdn-of-your-guacamole-instance&gt;/guacamole</code> to access the Gucamole service.</p>
<p>If everything has gone well, you will be redirected to SSO with your IdP of choice. Entering valid credentials will bring you to the Gucamole UI.</p>
<p><img src="14.png" alt="14"></p>
<h2 id="common-issue-1---ssl--security-warning">Common Issue #1 - SSL / Security Warning</h2>
<p>Don&rsquo;t be alarmed if you recieve an SSL error or Security Warning: Your connection between your Browser and Guacamole is secure.</p>
<p><img src="15.png" alt="15"></p>
<p>Your&rsquo;re seeing this warning because Caddy generated a self-signed SSL certificate to secure the Guacamole UI with, and your browser doesn&rsquo;t trust it. If you want get rid of this warning, you have 3 options:</p>
<ol>
<li>Whitelist the URL of your Gucamole instance in your browser to suppress the error</li>
<li>Import the certifcate generated by Caddy (stored under <code>~/configs/caddy/data</code>) into the trusted certificate store on your machine.</li>
<li>Configure Caddy to generate trusted signed certificates using Let&rsquo;s Encrypt (see Appendix).</li>
</ol>
<h2 id="common-issue-2---error-404-page-when-accessing-guacamole">Common Issue #2 - Error 404 page when accessing Guacamole</h2>
<p>If you receive a <code>HTTP Status 404 - Not Found</code> error when accessing your Guacamole instance, this is because you need to add <code>/guacamole</code> onto the end of the URL.</p>
<p>Gucamole is accessed at: <code>https://guac.company.com/guacamole</code> NOT <code>https://guac.company.com/</code></p>
<p><img src="16.png" alt="16"></p>
<h2 id="common-issue-3---something-is-broken">Common Issue #3 - Something is broken&hellip;</h2>
<p>If you are having issues and need to validate that the UI is working OK, in the <code>guacamole.properties</code> file, change the <code>extension-priority</code> attribute to <code>*, saml</code>. You might also want to change the <code>saml-debug</code> attribute to <code>true</code> to enable more verbose SAML logging.</p>
<pre tabindex="0"><code>&gt; nano $HOME/configs/guac/guacamole.properties

[...]
extension-priority: *, saml
saml-debug: true
[...]
</code></pre><p>Don&rsquo;t forget to restart the Guacamole container for the changes to apply:</p>
<pre tabindex="0"><code>docker compose restart guacamole
</code></pre><p>This will land you on the local login page for Guacamole by default, rather than automatically redirecting you to SSO.</p>
<p><img src="17.png" alt="17"></p>
<p>You can login locally to Guacamole with the default credentials:</p>
<ul>
<li>Username: <code>guacadmin</code></li>
<li>Password: <code>guacamin</code></li>
</ul>
<hr>
<h1 id="troubleshooting">Troubleshooting</h1>
<h2 id="review-logs">Review Logs</h2>
<p>To review the Guacamole logs, run the following:</p>
<pre tabindex="0"><code>docker logs guacamole
</code></pre><p>To review the Guacd logs (the main service behind the Guacamole UI), run the following:</p>
<pre tabindex="0"><code>docker logs guacd
</code></pre><p>To review the Caddy logs (reverse proxy/SSL uplift):</p>
<pre tabindex="0"><code>docker logs caddy
</code></pre><h2 id="enable-debug-logging">Enable Debug Logging</h2>
<p>To enable debug logging, create a file called <code>logback.xml</code> under <code>$HOME/configs/guac</code>:</p>
<pre tabindex="0"><code>nano $HOME/configs/guac/logback.xml
</code></pre><p>Paste in the following (no edits required):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">&lt;!-- Appender for debugging --&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;appender</span> <span style="color:#a6e22e">name=</span><span style="color:#e6db74">&#34;GUAC-DEBUG&#34;</span> <span style="color:#a6e22e">class=</span><span style="color:#e6db74">&#34;ch.qos.logback.core.ConsoleAppender&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;encoder&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;pattern&gt;</span>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n<span style="color:#f92672">&lt;/pattern&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;/encoder&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/appender&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">&lt;!-- Log at DEBUG level --&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;root</span> <span style="color:#a6e22e">level=</span><span style="color:#e6db74">&#34;trace&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;appender-ref</span> <span style="color:#a6e22e">ref=</span><span style="color:#e6db74">&#34;GUAC-DEBUG&#34;</span><span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/root&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span></code></pre></div><p>Restart the Guacamole service:</p>
<pre tabindex="0"><code>docker compose restart guacamole
</code></pre><p>To turn off debug logging (as it is VERY verbose), simply delete the <code>logback.xml</code> file and restart the guacamole service again.</p>
<h2 id="enable-saml-logging">Enable SAML Logging</h2>
<p>If you are having issues with getting SSO/SAML to work, it can be useful to enable SAML debug logging in the <code>guacamole.properties</code> file. Set the <code>saml-debug</code> attribute to <code>true</code>:</p>
<pre tabindex="0"><code>&gt; nano $HOME/configs/guac/guacamole.properties

[...]
saml-debug: true
[...]
</code></pre><p>Restart the Guacamole container to apply the change:</p>
<pre tabindex="0"><code>docker compose restart guacamole
</code></pre><h2 id="saml-issue-1----signature-validation-failed">SAML Issue #1 -  Signature validation failed</h2>
<p>If you see the following log message:</p>
<pre tabindex="0"><code>WARN  o.a.g.a.s.a.AssertionConsumerServiceResource - Authentication attempted with an invalid SAML response: SAML response did not pass validation: Signature validation failed. SAML Response rejected
</code></pre><p>The SAML response from your IdP is signed, but Guacamole can&rsquo;t make sense of it because it isn&rsquo;t aware of the X.509 certificate used by the IdP to sign it.</p>
<p>You have likely configured SAML by NOT using a metadata file (as these contain the certificate needed), and instead have used the <code>saml-idp-url</code> attribute in your <code>guacamole.properties</code> file. Guacamole also needs the certificate from your IdP, but unfortunately doesn&rsquo;t include a way to specify this in config.</p>
<p>To solve this, use the XML metadata file provided by your IdP (<code>saml-idp-metadata-url</code> attribute in <code>guacamole.properties</code>) instead of using the <code>saml-idp-url</code> field.</p>
<p>For Azure AD, the metadata file is called the App Federation Metadata URL.</p>
<p>For Okta, it can be tricky to find in the UI, but is available at the following URL:</p>
<pre tabindex="0"><code>https://&lt;tenant-name&gt;.okta.com/app/&lt;app-id&gt;/sso/saml/metadata
</code></pre><p>(Fill in <code>&lt;tenant-name&gt;</code> and <code>&lt;app-id&gt;</code> accordingly)</p>
<p>If you&rsquo;re using an IdP that doesn&rsquo;t provide a metadata file, you can generate one yourself by using <a href="https://www.samltool.com/idp_metadata.php">this online tool</a>. Save the metadata as an XML file called <code>metadata.xml</code> under <code>configs/guac/metadata.xml</code>. You then need to set your <code>gucamole.properties</code> file as follows:</p>
<pre tabindex="0"><code>[...]
saml-idp-metadata-url: file:///etc/guacamole/metadata.xml
[...]
</code></pre><p>Restart Guacamole for your changes to take effect.</p>
<pre tabindex="0"><code>docker compose restart gucacamole
</code></pre><h2 id="saml-issue-2---could-not-parse-saml-idp-metadata-file">SAML Issue #2 - Could not parse SAML IdP Metadata file</h2>
<p>This issue is likely because Gucamole cannot access the SAML metadata file specified in <code>guacamole.properties</code>.</p>
<ul>
<li>If this was the URL from Azure AD or Okta, then it can&rsquo;t reach the URL specified.
<ul>
<li>Make sure the VM can reach login.microsoft.com, or your Okta tenant.</li>
<li>You will need to bypass <code>login.microsoft.com</code> or <code>*.okta.com</code> from any SSL inspection mechanisms. Even if your server trusts the root CA you have installed, Gucamole/Tomcat/JDK uses it&rsquo;s own trust and does not.</li>
</ul>
</li>
<li>If you specified a local metadata file (eg: <code>saml-idp-metadataurl: file:///etc/guacamole/metadata/xml</code>), check that the file exists and the file path is correct. Also ensure that the metadata file is formatted correctly.</li>
</ul>
<p><a href="#">Back to Table of Contents</a></p>
<hr>
<h1 id="appendix-use-signed-ssl-certificates-with-caddy">Appendix: Use Signed SSL Certificates with Caddy</h1>
<p>If you have your own signed SSL certificates you want Caddy to use instead having it generate and use it&rsquo;s own ones (resulting in untrusted SSL warnings); OR if you want Caddy to use Let&rsquo;s Encrypt to automatically request signed certificates for you, then read on!</p>
<h2 id="using-your-own-root-ca-or-signed-ssl-certificate">Using your own Root CA or signed SSL certificate</h2>
<p>If you have an SSL certificate already that you would like to use, copy the certificate <code>.crt</code> and private key to <code>$HOME/configs/caddy/data</code> and ensure they have appropriate permissions.</p>
<p>Next, update your Caddyfile <code>~/configs/caddy/Caddyfile</code> as follows:</p>
<pre tabindex="0"><code>guac.company.com {
    reverse_proxy guacamole:8080 {
        trusted_proxies private_ranges
        flush_interval -1
    }
    tls /data/certificate.crt /data/private.key
}
www.guac.company.com {
    redir https://guac.company.com{uri}
    tls /data/certificate.crt /data/private.key
}
</code></pre><p>Replacing <code>certificate.crt</code> and <code>private.key</code> with the filenames of the certificate and associated private key respectively.</p>
<p>You may also need to need to specify additional options depending on how and where your certificates were generated. See the <code>tls</code> <a href="https://caddyserver.com/docs/caddyfile/directives/tls">directive page within the Caddy documentation</a> for more information.</p>
<p>Don&rsquo;t forget to restart Caddy to apply your changes:</p>
<pre tabindex="0"><code>docker compose restart caddy
</code></pre><p>You can check the Caddy logs in case any errors occur by using the following:</p>
<pre tabindex="0"><code>docker logs caddy
</code></pre><h2 id="using-lets-encrypt-to-request-signed-ssl-certificates-for-free">Using Let&rsquo;s Encrypt to request signed SSL certificates for free</h2>
<p>Caddy can automatically request and manage free signed SSL certificates from Let&rsquo;s Encrypt for you, but you must have the following in place:</p>
<ol>
<li>A non-internal TLD for Guacamole. Ie: The domain you access Guacamole on should be something like guac.company.com, and NOT guac.company.local</li>
<li>Have the DNS for the above domain hosted by a provider that allows DNS records to be managed via API; eg: Cloudflare.</li>
</ol>
<p>Let&rsquo;s Encrypt will only generate and sign certificates for public (non-internal) TLDs; eg: <code>.com</code>, <code>.net</code>, <code>.app</code>, <code>.cool</code> etc (hence #1).</p>
<p>Additionally, Let&rsquo;s Encrypt requires you to validate that you own and control the domain/server that it will be signing the certificate for,  and because our Guacamole instance is NOT exposed to the internet, our only method of validation is DNS-based validation (specifically a DNS-01 challenge) - hence #2.</p>
<p>To get the above to work, we need to build a special version of the Caddy Docker image, and provide it with a scoped API key for our DNS provider. Caddy uses this API key to insert a TXT record temporarily on Let&rsquo;s Encrypt&rsquo;s request, which validates we own the domain, and permits Let&rsquo;s Encrypt to generate and sign a certificate for us.</p>
<p>Let&rsquo;s Encrypt certificates are valid for 90 days, and Caddy will automatically handle renewal as long as the API key remains valid.</p>
<p>As Caddy has not bundled the different provider modules needed for a DNS-01 challenge into the official Docker image, we need to build our own Caddy image from scratch.</p>
<h3 id="1-build-a-new-caddy-image">1. Build a new Caddy Image</h3>
<p>First, locate the DNS provider module that you require within the <code>caddy-dns</code> repo here: <a href="https://github.com/orgs/caddy-dns/repositories">https://github.com/orgs/caddy-dns/repositories</a></p>
<p>Next, create and edit a new Dockerfile:</p>
<pre tabindex="0"><code>nano Dockerfile
</code></pre><p>Paste in and edit the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-dockerfile" data-lang="dockerfile"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> caddy:builder AS builder</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> caddy-builder <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    github.com/caddy-dns/&lt;your-dns-module&gt;<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> caddy:latest</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> --from<span style="color:#f92672">=</span>builder /usr/bin/caddy /usr/bin/caddy<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div><p>Replace <code>&lt;your-dns-module&gt;</code> with the name of the repository of your DNS providers module from github.com. I will be using Cloudflare DNS, so my Dockerfile looks as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-dockerfile" data-lang="dockerfile"><span style="display:flex;"><span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> caddy:builder AS builder</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> caddy-builder <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    github.com/caddy-dns/cloudflare<span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> caddy:latest</span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> --from<span style="color:#f92672">=</span>builder /usr/bin/caddy /usr/bin/caddy<span style="color:#960050;background-color:#1e0010">
</span></span></span></code></pre></div><p>Run the command to build the image:</p>
<pre tabindex="0"><code>docker build -t &lt;image-name&gt;:latest
</code></pre><p>Replace <code>&lt;image-name&gt;</code> with whatever you want your Caddy Docker image to be called. In my case, mine is called <code>nathancatania/caddy-cloudflare</code> as I&rsquo;ll be pushing it to my repository on Docker Hub.</p>
<h2 id="2-update-the-caddyfile">2. Update the Caddyfile</h2>
<p>We need to update our Caddy configuration and provide it with the API key details of our DNS provider.</p>
<p>Edit the existing Caddyfile:</p>
<pre tabindex="0"><code>nano ~/configs/caddy/Caddyfile
</code></pre><p>Replace it with the following:</p>
<pre tabindex="0"><code>{
    # Global options block. Entirely optional, https is on by default
    # Optional email key for lets encrypt
    email name@company.com
    
    # Optional staging lets encrypt for testing. Comment out for production.
    # acme_ca https://acme-staging-v02.api.letsencrypt.org/directory


}
guac.company.com {
    reverse_proxy guacamole:8080
    tls name@company.com {
        dns cloudflare &lt;api-key&gt;
        # resolvers 1.1.1.1
    }
}
www.guac.company.com {
    redir https://guac1.lightwave.cloud{uri}
    tls name@company.com {
        dns cloudflare &lt;api-key&gt;
        # resolvers 1.1.1.1
    }
}
</code></pre><p>Your configuration will vary!</p>
<p>Replace:</p>
<ul>
<li><code>email name@company.com</code> with your own email address. This is used for Let&rsquo;s Encrypt notifications.</li>
<li><code>guac.company.com</code> with the domain used to host your Guacamole instance. This is the domain you will be receiving a signed SSL certificate for.</li>
</ul>
<p>To test, you should uncomment the <code># acme_ca https://acme-staging-v02.api.letsencrypt.org/directory</code> part of the configuration to use Let&rsquo;s Encrypt&rsquo;s test server. The proper server that issues signed certificates is rate limited, and you can lock yourself out if you request a signed certificate too many times with incorrect configuration.</p>
<p>Note the <code>tls</code> directive blocks. These will be different depending on the DNS provider you use. Check the GitHub repo for the Caddy-dns module you selected for documenation on what needs to be included in this block.</p>
<p>For example, for Azure DNS, your <code>tls</code> directive will look as follows:</p>
<pre tabindex="0"><code>tls {
  dns azure {
    tenant_id &lt;tenant-id&gt;
    client_id &lt;azure-client-id&gt;
    client_secret &lt;azure-client-secret&gt;
    subscription_id &lt;azure-subscription-id&gt;
    resource_group_name &lt;azure-resource-group-name&gt;
  }
}
</code></pre><p>For Cloudflare DNS (which is what I am using), you will need to replace/change the following:</p>
<ul>
<li><code>tls name@company.com</code> -&gt; Replace the email here with the username of your Cloudflare account/the account that the generated API key is for.</li>
<li><code>&lt;api-key&gt;</code> with your Cloudflare API key.</li>
<li>The <code># resolver 1.1.1.1</code> can be uncommented or changed if you have DNS issues internally. This forces Caddy to use the specified DNS resolver; rather than relying on Docker DNS.</li>
</ul>
<h2 id="3-update-docker-composeyml">3. Update <code>docker-compose.yml</code></h2>
<p>We need to update the <code>docker-compose.yml</code> file and tell it to use our freshly build Caddy image, instead of the official one.</p>
<p>First, bring down your Docker services:</p>
<pre tabindex="0"><code>docker compose down
</code></pre><p>Open <code>docker-compose.yml</code></p>
<pre tabindex="0"><code>nano docker-compose.yml
</code></pre><p>Edit the <code>caddy</code> section and replace the <code>image</code> attribute with the name of your own Caddy image. In the example below, my Caddy image is called <code>nathancatania/caddy-cloudflare:latest</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span>[<span style="color:#ae81ff">...]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">caddy</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">env_file</span>: <span style="color:#ae81ff">.env</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">container_name</span>: <span style="color:#ae81ff">caddy</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">image</span>: <span style="color:#e6db74">&#39;nathancatania/caddy-cloudflare:latest&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">restart</span>: <span style="color:#ae81ff">unless-stopped</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;80:80&#34;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#34;443:443&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/caddy/Caddyfile:/etc/caddy/Caddyfile&#39;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/caddy/data:/data&#39;</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#e6db74">&#39;${BASEDIR}/caddy/config:/config&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">networks</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">web</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">internal</span>
</span></span><span style="display:flex;"><span>      
</span></span><span style="display:flex;"><span> [<span style="color:#ae81ff">...]</span>
</span></span></code></pre></div><p>Bring up your Docker services again. This time, the new Caddy image will be used:</p>
<pre tabindex="0"><code>docker compose up -d
</code></pre><p>Navigate to your Guacamole instance, or check the Caddy logs to make sure everything is working:</p>
<pre tabindex="0"><code>docker logs caddy
</code></pre><p><a href="#">Back to Table of Contents</a></p>
]]></content>
        </item>
        
        <item>
            <title>How-to Configure SSO for Netskope Cloud Exchange</title>
            <link>https://nathancatania.com/posts/sso-cloud-exchange/</link>
            <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/sso-cloud-exchange/</guid>
            <description>The thoughts and opinions in this post are my own and do not reflect those of Netskope. Please follow this guide at your own risk.
This post will cover how to configure Single-Sign-On (SSO) for the Netskope Cloud Exchange (CE) platform; specifically for Azure AD and Okta. This will allow you to manage administrator access to CE from within your existing Identity Provider (IdP), rather than configuring administrators within the platform manually.</description>
            <content type="html"><![CDATA[<blockquote>
<p>The thoughts and opinions in this post are my own and do not reflect those of Netskope. Please follow this guide at your own risk.</p>
</blockquote>
<p>This post will cover how to configure Single-Sign-On (SSO) for the Netskope Cloud Exchange (CE) platform; specifically for Azure AD and Okta. This will allow you to manage administrator access to CE from within your existing Identity Provider (IdP), rather than configuring administrators within the platform manually.</p>
<p>Cloud Exchange is different from the standard Netskope tenant you would have access to as a customer and facilitates the exchange of information between your various security and operations platforms. For information on what Cloud Exchange is (including how to deploy it), please <a href="/posts/deploy-netskope-cloud-exchange">see here</a>.</p>
<h1 id="azure-active-directory-azure-ad">Azure Active Directory (Azure AD)</h1>
<p><img src="26.png" alt="26"></p>
<h2 id="create-a-new-enterprise-application">Create a new Enterprise Application</h2>
<p>Log into the Azure AD <a href="https://portal.azure.com">portal</a>, and go to &ldquo;Enterprise Applications&rdquo;. You may need to search for this at the top of the portal.</p>
<p><img src="1.png" alt="1"></p>
<p>Click <strong>New application</strong>.</p>
<p><img src="2.png" alt="2"></p>
<p>Click <strong>Create your own application</strong> and name the application <code>Netskope Cloud Exchange</code>.</p>
<p>Select the 3rd option to create a non-gallery app: <strong>Integrate any other application you don&rsquo;t find in the gallery</strong>.</p>
<p>Click <strong>Create</strong> when you are done.</p>
<p><img src="3.png" alt="3"></p>
<p>Note, that Azure can sometimes have a quirk where it returns a 404 error when you click the <strong>Create</strong> button. Your application has should have been created, even if you get this error. If you encounter this issue, return to the <strong>Enterprise Applications</strong> view and click the refresh button. You should see your <em>Netskope Cloud Exchange</em> app appear in the list, despite getting a 404.</p>
<h2 id="copy-the-cloud-exchange-sso-information">Copy the Cloud Exchange SSO information</h2>
<p>Log in to Cloud Exchange using the <code>admin</code> (super administrator) user, and navigate to <strong>Settings &gt; Users</strong> (this settings area will only be visible to the <code>admin</code> user).</p>
<p>Select the <strong>SSO Configuration</strong> tab, and toggle the <strong>SSO</strong> toggle <strong>ON</strong> (make sure you save this configuration).</p>
<p>Note down the 3x &ldquo;Service Provider&rdquo; fields at the bottom of the screen. The image below maps which URL should be used for which SAML config field in Azure AD.</p>
<p><img src="6.png" alt="6"></p>
<h2 id="create-roles-in-azure-ad">Create Roles in Azure AD</h2>
<p>Users can be assigned Read/Write or just Read access to the CE UI based on one of two roles assigned to them: <code>Admin</code> (read/write access) and <code>Read Only</code>. We need to create these roles in Azure AD so that they can be assigned to users who use the CE application.</p>
<p><strong>Note: If you don&rsquo;t create and map these roles then SSO will fail!</strong></p>
<p>Return to the <strong>main</strong> Azure Active Directory menu (ensure you are NOT within the <em>Enterprise Applications</em> sub-menu). Select <strong>App registrations</strong> from the left-side menu, click the <em><strong>All applications</strong></em> tab, then select the <strong>Netskope Cloud Exchange</strong> app from the list.</p>
<p><img src="8.png" alt="8"></p>
<p>Next, click <strong>App Roles</strong> from the left-side menu, followed by <strong>Create app role</strong>. You will be creating two roles: One for the Admin user role and one for the Read-Only user role.</p>
<p>Create the <strong>Admin</strong> role as follows:</p>
<ul>
<li>For <em><strong>Display name</strong></em>, enter <code>CE-Admin</code> (this can be whatever you like)</li>
<li>For <em><strong>Allowed member types</strong></em>, select the first option: <code>Users/Groups</code></li>
<li>For <em><strong>Value</strong></em>, enter <code>netskope-ce-write;netskope-ce-read</code> &lt;- Ensure you copy/paste this exactly!</li>
<li>For <em><strong>Description</strong></em>, enter <code>Provide the user with read/write access to Cloud Exchange.</code></li>
<li>Ensure the <em><strong>Do you want to enable this app role?</strong></em> option is <strong>checked</strong>.</li>
</ul>
<p><img src="9.png" alt="9"></p>
<p>Create the <strong>Read-Only</strong> role as follows:</p>
<ul>
<li>For <em><strong>Display name</strong></em>, enter <code>CE-ReadOnly</code> (this can be whatever you like)</li>
<li>For <em><strong>Allowed member types</strong></em>, select the first option: <code>Users/Groups</code></li>
<li>For <em><strong>Value</strong></em>, enter <code>netskope-ce-read</code> &lt;- Ensure you copy/paste this exactly!</li>
<li>For <em><strong>Description</strong></em>, enter <code>Provide the user with read-only access to Cloud Exchange.</code></li>
<li>Ensure the <em><strong>Do you want to enable this app role?</strong></em> option is <strong>checked</strong>.</li>
</ul>
<p><img src="10.png" alt="10"></p>
<p>You&rsquo;re now finished configuring the App Roles. Return to the main Azure AD menu to proceed.</p>
<h2 id="configure-the-cloud-exchange-enterprise-app-in-azure-ad">Configure the Cloud Exchange Enterprise App in Azure AD</h2>
<p>From the Azure AD main menu, return to the <em>Enterprise Applications</em> list and select <strong>Netskope Cloud Exchange</strong> to configure it.</p>
<p><img src="4.png" alt="4"></p>
<p>From the left-side menu, click <strong>Single sign-on</strong>, and select <strong>SAML</strong> when prompted.</p>
<p><img src="5.png" alt="5"></p>
<h3 id="provide-the-saml-configuration">Provide the SAML Configuration</h3>
<p>Under <strong>Basic SAML Configuration</strong>, click the <em>Edit</em> button.</p>
<p>Copy the &ldquo;Service Provider&rdquo; URLs from the Cloud Exchange SSO Configuration page to the appropriate Azure AD SAML config field. See the table below for mapping.</p>
<table>
<thead>
<tr>
<th>Azure AD SAML Field</th>
<th>Cloud Exchange Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>Identifier (Entity ID)</td>
<td>Service Provider Entity ID</td>
</tr>
<tr>
<td>Reply URL (Assertion Consumer Service URL)</td>
<td>Service Provider ACS URL</td>
</tr>
<tr>
<td>Sign on URL</td>
<td>Service Provider ACS URL</td>
</tr>
<tr>
<td>Relay State</td>
<td>N/A - Leave Blank</td>
</tr>
<tr>
<td>Logout URL</td>
<td>Service Provider SLS URL</td>
</tr>
</tbody>
</table>
<p>The <em>Reply URL</em> and <em>Sign-on URL</em> in Azure AD both use the Service Provider ACS URL from the Cloud Exchange portal. The <em>Relay State</em> field in Azure AD should be left blank.</p>
<p><img src="7.png" alt="7"></p>
<p>Save your configuration when done.</p>
<h3 id="add-claims-for-username--roles">Add Claims for Username &amp; Roles</h3>
<p>Click <strong>Edit</strong> next the <strong>Attributes &amp; Claims</strong> section (section #2)</p>
<p><img src="11.png" alt="11"></p>
<p>Click the button to <strong>Add new claim</strong>. Add a new claim as follows:</p>
<ul>
<li>For the <em>Name</em> field, enter <code>roles</code> &lt;&ndash; Enter this exactly!</li>
<li>Leave <em><strong>Namespace</strong></em> blank.</li>
<li>For <em><strong>Source</strong></em>, ensure <code>Attribute</code> is selected (default).</li>
<li>For <em><strong>Source attribute</strong></em>, select <code>user.assignedroles</code> from the dropdown.</li>
</ul>
<p>Click <strong>Save</strong> to add the claim.</p>
<p><img src="12.png" alt="12"></p>
<p>Repeat the process to add a recond role:</p>
<ul>
<li>For the <em>Name</em> field, enter <code>username</code> &lt;&ndash; Enter this exactly!</li>
<li>Leave <em><strong>Namespace</strong></em> blank.</li>
<li>For <em><strong>Source</strong></em>, ensure <code>Attribute</code> is selected (default).</li>
<li>For <em><strong>Source attribute</strong></em>, select <code>user.mail</code> from the dropdown.</li>
</ul>
<p>Click <strong>Save</strong> to add the claim.</p>
<p><img src="13.png" alt="13"></p>
<p>Once you&rsquo;ve added the two new claims, your Attributes &amp; Roles should look as follows:</p>
<p><img src="14.png" alt="14"></p>
<h3 id="download-the-saml-signing-certificate">Download the SAML Signing Certificate</h3>
<p>Back on the SAML configuration page, scroll down to Section 3 - <strong>SAML Signing Certificate</strong>, and click to download the <strong>Base64</strong> certificate (see the image below).</p>
<h3 id="copy-the-azure-ad-application-urls">Copy the Azure AD Application URLs</h3>
<p>Next, under Section 4 - <strong>Set up Netskope Cloud Exchange</strong>, copy the <strong>Login URL</strong>, <strong>Logout URL</strong>, and <strong>Azure AD Identifier</strong> URL. You will need to paste these into the Cloud Exchange UI in the next section.</p>
<p><img src="15.png" alt="15"></p>
<h2 id="add-users--groups-to-the-enterprise-application">Add Users &amp; Groups to the Enterprise Application</h2>
<p>The last step we need to perform in Azure AD is to assign users and/or groups to the Cloud Exchange app to provide them with access. We will also assign either the <strong>Read-Only</strong> or <strong>Admin</strong> roles we created earlier to these users/groups to grant them the appropriate permissions within CE.</p>
<p>From the left-side menu within the Cloud Exchange Enterprise Application, select <strong>Users and groups</strong>, then click <strong>Add user/group</strong>.</p>
<p><img src="16.png" alt="16"></p>
<p>Select the users and/or groups that are permitted to use the Cloud Exchange application. You <strong>MUST</strong> also assign a role to the selected users/groups; ie: <code>CE-Admin</code> (read/write), or <code>CE-ReadOnly</code> (read-only).</p>
<p><strong>WARNING: If you do not assign a role, SSO will fail when the user attempts to sign in. Also, DO NOT assign the default <code>User</code> role you see in the list: this will also cause SSO to fail. You must only use the roles that you explicitly created in Azure AD yourself.</strong></p>
<p><img src="17.png" alt="17"></p>
<p>After assigning users/groups and applicable roles, your user/group list should look similar to the below:</p>
<p><img src="18.png" alt="18"></p>
<h2 id="finish-the-sso-configuration-in-cloud-exchange">Finish the SSO Configuration in Cloud Exchange</h2>
<p>Return to the <strong>SSO Configuration</strong> section of the Cloud Exchange UI (<strong>Settings &gt; Users &gt; SSO Configuration</strong>).</p>
<h3 id="copy-the-azure-app-urls">Copy the Azure app URLs</h3>
<p>For the 3 Identity Provider URL fields in the Cloud Exchange SSO configuration, paste the corresponding Azure AD Application URLs you copied when configuring SAML on the Azure AD side. See the table below for mapping:</p>
<table>
<thead>
<tr>
<th>Cloud Exchange Field</th>
<th>Azure AD SAML Config Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>Identity Provider Issuer URL</td>
<td>Azure AD Identifier URL</td>
</tr>
<tr>
<td>Identity provider SSO URL</td>
<td>Login URL</td>
</tr>
<tr>
<td>Identity provider SLO URL</td>
<td>Logout URL</td>
</tr>
</tbody>
</table>
<p><img src="19.png" alt="19"></p>
<h3 id="copy-the-saml-signing-certificate">Copy the SAML Signing Certificate</h3>
<p>Open the Base64 SAML Signing Certificate you downloaded from Azure AD earlier in a text editor such as Notepad or TextEdit. Don&rsquo;t use MS Word. The certificate will have a <code>.cer</code> extension.</p>
<p>Copy the contents of the certificate file into the <code>Public x509 Certificate</code> field in the Cloud Exchange SSO config (see the image above).</p>
<p>Save your SSO Configuration when done.</p>
<h2 id="testing-the-sso-configuration">Testing the SSO Configuration</h2>
<p>Open a new Incognito window (to avoid any potential issues with caching) and point your browser to the URL of your Cloud Exchange deployment.</p>
<p>If you enabled the &ldquo;SSO&rdquo; checkbox as instructed at the beginning of this guide, you will two options when reaching Cloud Exchange:</p>
<ol>
<li>Login with SSO</li>
<li>Login with Username/Password</li>
</ol>
<p>Option #2 is used for local login (ie: the default <code>admin</code> user, or any user manually added to the user list in CE).</p>
<p><img src="20.png" alt="20"></p>
<p>Select <strong>Login with SSO</strong>. You should be redirected to Azure AD to sign in.</p>
<p><img src="21.png" alt="21"></p>
<p>Upon entering your user credentials, you should be authenticated and redirected to the Cloud Exchange interface. In the example below, the Adele user was assigned the <strong>CE-ReadOnly</strong> role, so almost all of the <strong>Settings</strong> menu is hidden.</p>
<p><img src="22.png" alt="22"></p>
<h2 id="troubleshooting">Troubleshooting</h2>
<p>If you are having issues signing in, first, look at which platform is giving you an error: Azure AD, or Cloud Exchange?
If the error you are presented with is from Azure AD, then there is likely an issue with your config on the Azure AD side. Double-check your URLs and/or whether the user you are attempting to sign in as is assigned to the application (or present in the group assigned to the app).</p>
<p>In the image below, my <code>nathan@lightwave.cloud</code> user was unable to sign in, as they were not assigned to the application in Azure AD.</p>
<p><img src="23.png" alt="23"></p>
<p>If you are getting an error from Cloud Exchange, then you have likely stuffed up the URLs entered into either CE or Azure AD, not added the custom <code>username</code> and <code>roles</code> claims in Azure AD, or not assigned any roles to the user you are signing in as.</p>
<p>If you get the error <code>{&quot;detail&quot;:&quot;Method Not Allowed&quot;}</code>, check that the URLs copied into both Azure AD and Cloud Exchange are correct and in the right place.</p>
<p>If you get the error <code>{&quot;detail&quot;:&quot;Could not authenticate. username/roles attribute not set.&quot;}</code>, then check that you added the <code>username</code> and <code>roles</code> claims in the SAML config, AND assigned roles correctly to users when you added them to the Enterprise Application in Azure AD.</p>
<p><img src="24.png" alt="24"></p>
<p>If you pass SSO fine but receive a red <code>Error while fetching data</code> message in CE, then there is a problem with the role you have assigned to the user. Ensure you entered <code>netskope-ce-write;netskope-ce-read</code> as the attribute for the Admin role (CE-Admin) and <code>netskope-ce-read</code> as the attribute for the Read-Only role (CE-ReadOnly). Additionally, check that you have assigned one of these roles to your impacted user: You may also get this error if the default <code>User</code> role is assigned.</p>
<p><img src="25.png" alt="25"></p>
<hr>
<h1 id="okta">Okta</h1>
<p><img src="27.png" alt="27"></p>
<h2 id="create-a-new-app-integration">Create a new App Integration</h2>
<p>Log in to your Okta administrator console and from the left-side menubar, navigate to <strong>Applications &gt; Applications</strong>.</p>
<p>Select <strong>Create App Integration</strong>.</p>
<p><img src="28.png" alt="28"></p>
<p>Select <strong>SAML 2.0</strong> as the sign-in method and click <strong>Next</strong>.</p>
<p><img src="29.png" alt="29"></p>
<p>On the next screen, set the App name to be Netskope Cloud Exchange and provide an app logo if required. Click Next to proceed to the Configure SAML section.</p>
<p><img src="30.png" alt="30"></p>
<h2 id="copy-the-cloud-exchange-sso-information-1">Copy the Cloud Exchange SSO information</h2>
<p>Log in to Cloud Exchange using the <code>admin</code> (super administrator) user, and navigate to <strong>Settings &gt; Users</strong> (this settings area will only be visible to the <code>admin</code> user).</p>
<p>Select the <strong>SSO Configuration</strong> tab, and toggle the <strong>SSO</strong> toggle <strong>ON</strong> (make sure you save this configuration).</p>
<p>Note down the first two &ldquo;Service Provider&rdquo; fields at the bottom of the screen (<code>Service Provider Entity ID</code> and <code>Service Provider ACS URL</code>). The image below maps which URL should be used for which config field in Okta.</p>
<p><img src="31.png" alt="31"></p>
<h2 id="configure-okta-saml-integration">Configure Okta SAML Integration</h2>
<p>Switch back to your Okta configuration and configure the settings as follows:</p>
<h3 id="copy-the-cloud-exchange-service-provider-urls">Copy the Cloud Exchange Service Provider URLs</h3>
<p>For the first two Service Provider URL fields in the Cloud Exchange SSO configuration, paste the corresponding URL into the appropriate field in Okta. See the table below for mapping:</p>
<table>
<thead>
<tr>
<th>Cloud Exchange Field</th>
<th>Okta SAML Config Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>Service Provider Entity ID</td>
<td>Audience URL (SP Entity ID)</td>
</tr>
<tr>
<td>Service Provider ACS URL</td>
<td>Single sign on URL</td>
</tr>
<tr>
<td>Service Provider SLS URL</td>
<td>N/A - Not used</td>
</tr>
</tbody>
</table>
<h3 id="set-the-name-id-format">Set the Name ID format</h3>
<p>Ensure you change the <strong>Name ID format</strong> in Okta, from <em>Unspecified</em> to <em><strong>EmailAddress</strong></em>.</p>
<h3 id="add-additional-attributes">Add additional attributes</h3>
<p>You need to add two additional attribute statements to the Okta configuration: One called <code>username</code> and another called <code>roles</code>.</p>
<ul>
<li>The <code>username</code> attribute should have the value of <code>user.email</code>.</li>
<li>The <code>roles</code> attribute should have the value of <code>appuser.roles</code> (you will need to type this - it won&rsquo;t appear in the dropdown).</li>
</ul>
<p><img src="32.png" alt="32"></p>
<h3 id="finish-the-saml-configuration">Finish the SAML configuration</h3>
<p>When you are done, scroll to the bottom of the page and click <strong>Next</strong>.</p>
<p>Check the box &ldquo;<em>I&rsquo;m an Okta customer adding an internal app</em>&rdquo; and click <strong>Finish</strong>.</p>
<h3 id="open-the-okta-saml-20-steup-instructions">Open the Okta SAML 2.0 Steup Instructions</h3>
<p>On the next page, click the <strong>View Setup Instructions</strong> button inside the yellow box under the <strong>Sign On</strong> tab app.</p>
<p><img src="42.png" alt="42"></p>
<p>This will open a new tab containing the details we will need to copy back into the Cloud Exchange console.</p>
<p><img src="41.png" alt="41"></p>
<p>Leave this tab open for now as we still have some configuration left to do on the Okta side.</p>
<h2 id="create-the-roles-attribute-in-okta">Create the <code>roles</code> attribute in Okta</h2>
<p>Users can be assigned Read/Write or just Read access to the CE UI based on one of two roles assigned to them: <code>Admin</code> (read/write access) and <code>Read Only</code>. We need to create the <code>roles</code> attribute in Okta so that it can be used and assigned to the groups of IT admins who will use the CE application.</p>
<p>Navigate to <strong>Directory &gt; Profile Editor</strong> from the left-side menu, and select the <strong>Netskope Cloud Exchange User</strong> profile.</p>
<p><img src="33.png" alt="33"></p>
<p>Here you&rsquo;ll see the <code>username</code> attribute we added when we completed the SAML configuration, but the <code>roles</code> attribute is nowhere to be found! We need to create it manually.</p>
<p>Click the <strong>Add Attribute</strong> button.</p>
<p><img src="34.png" alt="34"></p>
<ul>
<li>For <strong>Display name</strong>, enter <code>Roles</code></li>
<li>For <strong>Variable name</strong>, enter <code>roles</code> &lt;&ndash; Case sensitive!</li>
<li>For <strong>Description</strong>, enter <code>Netskope Cloud Exchange Admin Roles</code></li>
</ul>
<p>Click <strong>Save</strong> at the bottom when you&rsquo;re done.</p>
<p><img src="35.png" alt="35"></p>
<h2 id="configure-user-groups-for-ce-access">Configure User Groups for CE Access</h2>
<p>Next, we need to create two groups: One for the users that will have read/write access to CE, and another for users that will have read-only access.</p>
<p>Navigate to <strong>Directory &gt; Groups</strong> from the left-side menu, and select the <strong>Add Group</strong> button.</p>
<p><img src="36.png" alt="36"></p>
<h3 id="create-the-read-only-and-admin-groups">Create the <code>Read-Only</code> and <code>Admin</code> groups</h3>
<p>Create two groups called <code>Netskope CE Read-Only</code> and <code>Netskope CE Admin</code> respectively.</p>
<p><img src="37.png" alt="37"></p>
<h3 id="assign-people-to-the-read-only-role">Assign people to the Read-Only role</h3>
<p>Click the <strong>Netskope CE Read-Only</strong> group you created from the group list to edit the group.</p>
<p>Under the <strong>People</strong> tab, click <strong>Assign People</strong> and assign the users who will have read-only access to the CE platform. Don&rsquo;t forget to click <strong>Save</strong>.</p>
<p><img src="38.png" alt="38"></p>
<p>Next, select the <strong>Applications</strong> tab and click <strong>Assign applications</strong>.</p>
<p><img src="39.png" alt="39"></p>
<p>Assign the <strong>Netskope Cloud Exchange</strong> application.</p>
<p>You will then be prompted to specify a role. Enter <code>netskope-ce-read</code></p>
<p><strong>WARNING: You must enter this exactly, or SSO will fail! It is case sensitive.</strong></p>
<p><img src="40.png" alt="40"></p>
<p>Select <strong>Save and Go Back</strong> to complete the configuration of the read-only group.</p>
<h3 id="assign-people-to-the-admin-role">Assign people to the Admin role</h3>
<p>Click the <strong>Netskope CE Admin</strong> group you created from the group list to edit the group.</p>
<p>Repeat the steps above, except this time select the people who will have read/write access to the CE platform. Don&rsquo;t forget to click <strong>Save</strong>.</p>
<p>When prompted to specify a role, enter <code>netskope-ce-write;netskope-ce-read</code></p>
<p><strong>WARNING: You must enter this exactly, or SSO will fail! It is case sensitive.</strong></p>
<p><img src="43.png" alt="43"></p>
<p>Select <strong>Save and Go Back</strong> to complete the configuration of the Admin group.</p>
<h2 id="finish-the-sso-configuration-in-cloud-exchange-1">Finish the SSO Configuration in Cloud Exchange</h2>
<p>Return to the <strong>SSO Configuration</strong> section of the Cloud Exchange UI (<strong>Settings &gt; Users &gt; SSO Configuration</strong>). Here we will use the details within the Setup Instructions that we opened (in a separate tab) earlier.</p>
<p><img src="41.png" alt="41"></p>
<p>For the below fields in the Cloud Exchange SSO configuration, paste the corresponding information from the Okta Setup Instructions. See the table below for mapping:</p>
<table>
<thead>
<tr>
<th>Cloud Exchange Field</th>
<th>Okta Setup Instructions Field</th>
</tr>
</thead>
<tbody>
<tr>
<td>Identity Provider Issuer URL</td>
<td>Identity Provider Issuer</td>
</tr>
<tr>
<td>Identity provider SSO URL</td>
<td>Identity Provider Single Sign-On URL</td>
</tr>
<tr>
<td>Identity provider SLO URL</td>
<td>Identity Provider Single Sign-On URL</td>
</tr>
<tr>
<td>Public x509 Certificate</td>
<td>X.509 Certificate</td>
</tr>
</tbody>
</table>
<p>The SLO URL field is not needed, but cannot be blank. Copy the same URL used for the Identity provider SSO URL for this field.</p>
<p><img src="44.png" alt="44"></p>
<p>Save your SSO Configuration when done.</p>
<h2 id="testing-the-sso-configuration-1">Testing the SSO Configuration</h2>
<p>Open a new Incognito window (to avoid any potential issues with caching) and point your browser to the URL of your Cloud Exchange deployment.</p>
<p>If you enabled the &ldquo;SSO&rdquo; checkbox as instructed at the beginning of this guide, you will two options when reaching Cloud Exchange:</p>
<ol>
<li>Login with SSO</li>
<li>Login with Username/Password</li>
</ol>
<p>Option #2 is used for local login (ie: the default <code>admin</code> user, or any user manually added to the user list in CE).</p>
<p><img src="20.png" alt="20"></p>
<p>Select <strong>Login with SSO</strong>. You should be redirected to Okta to sign in.</p>
<p><img src="45.png" alt="45"></p>
<p>Upon entering your user credentials, you should be authenticated and redirected to the Cloud Exchange interface. In the example below, the Ben user was assigned to the <strong>Netskope CE Read-Only</strong> group, so almost all of the <strong>Settings</strong> menu is hidden.</p>
<p><img src="46.png" alt="46"></p>
<h2 id="troubleshooting-1">Troubleshooting</h2>
<p>If you are having issues signing in, first, look at which platform is giving you an error: Okta, or Cloud Exchange?
If the error you are presented with is from Okta, then the issue is likely with your config on the Okta side. Double-check your URLs and/or whether the user you are attempting to sign in as is assigned to either the <em>Netskope CE Read-Only</em> or <em>Netskope CE Admin</em> groups.</p>
<p>If you are getting an error from Cloud Exchange, then you have likely stuffed up the URLs entered into either CE or Azure AD, not added the custom <code>username</code> and <code>roles</code> attributes, or not typed the name of the role correctly (ie: <code>netskope-ce-read</code> and <code>netskope-ce-write;netskope-ce-read</code>).</p>
<p>If you get the error <code>{&quot;detail&quot;:&quot;Method Not Allowed&quot;}</code>, check that the URLs copied into both Okta and Cloud Exchange are correct and in the right place.</p>
<p>If you get the error <code>{&quot;detail&quot;:&quot;Could not authenticate. username/roles attribute not set.&quot;}</code>, then check that you have added the <code>username</code> and <code>roles</code> claims in the SAML config.</p>
<p><img src="24.png" alt="24"></p>
<p>If you pass SSO fine but receive a red <code>Error while fetching data</code> message in CE, then there is a problem with the role you have assigned to the user. Ensure you entered <code>netskope-ce-write;netskope-ce-read</code> as the attribute for the Admin group (Netskope CE Admin) and <code>netskope-ce-read</code> as the attribute for the Read-Only role (Netskope CE Read-Only). Additionally, check that you have assigned one of these groups to your impacted user: You may also get this error if anything else has been entered into the role field apart from the above two accepted strings.</p>
<p><img src="25.png" alt="25"></p>
]]></content>
        </item>
        
        <item>
            <title>Deploy Zscaler Client Connector with Intune (iOS &amp; Android)</title>
            <link>https://nathancatania.com/posts/deploy-zapp-mobile-with-intune/</link>
            <pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploy-zapp-mobile-with-intune/</guid>
            <description>The thoughts and opinions in this post are my own and do not necessarily reflect those of Zscaler.
In this guide, we&amp;rsquo;ll walkthrough how to configure Microsoft Intune from scratch and use it to deploy the Zscaler Client Connector agent (ZCC) - formerly known as Zscaler Client Connector (ZCC).
Due to length, I&amp;rsquo;ve split this into two posts (the orginal was over 8000 words):
This post covers deployment on iOS/iPadOS and Android.</description>
            <content type="html"><![CDATA[<blockquote>
<p>The thoughts and opinions in this post are my own and do not necessarily reflect those of Zscaler.</p>
</blockquote>
<p>In this guide, we&rsquo;ll walkthrough how to configure Microsoft Intune from scratch and use it to deploy the Zscaler Client Connector agent (ZCC) - formerly known as Zscaler Client Connector (ZCC).</p>
<p>Due to length, I&rsquo;ve split this into two posts (the orginal was over 8000 words):</p>
<ul>
<li>This post covers deployment on iOS/iPadOS and Android.</li>
<li>The other post, <a href="/posts/deploy-zapp-with-intune">available here</a>, covers Windows and macOS.</li>
</ul>
<p>I suggest you use the Table of Contents to jump to the section that you need.</p>
<h1 id="what-is-intune">What is Intune?</h1>
<p><a href="https://docs.microsoft.com/en-us/mem/intune/fundamentals/what-is-intune">According</a> to Microsoft:</p>
<blockquote>
<p>Microsoft Intune is a cloud-based service that focuses on mobile device management (MDM) and mobile application management (MAM).</p>
<p>With Intune, you can:</p>
<ul>
<li>Set rules and configure settings on personal and organization-owned devices to access data and networks.</li>
<li>Deploy and authenticate apps on devices &ndash; on-premises and mobile.</li>
<li>Be sure devices and apps are compliant with your security requirements.</li>
</ul>
</blockquote>
<p>In order to access Intune, you need to have either a Microsoft 365 or <a href="https://www.microsoft.com/en-au/microsoft-365/enterprise-mobility-security/compare-plans-and-pricing">Enterprise &amp; Mobility E3/E5</a> subscription. If you&rsquo;re using a free Azure account, you&rsquo;ll need to sign up to a trial, or pay per user (which can get costly).</p>
<h1 id="before-you-begin">Before You Begin</h1>
<p>When adding an app to Intune, you&rsquo;ll be prompted to allocate the groups of users (or devices) that the app will be rolled out to. Hence before beginning, ensure you have the users of Zscaler inside of an AD or Azure AD group that you can assign the Zscaler Client Connector app to.</p>
<p>Depending on whether you want the ZCC app to be mandatory or optional for certain groups of users, you may want to divide your users into two groups:</p>
<ol>
<li>The users to which the app is MANDATORY. Any user in this group will have the app automatically pushed out to them.</li>
<li>The users to which the app is OPTIONAL. The app will not be automatically pushed for users in this group, allowing them to go to the Company Portal and download it themselves if they choose.</li>
</ol>
<p>In my examples below, I have 3 groups:</p>
<table>
<thead>
<tr>
<th>Group</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZIA_Entitlement</td>
<td>This is the group of all users that are entitled to use Zscaler Internet Access (ZIA)</td>
</tr>
<tr>
<td>ZPA_Entitlement</td>
<td>This is the group of all users that are entitled to use Zscaler Private Access (ZPA). In my case, this is a subset of users from the ZIA_Entitlement group as I might not want to roll ZPA out to every user in the organization.</td>
</tr>
<tr>
<td>Zscaler - Mandatory</td>
<td>This group contains every user in the organization to which the ZCC app will be automatically rolled out to. Ie: The majority of users from the above two groups. If this is your organization, you might include the whole org in this group, except select users (eg: some from IT) for which the app will be optional.</td>
</tr>
</tbody>
</table>
<h1 id="a-warning-on-ssl-inspection-for-ios--android">A Warning on SSL Inspection for iOS &amp; Android</h1>
<p>You should be <strong>very</strong> careful before enabling SSL inspection for iOS and Android devices. Mobile devices and applications are notorious for &ldquo;Certificate Pinning&rdquo; or &ldquo;Public Key Pinning&rdquo; which breaks the connectivity of the app when subjected to SSL inspection.</p>
<p>In this instance, the app only trusts a hardcoded set of certificates, typically from it&rsquo;s developer. If the certificate the app sees is not in this hardcoded list, then the app will terminate the connection and not send any traffic; even if the certificate is trusted by the device. This is to protect against malicious Man-in-the-Middle (MitM) attacks, however it also prevents legitimate MitM functions, like SSL inspection, from working.</p>
<p>The only way around certificate pinning today is to bypass the application from SSL inspection; a solution that many enterprises are not happy doing as it prevents visibility of that application&rsquo;s traffic.</p>
<p>Turning on SSL inspection off the bat for iOS and Android will likely lead to a number of very angry users. I would typically recommend you leave it OFF in the first instance, gather data on the applications used by your users, and then switch it ON at a later date armed with a list of apps you might need to bypass.</p>
<p>For iOS and iPadOS, if you are enabling SSL inspection, iMessage, iCloud, and the iTunes and App Stores all implement Certificate Pinning. You will need to bypass the following domains under <strong>Policy &gt; SSL Inspection</strong> in the Zscaler Admin Portal:</p>
<pre tabindex="0"><code>p24-keyvalueservice.icloud.com
*.apps.apple.com
.itunes.apple.com
.mzstatic.com
gs-loc.apple.com
gsa.apple.com
securemetrics.apple.com
swscan.apple.com
xp.apple.com
.icloud.com
ppq.apple.com
akadns.net
</code></pre><p>For Android, if you are enabling SSL inspection, Google Play implements Certificate Pinning, so you will need to bypass the following domains under <strong>Policy &gt; SSL Inspection</strong> in the Zscaler Admin Portal:</p>
<pre tabindex="0"><code>.gvt1.com
.gvt2.com 
.vzw.com
.ggpht.com
play.googleapis.com
android.clients.google.com
.googleapis.com
.googleusercontent.com
.ggpht.com
.android.clients.google.com
.play.googlezip.net
connectivitycheck.gstatic.com
</code></pre><p>Zscaler maintains a list of commonly required SSL bypasses across platforms <a href="https://help.zscaler.com/zia/certificate-pinning-and-ssl-inspection">here</a>.</p>
<h1 id="microsoft-endpoint-manager">Microsoft Endpoint Manager</h1>
<p>We&rsquo;ll be using the <strong>Microsoft Endpoint Manager console</strong> (MEM) to orchestrate Intune. You can log in using the same Azure Portal credentials here: <a href="https://endpoint.microsoft.com">https://endpoint.microsoft.com</a></p>
<p><img src="1.png" alt="1"></p>
<h2 id="optional-setting-the-mdm-authority">(Optional) Setting the MDM Authority</h2>
<p>If you&rsquo;re using an existing Office 365 account <strong>and</strong> have been using the Office 365 MDM, you&rsquo;ll need to change the MDM authority from Office 365 to Intune. <a href="https://docs.microsoft.com/en-us/mem/intune/fundamentals/mdm-authority-set">This</a> Microsoft help article will guide you through it.</p>
<hr>
<h1 id="ios-and-ipados">iOS and iPadOS</h1>
<p>This section will cover deploying ZCC onto iOS (and iPadOS) using Intune.</p>
<h2 id="1-create-a-device-configuration-profile-for-vpn">1. Create a Device Configuration Profile for VPN</h2>
<p>ZCC requires the use of a VPN profile on the device which Intune will deploy for us. We need to create it first however.</p>
<p>Note that ZCC does not use a VPN to forward traffic to Zscaler. On iOS the VPN profile is only used to direct device traffic into the ZCC application which then forwards it on to the closest Zscaler DC itself.</p>
<h3 id="creating-the-vpn-profile">Creating the VPN Profile</h3>
<p>In the <strong>Devices</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, go to <strong>Configuration profiles</strong> (this is under the &ldquo;Policy&rdquo; menu heading). Select <strong>Create profile</strong>.</p>
<p>Under <strong>Platform</strong> select <strong>iOS/iPadOS</strong> from the dropdown. Likewise, under <strong>Profile</strong>, select <strong>VPN</strong>. When you&rsquo;re done, click <strong>Create</strong> to continue.</p>
<p><img src="13.png" alt="13"></p>
<p>On the next screen, give the VPN a name (eg: <code>ZscalerForwarding</code>) then click <strong>Next</strong> to got to the <strong>Configuration Settings</strong> tab.</p>
<p><img src="14.png" alt="14"></p>
<h3 id="configuring-the-base-vpn-profile">Configuring the Base VPN Profile</h3>
<p>For the <strong>Connection type</strong>, select <strong>Zscaler</strong> from the dropdown.</p>
<p><img src="15.png" alt="15"></p>
<p>Expand the <strong>Base VPN</strong> section and fill in the following:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Connection name</strong></td>
<td>The name of the VPN connection. This is what will show up on the user&rsquo;s device. Eg: <code>ZscalerForwarding</code></td>
</tr>
<tr>
<td><strong>Custom domain name</strong></td>
<td>Enter the primary domain name associated with your company&rsquo;s identity service / SSO provider. This is used to pre-populate the login field in ZCC. In my case, this is <code>oblivion.industries</code> as I authenticate with <a href="mailto:nathan@oblivion.industries">nathan@oblivion.industries</a> as my username.</td>
</tr>
<tr>
<td><strong>Enable strict enforcement</strong></td>
<td>If enabled, Strict Enforcement blocks internet access on the device until the user signs into ZCC. Strict Enforcement requires a device be in Supervised Mode, which in turn, is only possible with corporate owned devices (those configured with Apple Configurator or DEP/Apple Business Manager) - BYOD or employee-owned devices can&rsquo;t be put into Supervised Mode and hence, won&rsquo;t work with Strict Enforcement (even if it&rsquo;s enabled).</td>
</tr>
<tr>
<td><strong>Organization&rsquo;s cloud name</strong></td>
<td>The name of the Zscaler cloud on which your organization is provisioned. When entering the cloud name, DO NOT enter the <strong>.net</strong> at the end. Eg: zscalertwo.net should be entered as <code>zscalertwo</code>, zscaler.net should be entered as <code>zscaler</code>.</td>
</tr>
</tbody>
</table>
<p><img src="16.png" alt="16"></p>
<p>The <strong>Excluded URLs</strong> section allows you to specify URLs that are bypassed from Zscaler (typically this should be done within the Zscaler admin portal itself so you&rsquo;re not fragmenting the configuration).</p>
<p>If you&rsquo;re enabling strict enforcement, at a minimum you&rsquo;ll want to include the URL for your SSO/identity provider and the URL for Zscaler&rsquo;s authentication service. For example, for Azure AD:</p>
<pre tabindex="0"><code>login.microsoftonline.com
authsp.prod.zpath.net
</code></pre><p>You won&rsquo;t be able to proceed without adding some sort of entry to the <strong>Key</strong> and <strong>Value</strong> sections (more info is provided below, but this won&rsquo;t apply to most orgs). <strong>You can enter any random key and value pair to proceed.</strong></p>
<h3 id="optional-additional-customization">(Optional) Additional Customization</h3>
<p>The <strong>Key</strong> and <strong>Value</strong> pairs you can enter allow you to further customize the install if:</p>
<ul>
<li>You need to use a token to log in a device (eg: a non-user, kiosk device)</li>
<li>You need to enable FIPS compliant libraries.</li>
</ul>
<p>Most deployments won&rsquo;t need to to this and can safely skip this section.</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>deviceToken</code></td>
<td>The appropriate device token from the Zscaler Client Connector Portal, if you want to use the <a href="https://help.zscaler.com/z-app/using-zscaler-app-portal-identity-provider-idp">Zscaler Client Connector Portal as an IdP</a>.</td>
</tr>
<tr>
<td><code>username</code></td>
<td>The username for the user. For example, if the username is <a href="mailto:nathan@oblivion.industries">nathan@oblivion.industries</a>, you would enter <code>nathan</code>. Only required if you&rsquo;re using <code>deviceToken</code> above.</td>
</tr>
<tr>
<td><code>enableFips</code></td>
<td>Enabling this option indicates that ZCC uses FIPS compliant libraries for communication with Zscaler infrastructure. Enter 1 to enable or 0 to disable this option (enable only if you require FIPS level security within your org).</td>
</tr>
<tr>
<td><code>userDomain</code></td>
<td>Not needed. Duplicate of the above &ldquo;Custom domain name&rdquo; field from the VPN profile configuration.</td>
</tr>
<tr>
<td><code>cloudname</code></td>
<td>Not needed. Duplicate of the above &ldquo;Organization cloud name&rdquo; field from the VPN profile configuration.</td>
</tr>
</tbody>
</table>
<h3 id="optional-configure-the-automatic-vpn-settings">(Optional) Configure the Automatic VPN settings</h3>
<p>Scroll down and expand the <strong>Automatic VPN</strong> section. By default, you can leave this set to <strong>Not configured</strong>. In this instance, the device will direct all internet bound traffic from every app into the ZCC app to be forwarded to Zscaler. You can then control, from within the Zscaler Client Connector portal, what traffic should be sent to Zscaler and what traffic should be bypassed. This gives you a single point of control over how traffic is bypassed or directed towards Zscaler.</p>
<p><img src="18.png" alt="18"></p>
<p>Optionally, you can configure an <strong>On-demand</strong> or <strong>Per-App</strong> VPN in order dictate at a device level through Intune what traffic should be directed towards Zscaler. An <strong>On-demand</strong> VPN allows you to set rules as to when the traffic should be directed to ZCC (eg: when the user is or isn&rsquo;t connected to specific specific SSIDs), while a <strong>Per-App</strong> VPN allows you to selectively steer traffic into the ZCC app based on specific apps on the device or URLs.</p>
<p>This guide won&rsquo;t cover configuring an <strong>On-demand</strong> or <strong>Per-app</strong> VPN here as it&rsquo;s quite straightforward. See <a href="https://docs.microsoft.com/en-gb/mem/intune/configuration/vpn-settings-ios#connection-type">here</a> for more information.</p>
<p>When you&rsquo;re satisifed, click <strong>Next</strong> to continue.</p>
<h3 id="assign-groups-to-the-vpn-profile">Assign Groups to the VPN Profile</h3>
<p>In the next section, you need to select the Users, Groups, or Devices that will make use of this VPN Configuration Profile. As this profile is <strong>required</strong> for all users that will use the ZCC app on iOS/iPad OS, you should assign the AD groups that contain all of the users that are entitled to use Zscaler.</p>
<p>In my case, this was the groups <code>ZIA_Entitlement</code> (a group containing all users org wide that can use Zscaler Internet Access (ZIA)), and <code>ZPA_Entitlement</code> (a group containing all users org wide that can use Zscaler Private Access (ZPA)).</p>
<p><img src="19.png" alt="19"></p>
<p>Select <strong>Next</strong> to proceed to review your profile configuration. When you&rsquo;re done, click <strong>Review + Create</strong> to create the profile.</p>
<h2 id="2-push-the-zscaler-certificate-for-ssl-inspection">2. Push the Zscaler Certificate for SSL Inspection</h2>
<p><em>NB: If you&rsquo;re <strong>not</strong> a ZIA customer (ie: ZPA only), then you can skip this section.</em></p>
<p>For Windows and macOS, ZCC will automatically install the intermediate root certificate (required for SSL inspection) onto the device for you.</p>
<p>With iOS, this is not possible as Apple requires application-installed certificates to be untrusted by default. This means that if ZCC <em>were</em> to try and install the certificate, the user would get an SSL error for every site they visited as Zscaler is inspecting all traffic and the device doesn&rsquo;t trust the certificate installed.</p>
<p>Instead, we need to have the certificate pushed out via Intune.</p>
<h3 id="download-the-zscaler-intermediate-root-ca--enable-ios-ssl-inspection">Download the Zscaler Intermediate Root CA &amp; Enable iOS SSL Inspection</h3>
<p>Log into your ZIA admin portal, and navigate to <strong>Policy &gt; SSL Inspection</strong>.</p>
<p><img src="20.png" alt="20"></p>
<p>Scroll to the bottom of the page and under the section, <strong>INTERMEDIATE ROOT CERTIFICATE AUTHORITY FOR SSL INSPECTION</strong>, click <strong>Download Zscaler Root Certificate</strong>.</p>
<p>You can optionally enable SSL inspection for iOS on this screen, but be weary of Certificate Pinning when doing so.</p>
<p><img src="21.png" alt="21"></p>
<p><strong>Save</strong> and <strong>activate</strong> your changes.</p>
<p>On your computer, unzip the <code>.zip</code> file containing the certificate to obtain the <code>ZscalerRootCertificate-2048-SHA256.crt</code> certificate file. You&rsquo;ll need this in the next step.</p>
<h3 id="create-a-device-configuration-profile-for-a-trusted-certificate">Create a Device Configuration Profile for a Trusted Certificate</h3>
<p>Just like we did for the VPN profile, we need to create <em>another</em> Device Configuration Profile; this time for a <strong>Trusted Certificate</strong>.</p>
<p>In the <strong>Devices</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, go to <strong>Configuration profiles</strong> (this is under the &ldquo;Policy&rdquo; menu heading). Select <strong>Create profile</strong>.</p>
<p>Under <strong>Platform</strong> select <strong>iOS/iPadOS</strong> from the dropdown. Under <strong>Profile</strong>, select Trusted Certificate.</p>
<p><img src="22.png" alt="22"></p>
<p>On the next screen, give the Trusted Certificate a name (eg: <code>Zscaler Root CA</code>) then click <strong>Next</strong> to got to the <strong>Configuration Settings</strong> tab.</p>
<p><img src="23.png" alt="23"></p>
<p>On the next screen, navigate to and select the <code>ZscalerRootCertificate-2048-SHA256.crt</code> file you downloaded from the Zscaler admin portal. Click <strong>Next</strong> once the file has uploaded.</p>
<p><img src="24.png" alt="24"></p>
<p>On the <strong>Assignments</strong> tab, you can either assign this to <strong>All devices</strong> or explicitly select the groups containing your Zscaler users.</p>
<p><img src="25.png" alt="25"></p>
<p>Click <strong>Next</strong> when you are done to review and create the profile.</p>
<h2 id="3-add-a-new-ios-app-in-mem">3. Add a new iOS App in MEM</h2>
<h3 id="add-a-new-ios-store-app">Add a new iOS Store App</h3>
<p>In the <strong>Apps</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, navigate to <strong>Apps &gt; All Apps &gt; Add</strong>. In the panel that appears, under the <strong>Store Apps</strong> heading, select <strong>iOS store app</strong>.</p>
<p><img src="10.png" alt="10"></p>
<p>When prompted, search for &ldquo;<strong>Zscaler</strong>&rdquo; and select the Zscaler Client Connector.</p>
<p><img src="11.png" alt="11"></p>
<p>On the next page, most of the App information will be populated for you. Ensure <strong>iOS 9.0</strong> is selected as the minimum operating system, and click <strong>Next</strong> to move to the <strong>Assignments</strong> tab.</p>
<p><img src="12.png" alt="12"></p>
<h3 id="assign-users-to-the-app">Assign Users to the App</h3>
<p>There are two different sections you can allocate users or groups to depending on how you want the app rolled out to users:</p>
<ul>
<li><strong>Required</strong> = The app is MANDATORY for these users/groups. Any user or group in this section will have the App automatically pushed out to them.</li>
<li><strong>Available for enrolled devices</strong> = The app is OPTIONAL for these users/groups. The app will not be automatically pushed and the users can go to download the app themselves from within the Company Portal.</li>
</ul>
<p>Assign your users or groups to the ZCC app for iOS accordingly.</p>
<p><img src="26.png" alt="26"></p>
<p>Click <strong>Next</strong> to continue and then <strong>Create</strong> on the following screen. Your iOS application will be created and you&rsquo;ll be ready to go!</p>
<h2 id="4-optional-configure-intune-for-apple-devices">4. (Optional) Configure Intune for Apple Devices</h2>
<p>Apple requires an MDM Push Certificate to enable management of iOS, iPadOS and macOS devices. If you haven&rsquo;t used any iOS/iPad OS devices with Intune before, you&rsquo;ll need to <a href="https://docs.microsoft.com/en-us/mem/intune/enrollment/apple-mdm-push-certificate-get">follow the steps outlined by Microsoft here</a> before you can enroll and test any Apple devices.</p>
<h2 id="5-testing-zcc-deployment-on-ios">5. Testing ZCC Deployment on iOS</h2>
<p>If you haven&rsquo;t already:</p>
<ol>
<li>Download and install the <a href="https://play.google.com/store/apps/details?id=com.microsoft.windowsintune.companyportal">Intune Company Portal</a> app from Microsoft on the App Store.</li>
<li>Open the app and sign-in with your company SSO credentials.</li>
<li>Follow the prompts to complete the Intune device enrolment.</li>
</ol>
<p>Following the device enrolment, provided that you signed in with a user in which the ZCC was mandatory, the ZCC app should automatically install on the user&rsquo;s device. If you specified the <code>cloudName</code> and <code>userDomain</code> flags in the VPN Configuration Profile, the user should automatically be prompted to sign in via SSO when opening the app.</p>
<h2 id="6-demo-video">6. Demo Video</h2>
<p>Coming shortly&hellip;</p>
<h2 id="7-authentication-friction-on-ios">7. Authentication Friction on iOS</h2>
<h3 id="removing-the-need-for-users-to-enter-sso-credentials">Removing the need for users to enter SSO credentials</h3>
<p>Presently, our method for deploying ZCC on iOS works, however users still need to open the app and manually authenticate via SSO by typing their credentials. This creates user friction.</p>
<p>Authenticating the user without them having to enter their SSO credentials <em>is possible</em> on iOS using certificates, however given the length of this guide already, I might tackle this in a separate post&hellip; Check back later.</p>
<h3 id="the-issue-with-silent--automatic-authentication">The issue with Silent &amp; Automatic Authentication</h3>
<blockquote>
<p>Can I automatically and silently sign the user into the Zscaler Client Connector app on iOS when the app is rolled out with Intune?</p>
</blockquote>
<p>This is a very common question I get from clients. <strong>The answer is no, and you&rsquo;ll probably never be able to do this.</strong></p>
<p>Apple does not allow apps to automatically open and run themselves, and in order to silently authenticate the user during app rollout, the ZCC app would need to automatically open once installed to process the user authentication. From a security perspective, giving apps the ability to automatically open themselves would be a nightmare and something I can&rsquo;t see Apple allowing anytime soon.</p>
<p>What you need to do is create a &ldquo;compelling event&rdquo; so that your users <em>have</em> to open the app to authenticate.</p>
<h3 id="creating-a-compelling-event">Creating a &ldquo;Compelling Event&rdquo;</h3>
<p>Users are never going to open an app and sign in, just to ensure that your organization is secure: there is nothing in it for them to do so. You need to give them a reason and there are a few ways to do that:</p>
<ol>
<li>Prevent certain apps, like Office 365, from working unless the user is signed into Zscaler.</li>
<li>Block all internet access from the device until the user opens the ZCC app to authenticate.</li>
<li>Prevent access to internal company applications unless the user is signed into Zscaler.</li>
</ol>
<p>Number 1 is the easiest and involves either using the <strong>Identity Proxy</strong> feature in ZIA (this prevents your users from signing into apps like Office or Salesforce unless their traffic is going through Zscaler), or only allowing access to the application from the Zscaler IP space (eg: 165.225.0.0/17).</p>
<p>Number 2 is harder as it requires you to use Strict Enforcement, which requires the device be in Supervised Mode, which is only possible on corporate owned devices. BYOD and user-owned devices are out of the picture.</p>
<p>Number 3 can work in conjunction with Number 1, but requires ZPA. Essentially, ZPA provides access to your internal resources and won&rsquo;t work unless the user is signed in&hellip; so they have to sign in.</p>
<hr>
<h1 id="android">Android</h1>
<p>This section will cover deploying ZCC onto Android devices using Intune.</p>
<h2 id="1-add-a-new-android-app-in-mem">1. Add a new Android App in MEM</h2>
<h3 id="add-a-new-managed-google-play-app">Add a new Managed Google Play App</h3>
<p>In the <strong>Apps</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, navigate to <strong>Apps &gt; All Apps &gt; Add</strong>. In the panel that appears, under the <strong>Store Apps</strong> heading, select <strong>Managed Google Play app</strong>.</p>
<p><img src="27.png" alt="27"></p>
<h3 id="link-intune-to-android-enterprise">Link Intune to Android Enterprise</h3>
<p><strong>If this is your first time adding an Android app to Intune</strong>, you&rsquo;ll be prompted to connect your Intune account to your Android Enterprise account before you can do anything else. After you&rsquo;ve completed this step, go back and add a new Managed Google Play app again.</p>
<p><img src="28.png" alt="28"></p>
<p><img src="29.png" alt="29"></p>
<p>Note: If you are using a Samsung device, you have <a href="https://docs.microsoft.com/en-us/mem/intune/enrollment/android-samsung-knox-mobile-enroll">additional steps you will need to go through</a> before proceeding.</p>
<h3 id="approve-the-zscaler-client-connector-app">Approve the Zscaler Client Connector App</h3>
<p>When prompted, search for &ldquo;<strong>Zscaler</strong>&rdquo; and select <strong>Zscaler Client Connector</strong>.</p>
<p><img src="30.png" alt="30"></p>
<p>On the store page, click <strong>Approve</strong>. Follow the prompts to set your permission preferences for the app.</p>
<p>When you&rsquo;re finished, click <strong>Select</strong> under the app description, and then <strong>Sync</strong> at the top left. This will place you back into the All Apps section of Intune while your Managed Google Play preferences sync with Intune.</p>
<p><img src="31.png" alt="31"></p>
<p>Wait 30-60 seconds, and refresh the app list. You should see the Zscaler Client Connector as a Managed Google Play store app appear in the list.</p>
<p><img src="32.png" alt="32"></p>
<h3 id="assign-users-to-the-app-1">Assign Users to the App</h3>
<p>Click on the app and select <strong>Preferences</strong> from the menu pane. Under <strong>Assignments</strong> click <strong>Edit</strong>.</p>
<p><img src="33.png" alt="33"></p>
<p>There are two different sections you can allocate users or groups to depending on how you want the app rolled out to users:</p>
<ul>
<li><strong>Required</strong> = The app is MANDATORY for these users/groups. Any user or group in this section will have the App automatically pushed out to them.</li>
<li><strong>Available for enrolled devices</strong> = The app is OPTIONAL for these users/groups. The app will not be automatically pushed and the users can go to download the app themselves from within the Company Portal.</li>
</ul>
<p>Assign your users or groups to the ZCC app for Android accordingly.</p>
<p><img src="34.png" alt="34"></p>
<p>When you&rsquo;re done, click <strong>Review and Save</strong> at the bottom to save your configuration.</p>
<h2 id="2-push-the-zscaler-certificate-for-ssl-inspection-1">2. Push the Zscaler Certificate for SSL Inspection</h2>
<p><em>NB: If you&rsquo;re <strong>not</strong> a ZIA customer (ie: ZPA only), then you can skip this section.</em></p>
<p>For Windows and macOS, ZCC will automatically install the intermediate root certificate (required for SSL inspection) onto the device for you.</p>
<p>With Android, this is not possible: Google (by default) prevents non-default certificate authorities installed by 3rd party apps from being trusted by the device. Instead, we need to have the certificate pushed out via Intune.</p>
<h3 id="download-the-zscaler-intermediate-root-ca--enable-android-ssl-inspection">Download the Zscaler Intermediate Root CA &amp; Enable Android SSL Inspection</h3>
<p>Log into your ZIA admin portal, and navigate to <strong>Policy &gt; SSL Inspection</strong>.</p>
<p><img src="20.png" alt="20"></p>
<p>Scroll to the bottom of the page and under the section, <strong>INTERMEDIATE ROOT CERTIFICATE AUTHORITY FOR SSL INSPECTION</strong>, click <strong>Download Zscaler Root Certificate</strong>.</p>
<p>You can optionally enable SSL inspection for Android on this screen, but be weary of Certificate Pinning when doing so.</p>
<p><img src="35.png" alt="35"></p>
<p><strong>Save</strong> and <strong>activate</strong> your changes.</p>
<p>On your computer, unzip the <code>.zip</code> file containing the certificate to obtain the <code>ZscalerRootCertificate-2048-SHA256.crt</code> certificate file. You&rsquo;ll need this in the next step.</p>
<h3 id="create-a-device-configuration-profile-for-a-trusted-certificate-1">Create a Device Configuration Profile for a Trusted Certificate</h3>
<p>In the <strong>Devices</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, go to <strong>Configuration profiles</strong> (this is under the &ldquo;Policy&rdquo; menu heading). Select <strong>Create profile</strong>.</p>
<p>Under <strong>Platform</strong> select <strong>Android Enterprise</strong> from the dropdown.</p>
<p>For the <strong>Profile</strong>:</p>
<ul>
<li>If you are deploying to <strong>corporate-owned</strong> Android devices, select the <strong>Trusted Certificate</strong> option under the &ldquo;<strong>Fully Managed, Dedicated, and Corporate-Owned Work Profile</strong>&rdquo; heading.</li>
<li>If you are deploying to <strong>BYOD</strong> or <strong>Employee-owned</strong> Android devices, select the <strong>Trusted Certificate</strong> option under the &ldquo;<strong>Work Profile</strong>&rdquo; heading.</li>
<li>If you plan on having a mix of <strong>corporate-owned <em>AND</em> BYOD/Employee-owned devices</strong>, you will need to follow this section twice; creating a separate configuration profile for each option.</li>
</ul>
<p><img src="36.png" alt="36"></p>
<p>On the next screen, give the Trusted Certificate a name (eg: <code>Zscaler Root CA</code>) then click <strong>Next</strong> to got to the <strong>Configuration Settings</strong> tab.</p>
<p><img src="23.png" alt="23"></p>
<p>On the next screen, navigate to and select the <code>ZscalerRootCertificate-2048-SHA256.crt</code> file you downloaded from the Zscaler admin portal. Click <strong>Next</strong> once the file has uploaded.</p>
<p><img src="24.png" alt="24"></p>
<p>On the <strong>Assignments</strong> tab, you can either assign this to <strong>All devices</strong> or explicitly select the groups containing your Zscaler users.</p>
<p><img src="25.png" alt="25"></p>
<p>Click <strong>Next</strong> when you are done to review and create the profile.</p>
<h2 id="3-create-an-app-configuration-policy">3. Create an App Configuration Policy</h2>
<p>An App Configuration Policy will allow us to customize the install of ZCC on Android.</p>
<h3 id="creating-the-app-configuration-policy">Creating the App Configuration Policy</h3>
<p>In the <strong>Apps</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, go to <strong>App configuration policies</strong> (this is under the &ldquo;Policy&rdquo; menu heading). Select <strong>Add &gt; Managed devices</strong>.</p>
<p><img src="37.png" alt="37"></p>
<ol>
<li>Provide a name for the App Configuration Policy, eg: <strong>Zscaler Client Connector</strong></li>
<li>For the Platform, select <strong>Android Enterprise</strong>.</li>
<li>For the Targeted App, click the link and select <strong>Zscaler Client Connector</strong> from the side panel that appears.</li>
</ol>
<p>For the <strong>Profile Type</strong>:</p>
<ul>
<li><strong>Fully Managed, Dedicated, and Corporate-Owned Work Profile Only</strong> applies this configuration to the ZCC app deployed on <strong>Corporate-owned</strong> devices.</li>
<li><strong>Work Profile Only</strong> applies this configuration to the ZCC app deployed on <strong>BYOD / Employee-owned</strong> devices.</li>
<li><strong>All Profile Types</strong> applies this configuration to all ZCC app deployments on Android, regardless of the device type. <strong>This option should suffice for most organizations.</strong></li>
</ul>
<p><img src="38.png" alt="38"></p>
<p>Click <strong>Next</strong> to continue.</p>
<h3 id="a-note-on-byod--employee-owned-devices">A note on BYOD &amp; Employee-owned devices</h3>
<p>It is important to note that for BYOD / Employee-owned devices, Android for Work is used. <strong>This creates a separate, sandboxed partition on the user&rsquo;s device for corporate data and apps; ensuring that they are segmented from personal data.</strong> When you push apps using Intune, they are installed into the isolated Android for Work environment only and cannot interact with personal apps or data on the device.</p>
<p>If the user opens Chrome on their device, even though the Zscaler app is running, this traffic will NOT go through Zscaler as the Chrome app is from the personal partition; not Android for Work. However any apps that the user uses that are rolled out by the business via Intune WILL go through Zscaler.</p>
<p>For this reason, you might want to also add Chrome as a Managed Google Play app through Intune. This ensures that the user can use the work-instance of Chrome for access to corporate resources and applications, and the personal-instance of Chrome for all of their traffic.</p>
<p>If you would like ALL traffic from an employee owned device to go through Zscaler, you will need to push out a non-managed version of the ZCC app (which cannot be customized), or educate the user about installing ZCC themselves. Utimately you can&rsquo;t force them to do this though as it is their device.</p>
<h3 id="customizing-the-app-configuration-policy">Customizing the App Configuration Policy</h3>
<p>On the Settings tab, for <strong>Configuration settings format</strong>, select <strong>Use configuration designer</strong> from the dropdown.</p>
<p><img src="39.png" alt="39"></p>
<p>Click the <strong>Add</strong> button to add in new attributes to customize the install. You can choose from the following:</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>userDomain</code></td>
<td>Your organization’s domain name associated with your identity/SSO service, e.g., <code>oblivion.industries</code>. This is used to pre-populate the login field in ZCC. If your instance has multiple domains associated with it, enter the primary domain for your instance.</td>
</tr>
<tr>
<td><code>cloudName</code></td>
<td>The name of the Zscaler cloud on which your organization is provisioned. When entering the cloud name, DO NOT enter the <strong>.net</strong> at the end. Eg: zscalertwo.net should be entered as <code>zscalertwo</code>, zscaler.net should be entered as <code>zscaler</code></td>
</tr>
<tr>
<td><code>deviceToken</code></td>
<td>The appropriate device token from the Zscaler Client Connector Portal, if you want to use the <a href="https://help.zscaler.com/z-app/using-zscaler-app-portal-identity-provider-idp">Zscaler Client Connector Portal as an IdP</a>. Useful if ZCC is to be deployed to a shared or kiosk mobile device.</td>
</tr>
<tr>
<td><code>userName</code></td>
<td>Only required if you&rsquo;re using <code>deviceToken</code> above. The username for the user. For example, if the username is <a href="mailto:nathan@oblivion.industries">nathan@oblivion.industries</a>, you would enter <code>nathan</code></td>
</tr>
<tr>
<td><code>enableFips</code></td>
<td>Enabling this option indicates that ZCC uses FIPS compliant libraries for communication with Zscaler infrastructure. Enter 1 to enable or 0 to disable this option (enable only if you require FIPS level security within your org).</td>
</tr>
</tbody>
</table>
<p><strong>At a minimum, select the <code>userDomain</code> and <code>cloudName</code> fields as this is best practice.</strong> This should suffice for most deployments - the other options are more specialized should not be needed in most circumstances.</p>
<blockquote>
<p><strong>Bug alert!</strong> If you are using the <code>userDomain</code> and <code>cloudName</code> fields, you will also need to specify dummy values for <code>deviceToken</code> and <code>userName</code> as well, or the <code>userDomain</code> field won&rsquo;t actually function. This will be fixed in the next Android release (v.1.8)</p>
</blockquote>
<p>Once you have entered values for the selected fields, click <strong>Next</strong>.</p>
<h3 id="assign-users--devices-to-the-app-configuration-policy">Assign Users &amp; Devices to the App Configuration Policy</h3>
<p>In the next section, you need to select the Users, Groups, or Devices that will make use of this App Configuration Policy. Depending on whether this profile is for corporate-owned devices, personal/BYOD devices, or both, you should select groups accordingly.</p>
<p>In my case, this profile is for both corporate and employee-owned devices so I selected &ldquo;<strong>All users and devices</strong>&rdquo;.</p>
<p><img src="40.png" alt="40"></p>
<p>Select <strong>Next</strong> to proceed to review your policy configuration. When you&rsquo;re done, click <strong>Create</strong> to create the profile.</p>
<p>Your Android application should now be ready to rollout to users!</p>
<h2 id="4-testing-zcc-deployment-on-android">4. Testing ZCC Deployment on Android</h2>
<p>If you haven&rsquo;t already:</p>
<ol>
<li>Download and install the <a href="https://play.google.com/store/apps/details?id=com.microsoft.windowsintune.companyportal">Intune Company Portal</a> app from Microsoft on the Google Play store.</li>
<li>Open the app and sign-in with your company SSO credentials.</li>
<li>Follow the prompts to complete the Intune device enrolment.</li>
</ol>
<p>Following the device enrolment, provided that you signed in with a user in which the ZCC was mandatory, the ZCC app should automatically install on the user&rsquo;s device. If you specified the <code>cloudName</code> and <code>userDomain</code> flags in the App Configuration Policy, the user should automatically be prompted to sign in via SSO when opening the app.</p>
<p>If ZCC is deployed, but the user is prompted to enter a username from a blue Zscaler screen, this will be attributed to either of the following:</p>
<ul>
<li>The App Configuration Policy is not being applied against this user and device. Check the <strong>Assignments</strong> section under <strong>Properties</strong> for the App Configuration Policy and ensure your selection encompasses both the user and their device: <strong>Apps &gt; All Apps &gt; App configuration policies &gt; [Select your app policy]</strong></li>
<li>You haven&rsquo;t specified the <code>cloudName</code> and <code>userDomain</code> flags correctly.</li>
<li>You are hitting a bug where you also need to specify the <code>deviceToken</code> and <code>userName</code> fields in the App Configuration Policy (with dummy data).</li>
</ul>
<h2 id="5-demo-video">5. Demo Video</h2>
<p>Coming shortly&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Deploy Zscaler Client Connector with Intune (Windows &amp; macOS)</title>
            <link>https://nathancatania.com/posts/deploy-zapp-with-intune/</link>
            <pubDate>Mon, 05 Oct 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploy-zapp-with-intune/</guid>
            <description>The thoughts and opinions in this post are my own and do not necessarily reflect those of Zscaler.
In this guide, we&amp;rsquo;ll walkthrough how to configure Microsoft Intune from scratch and use it to deploy the Zscaler Client Connector agent (ZCC) - formerly known as Zscaler Client Connector (ZCC).
Due to length, I&amp;rsquo;ve split this into two posts (the orginal was over 8000 words):
This post covers deployment on Windows and macOS.</description>
            <content type="html"><![CDATA[<blockquote>
<p>The thoughts and opinions in this post are my own and do not necessarily reflect those of Zscaler.</p>
</blockquote>
<p>In this guide, we&rsquo;ll walkthrough how to configure Microsoft Intune from scratch and use it to deploy the Zscaler Client Connector agent (ZCC) - formerly known as Zscaler Client Connector (ZCC).</p>
<p>Due to length, I&rsquo;ve split this into two posts (the orginal was over 8000 words):</p>
<ul>
<li>This post covers deployment on Windows and macOS.</li>
<li>The other post, <a href="/posts/deploy-zapp-mobile-with-intune">available here</a>, covers iOS and Android.</li>
</ul>
<p>I suggest you use the Table of Contents to jump to the section that you need.</p>
<h1 id="what-is-intune">What is Intune?</h1>
<p><a href="https://docs.microsoft.com/en-us/mem/intune/fundamentals/what-is-intune">According</a> to Microsoft:</p>
<blockquote>
<p>Microsoft Intune is a cloud-based service that focuses on mobile device management (MDM) and mobile application management (MAM).</p>
<p>With Intune, you can:</p>
<ul>
<li>Set rules and configure settings on personal and organization-owned devices to access data and networks.</li>
<li>Deploy and authenticate apps on devices &ndash; on-premises and mobile.</li>
<li>Be sure devices and apps are compliant with your security requirements.</li>
</ul>
</blockquote>
<p>In order to access Intune, you need to have either a Microsoft 365 or <a href="https://www.microsoft.com/en-au/microsoft-365/enterprise-mobility-security/compare-plans-and-pricing">Enterprise &amp; Mobility E3/E5</a> subscription. If you&rsquo;re using a free Azure account, you&rsquo;ll need to sign up to a trial, or pay per user (which can get costly).</p>
<h1 id="video-demonstration">Video Demonstration</h1>
<p>Scott Bullock of Zscaler (@scottyb) has <a href="https://community.zscaler.com/t/z-app-deployment-with-microsoft-intune/4606">posted a great 10 minute video</a> in their community forum that runs through the user experience of enrolling a fresh Windows 10 device into Intune. ZCC is automatically pushed out and transparently authenticated for both ZIA and ZPA.</p>
<h1 id="before-you-begin">Before You Begin</h1>
<p>When adding an app to Intune, you&rsquo;ll be prompted to allocate the groups of users (or devices) that the app will be rolled out to. Hence before beginning, ensure you have the users of Zscaler inside of an AD or Azure AD group that you can assign the Zscaler Client Connector app to.</p>
<p>Depending on whether you want the ZCC app to be mandatory or optional for certain groups of users, you may want to divide your users into two groups:</p>
<ol>
<li>The users to which the app is MANDATORY. Any user in this group will have the app automatically pushed out to them.</li>
<li>The users to which the app is OPTIONAL. The app will not be automatically pushed for users in this group, allowing them to go to the Company Portal and download it themselves if they choose.</li>
</ol>
<p>In my examples below, I have 3 groups:</p>
<table>
<thead>
<tr>
<th>Group</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZIA_Entitlement</td>
<td>This is the group of all users that are entitled to use Zscaler Internet Access (ZIA)</td>
</tr>
<tr>
<td>ZPA_Entitlement</td>
<td>This is the group of all users that are entitled to use Zscaler Private Access (ZPA). In my case, this is a subset of users from the ZIA_Entitlement group as I might not want to roll ZPA out to every user in the organization.</td>
</tr>
<tr>
<td>Zscaler - Mandatory</td>
<td>This group contains every user in the organization to which the ZCC app will be automatically rolled out to. Ie: The majority of users from the above two groups. If this is your organization, you might include the whole org in this group, except select users (eg: some from IT) for which the app will be optional.</td>
</tr>
</tbody>
</table>
<h1 id="microsoft-endpoint-manager">Microsoft Endpoint Manager</h1>
<p>We&rsquo;ll be using the <strong>Microsoft Endpoint Manager console</strong> (MEM) to orchestrate Intune. You can log in using the same Azure Portal credentials here: <a href="https://endpoint.microsoft.com">https://endpoint.microsoft.com</a></p>
<p><img src="1.png" alt="1"></p>
<h2 id="optional-setting-the-mdm-authority">(Optional) Setting the MDM Authority</h2>
<p>If you&rsquo;re using an existing Office 365 account <strong>and</strong> have been using the Office 365 MDM, you&rsquo;ll need to change the MDM authority from Office 365 to Intune. <a href="https://docs.microsoft.com/en-us/mem/intune/fundamentals/mdm-authority-set">This</a> Microsoft help article will guide you through it.</p>
<hr>
<h1 id="windows">Windows</h1>
<p>This section will cover deploying ZCC onto Windows using Intune.</p>
<h2 id="1-download-the-zscaler-client-connector-msi">1. Download the Zscaler Client Connector MSI</h2>
<p>To start you&rsquo;ll need the .MSI installer for ZCC from the Zscaler Client Connector Portal. Log into the portal (either through ZIA or ZPA) and navigate to <strong>Administration &gt; Zscaler Client Connector Store</strong>.</p>
<p><img src="2.png" alt="2"></p>
<p>In the <strong>Windows</strong> panel, download the <strong>MSI</strong> for the latest <strong>2.X.X</strong> version. Do not use the older 1.X.X releases.</p>
<h2 id="2-add-a-new-line-of-business-app">2. Add a new Line-of-Business App</h2>
<h3 id="add-a-new-line-of-business-lob-app">Add a new Line of Business (LoB) App</h3>
<p>Back in the <strong>Apps</strong> menu of the MEM portal, navigate to <strong>Apps &gt; All Apps &gt; Add</strong>. In the panel that appears, scroll to the bottom and under the <strong>Other</strong> heading, select <strong>Line-of-business app</strong>.</p>
<p><img src="3.png" alt="3"></p>
<p>When prompted to select an app package file, <strong>upload the MSI of the Zscaler Client Connector</strong> you downloaded above and click OK.</p>
<h3 id="customize-the-app-details">Customize the App Details</h3>
<p>Fill in the required details about the app:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Content</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Name</strong></td>
<td>Enter <strong>Zscaler Client Connector 2.X.X.X</strong> (where 2.X.X.X is the version number of the app - this will help you distinguish what version is being distributed by Intune)</td>
</tr>
<tr>
<td><strong>Description</strong></td>
<td>Enter <strong>Zscaler Client Connector</strong></td>
</tr>
<tr>
<td><strong>Publisher</strong></td>
<td>Enter <strong>Zscaler, Inc</strong></td>
</tr>
<tr>
<td><strong>Ignore app version</strong></td>
<td>Set to <strong>Yes</strong>. ZCC will automatically update itself once deployed, so Intune can safely ignore the version the user has installed after deployment.</td>
</tr>
<tr>
<td><strong>Category</strong></td>
<td>(Optional) Select an app category to allocate the Zscaler Client Connector to.</td>
</tr>
<tr>
<td><strong>Command-line arguments</strong></td>
<td>See below.</td>
</tr>
</tbody>
</table>
<p><img src="4.png" alt="4"></p>
<p>For the <strong>Command-line arguments</strong> section, enter the following (substituting in your own cloud and domain info):</p>
<pre tabindex="0"><code>CLOUDNAME=&lt;cloudname&gt; USERDOMAIN=&lt;your-custom-domain&gt;
</code></pre><p><strong>Important!</strong></p>
<ol>
<li>When entering the cloud name, DO NOT enter the <strong>.net</strong> at the end. Eg: zscalertwo.net should be entered as <code>zscalertwo</code></li>
<li>All command-line arguments should be on a single line with a space separating them. Do not linebreak each argument or they will fail.</li>
</ol>
<p>Command-line arguments can be used for each platform to customize the install. For example, <code>STRICTENFORCEMENT</code> can be used to block access to the internet until your users enroll in the Zscaler Client Connector.</p>
<p>For a list and description of all the MSI customization options, scroll down to point #5 in <a href="https://help.zscaler.com/z-app/customizing-zscaler-app-install-options-msi">this help article</a>.</p>
<p>Click <strong>Next</strong> when ready to move onto the <strong>Assignments</strong> tab.</p>
<h3 id="assign-users-to-the-app">Assign Users to the App</h3>
<p>There are two different sections you can allocate users or groups to depending on how you want the app rolled out to users:</p>
<ul>
<li><strong>Required</strong> = The app is MANDATORY for these users/groups. Any user or group in this section will have the App automatically pushed out to them.</li>
<li><strong>Available for enrolled devices</strong> = The app is OPTIONAL for these users/groups. The app will not be automatically pushed and the users can go to download the app themselves from within the Company Portal.</li>
</ul>
<p>Assign your users or groups to the ZCC app accordingly.</p>
<p><img src="5.png" alt="5"></p>
<p>Click <strong>Next</strong> to continue and then <strong>Create</strong> on the following screen. Your Line-of-Business application will be created and the MSI will upload - be sure to wait until it&rsquo;s complete.</p>
<p>Done!</p>
<hr>
<h1 id="macos">macOS</h1>
<p>This section will cover deploying ZCC onto macOS using Intune.</p>
<p>macOS requires a little bit more effort to get going than Windows does. We will need to do the following on a local macOS machine:</p>
<ol>
<li>Download the Zscaler Client Connector installer for macOS (this is a <code>.app</code> file)</li>
<li>Create a post-installation script (to customize the install of ZCC with our chosen arguments)</li>
<li>Convert the .app file and script to .pkg (Intune can only work with pkg files on macOS)</li>
<li>Wrap the .pkg file using the <a href="https://github.com/msintuneappsdk/intune-app-wrapping-tool-mac">Intune App Wrapping Tool</a> (creates an <code>.intunemac</code> file)</li>
</ol>
<blockquote>
<p><strong>If you&rsquo;re using MacOS Catalina 10.15 or higher, you MUST use ZCC v2.1.X or above.</strong> Catalina introduced the requirement that apps are notarized by their developers. Only ZCC releases v2.1 and above are notarized by Zscaler.</p>
</blockquote>
<h2 id="do-i-need-an-apple-developer-account">Do I need an Apple Developer Account?</h2>
<p><strong>An Apple Developer Account is recommended.</strong></p>
<p>You can proceed and deploy the agent <em>without</em> an Apple Developer account, however you will not be able to sign and notarize the <code>.pkg</code> file created below without a valid Developer ID. This will result in your users receiving an error about an the software coming from an &lsquo;Unidentified Developer&rsquo;, and depending on security settings, the device may block the install altogether.</p>
<p><img src="6.jpg" alt="6"></p>
<p>If you enroll in the <a href="https://developer.apple.com/enroll/">Apple Developer program</a> (US$99), you can sign and notarize your package which will make this error go away. If you&rsquo;re an organization running a macOS deployment, you will most likely have a developer account for the company already.</p>
<blockquote>
<p>But shouldn&rsquo;t Zscaler have already signed the app I&rsquo;m deploying?</p>
</blockquote>
<p>Yes, Zscaler HAS both signed and notarized the .app package that will be installed. The problem with Intune is that it can only deploy <code>.pkg</code> files to macOS; NOT <code>.app</code> files. <strong>We need to wrap our .app file inside a .pkg file for it to work with Intune, and it is <em>this</em> pkg file that needs to be signed and notarized as well.</strong></p>
<h3 id="obtaining-developer-id-certificates">Obtaining Developer ID Certificates</h3>
<p>To sign an notarize the <code>.pkg</code>, you will need both the <strong>Developer ID Installer</strong> and <strong>Developer ID Application</strong> certificates. You can create these under the <a href="https://developer.apple.com/account/resources/"><strong>Certificates, Identifiers &amp; Profiles</strong></a> section of your developer account, but will need a Certificate Signing Request (CSR) to do so: Apple have a brief guide on how to generate one using Keychain, <a href="https://help.apple.com/developer-account/#/devbfa00fef7">here</a>.</p>
<p><img src="8.png" alt="8"></p>
<p>Download the certificates when you have them and click to open the <code>.cer</code> files in Keychain. Add them as a <strong>login</strong> certificate.</p>
<p>You can check the certificates have been installed correctly by running the following command:</p>
<pre tabindex="0"><code>security find-identity -p basic -v

  1) XXXXX[REDACTED] &#34;Developer ID Installer: Nathan Catania (XXXXXXXXXX)&#34;
  2) XXXXX[REDACTED] &#34;Developer ID Application: Nathan Catania (XXXXXXXXXX)&#34;
  3) [REDACTED] &#34;[REDACTED]&#34;
     3 valid identities found
</code></pre><p>If you have the <strong>Developer ID Installer</strong> and <strong>Developer ID Application</strong> certificates, you&rsquo;re good to proceed.</p>
<h2 id="1-download-the-zscaler-client-connector-app">1. Download the Zscaler Client Connector .app</h2>
<p>To start, you&rsquo;ll need the <code>.app</code> installer for ZCC from the Zscaler Client Connector Portal.</p>
<p>Log into the portal (either through ZIA or ZPA) and navigate to <strong>Administration &gt; Zscaler Client Connector Store</strong>.</p>
<p><img src="2.png" alt="2"></p>
<p>In the <strong>macOS</strong> panel, click the download link for the latest <strong>2.X.X</strong> version. Do not use the older 1.X.X releases.</p>
<p>Unzip the file downloaded to obtain the .app installer.</p>
<h2 id="2-create-the-post-installation-script">2. Create the post-installation script</h2>
<p>Intune will push out and install the <code>.pkg</code> file - which is just our <code>.app</code> file wrapped up as a <code>.pkg</code> for the purposes of Intune deployment.</p>
<p>The problem is however, that when Intune deploys the <code>.pkg</code>, it just saves the wrapped <code>.app</code> to the user&rsquo;s device without doing anything else. We need a way to <em>run and install</em> the <code>.app</code> <em>after</em> Intune has deployed the <code>.pkg</code>, PLUS a way to include arguments to customize the install. A post-installation script will do all of this for us.</p>
<p>To start, on a macOS device <strong>open Terminal</strong>:</p>
<p>Create a folder called <code>scripts</code>. Inside this folder, create a file called <code>postinstall</code></p>
<pre tabindex="0"><code>mkdir scripts &amp;&amp; cd scripts &amp;&amp; touch postinstall &amp;&amp; pwd
...
&gt; /Users/nathan/package/scripts
</code></pre><p>Note down the full path to the <code>scripts</code> directory - we&rsquo;ll need this later.</p>
<p>Open the postinstall file for editing:</p>
<pre tabindex="0"><code>nano postinstall
</code></pre><p>Copy and paste the following into the Terminal window (modify the arguments as required):</p>
<pre tabindex="0"><code>#!/bin/sh
open /tmp/&lt;NAME-OF-ZSCALER-APP-INSTALLER&gt;.app --args --unattendedmodeui none --userDomain &lt;your-custom-domain&gt; --cloudName &lt;cloud-name&gt; --hideAppUIOnLaunch 1 --mode unattended
</code></pre><p>To exit Nano, press <code>Control + X</code> and then <code>Y</code> to save.</p>
<p>This will do a silent installation of the Zscaler Client Connector (unattended mode) and automatically redirect the user to your company SSO page to sign in.</p>
<p><strong>Important!</strong> When entering the cloud name (<code>--cloudName</code>), DO NOT enter the <strong>.net</strong> at the end. Eg: zscalertwo.net should be entered as <code>zscalertwo</code></p>
<p>Command-line arguments can be used for each platform to customize the install. For example, <code>--strictEnforcement 1</code> can be used to block access to the internet until your users enroll in the Zscaler Client Connector.</p>
<p>For a list and description of all the .app customization options, scroll down to point #4 in <a href="https://help.zscaler.com/z-app/customizing-zscaler-app-install-options-macos">this help article</a>.</p>
<p>As an example, the script for my installation looks like the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/sh
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>open /tmp/Zscaler-osx-2.1.2.38-installer.app --args --unattendedmodeui none --userDomain oblivion.industries --cloudName zscaler --hideAppUIOnLaunch <span style="color:#ae81ff">1</span> --mode unattended
</span></span></code></pre></div><p>Lastly, we need to make the script executable. Run the following in Terminal:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>chmod a+x postinstall
</span></span></code></pre></div><h2 id="3-create-the-pkg-file">3. Create the PKG file</h2>
<p>Intune only supports <code>pkg</code> files for macOS. A <code>.pkg</code> file is analogous to an MSI for Windows. All we are essentially doing is wrapping the .app file inside a .pkg file so that it can be deployed by Intune.</p>
<p>We&rsquo;ll be using the built-in <code>pkgbuild</code> tool to do this. Open Terminal and run the following command (change the file paths before running):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>pkgbuild --install-location /tmp <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--scripts /Path/to/scripts/directory <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--component <span style="color:#e6db74">&#34;/Path/to/Zscaler-Installer.app&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--sign <span style="color:#e6db74">&#34;Developer ID Installer: MY-DEV-NAME (UXXXXXXXXX)&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--identifier <span style="color:#e6db74">&#34;com.zscaler.zscalerclientconnector&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--version <span style="color:#e6db74">&#34;1.0&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span><span style="color:#e6db74">&#34;/Path/to/save/pkg-file.pkg&#34;</span>
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--install-location</code></td>
<td>This should point to the <code>tmp</code> folder, or somewhere writeable on the user machine. The <code>.pkg</code> will unpack itself here, then run the <code>.app</code> installer; which will install ZCC to the  <code>/Applications</code> directory as required. If you change this from <code>/tmp</code>, you&rsquo;ll need to update the <code>postinstall</code> script as well.</td>
</tr>
<tr>
<td><code>--scripts</code></td>
<td>This should be the path to the scripts folder you created in the step above.</td>
</tr>
<tr>
<td><code>--component</code></td>
<td>This file path should point to the Zscaler Client Connector <code>.app</code> file you downloaded in Step #1.</td>
</tr>
<tr>
<td><code>--identifier</code></td>
<td>Specify a unique identifier for this package. It is advisable to set a meaningful, consistent              identifier, eg: <strong>com. zscaler. zscalerclientconnector</strong></td>
</tr>
<tr>
<td><code>--version</code></td>
<td>This has no relationship to the actual Zscaler Client Connector version. This is only used by Intune. If you ever deploy another pkg via Intune for a different version of ZCC, you&rsquo;ll need to increment this (eg: Version 1.1) so that Intune can tell the pkg files apart. Note that ZCC has its own update mechanism, so you don&rsquo;t need to worry about using Intune to push out updates to the Zscaler Client Connector software.</td>
</tr>
<tr>
<td><code>--sign</code></td>
<td>If you don&rsquo;t want your users to recieve an error that your package is from an &lsquo;Unidentified Developer&rsquo; (which will prevent installation entirely), you will need to sign the package using a valid Apple Developer ID. To do this, you will need to enroll in the Apple Developer program (US$99). If you are an organization, you probably have already done this. Make sure you correctly substitute <code>MY-DEV-NAME</code> with your correct Developer name / org name. <strong>If you don&rsquo;t care about the &lsquo;Unidentified Developer&rsquo; error, you can remove the</strong> <code>--sign</code> <strong>argument.</strong></td>
</tr>
</tbody>
</table>
<p>The last file path listed points to the location where you want to save the output pkg file.</p>
<p>If you&rsquo;re signing the package and are not sure about your team / developer / org certificate name, you can check this under the <strong>Certificates, Identifiers &amp; Profiles</strong> section of your Apple Developer account, <a href="https://developer.apple.com/account/resources/">here</a>.</p>
<p>As an example, my completed <code>pkgbuild</code> command is below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>pkgbuild --install-location /tmp <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--scripts /Users/nathan/package/scripts <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--component <span style="color:#e6db74">&#34;/Users/nathan/package/Zscaler-osx-2.1.2.38-installer.app&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--sign <span style="color:#e6db74">&#34;Developer ID Installer: Nathan Catania (UXXXXXXXXX)&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--identifier <span style="color:#e6db74">&#34;com.zscaler.zscalerclientconnector&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--version <span style="color:#e6db74">&#34;1.0&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span><span style="color:#e6db74">&#34;/Users/nathan/package/zccinstaller.pkg&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pkgbuild: Adding component at /Users/nathan/package/Zscaler-osx-2.1.2.38-installer.app
</span></span><span style="display:flex;"><span>pkgbuild: Adding top-level postinstall script
</span></span><span style="display:flex;"><span>pkgbuild: Using timestamp authority <span style="color:#66d9ef">for</span> signature
</span></span><span style="display:flex;"><span>pkgbuild: Signing package with identity <span style="color:#e6db74">&#34;Developer ID Installer: Nathan Catania (UXXXXXXXXX)&#34;</span> from keychain
</span></span><span style="display:flex;"><span>pkgbuild: Adding certificate <span style="color:#e6db74">&#34;Developer ID Certification Authority&#34;</span>
</span></span><span style="display:flex;"><span>pkgbuild: Adding certificate <span style="color:#e6db74">&#34;Apple Root CA&#34;</span>
</span></span><span style="display:flex;"><span>pkgbuild: Wrote package to /Users/nathan/package/zccinstaller.pkg
</span></span></code></pre></div><p>If you signed your package, you can validate the signatures using <code>pkgutil</code>:</p>
<pre tabindex="0"><code>pkgutil --check-signature /path/to/pkg.pkg
</code></pre><p>For example:</p>
<pre tabindex="0"><code>pkgutil --check-signature /Users/nathan/package/zccinstaller.pkg 
Package &#34;zccinstaller.pkg&#34;:
   Status: signed by a certificate trusted by macOS X
   Certificate Chain:
    1. Developer ID Installer: Nathan Catania (UXXXXXXXXX)
       SHA1 fingerprint: E3 CB 24 EA 50 74 B6 82 EF DA 5C 43 17 8D BA D2 40 CC ED F5
       -----------------------------------------------------------------------------
    2. Developer ID Certification Authority
       SHA1 fingerprint: 3B 16 6C 3B 7D C4 B7 51 C9 FE 2A FA B9 13 56 41 E3 88 E1 86
       -----------------------------------------------------------------------------
    3. Apple Root CA
       SHA1 fingerprint: 61 1E 5B 66 2C 59 3A 08 FF 58 D1 4A E2 24 52 D1 98 DF 6C 60
</code></pre><h2 id="4-notorize-the-pkg">4. Notorize the PKG</h2>
<p><strong>You only need to do this step if you signed the <code>.pkg</code> file in the previous step.</strong> Otherwise you can skip to the next step.</p>
<p>What is notarization? According to Apple:</p>
<blockquote>
<p>Notarization gives users more confidence that the Developer ID-signed software you distribute has been checked by Apple for malicious components. If there are no issues, the notary service generates a ticket for you to staple to your software; the notary service also publishes that ticket online where Gatekeeper can find it.</p>
<p>Beginning in macOS 10.14.5, software signed with a new Developer ID certificate and all new or updated kernel extensions must be notarized to run. Beginning in macOS 10.15 [Catalina], all software built after June 1, 2019, and distributed with Developer ID must be notarized.</p>
</blockquote>
<h3 id="create-an-app-specific-password">Create an App Specific Password</h3>
<p>We&rsquo;re going to notarize the <code>.pkg</code> file via the command-line. To do this, you&rsquo;ll need to <a href="https://support.apple.com/en-us/HT204397">generate an <strong>App Specific Password</strong></a> for your the Apple ID of your Developer Account:</p>
<blockquote>
<p><strong>How to generate an app-specific password</strong></p>
<ol>
<li>Sign in to your <a href="https://appleid.apple.com/account/home">Apple ID account page</a>.</li>
<li>In the Security section, click Generate Password below App-Specific Passwords.</li>
<li>Follow the steps on your screen.</li>
</ol>
</blockquote>
<p>Next, open <strong>Keychain</strong> and click the &ldquo;+&rdquo; icon to add a new Keychain Item.</p>
<ul>
<li>For <strong>Keychain Item Name</strong>, enter <code>notarization-tool</code></li>
<li>For <strong>Account Name</strong>, enter the email associated with your Developer Account / Apple ID.</li>
<li>For <strong>Password</strong>, copy and paste the app-specific password from your Apple ID account.</li>
</ul>
<p><img src="9.png" alt="9"></p>
<h3 id="request-notorization">Request Notorization</h3>
<p>To request notarization from Apple, run the following command (replacing the values with your own):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>xcrun altool --notarize-app <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--username <span style="color:#e6db74">&#34;appleid@example.com&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--password <span style="color:#e6db74">&#34;@keychain:notarization-tool&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--asc-provider <span style="color:#e6db74">&#34;UXXXXXXXXX&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--primary-bundle-id <span style="color:#e6db74">&#34;com.zscaler.zscalerclientconnector&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--file <span style="color:#e6db74">&#34;/Path/to/pkg.pkg&#34;</span>
</span></span></code></pre></div><table>
<thead>
<tr>
<th>Field</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>username</code></td>
<td>The Apple ID username associated with your Apple Developer Account</td>
</tr>
<tr>
<td><code>password</code></td>
<td>Enter <code>@keychain:</code> followed by the name of the Keychain Item which you saved your app-specific password to. This will fetch the password from the keychain.</td>
</tr>
<tr>
<td><code>asc-provider</code></td>
<td>This is the Team ID from your Developer Account. You can find this by logging into your Developer Account and reviewing your profile</td>
</tr>
<tr>
<td><code>primary-bundle-id</code></td>
<td>This should match the identifier you specified when you created the pkg.</td>
</tr>
<tr>
<td><code>file</code></td>
<td>The path to the .pkg file</td>
</tr>
</tbody>
</table>
<p>For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>xcrun altool --notarize-app <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--username <span style="color:#e6db74">&#34;[redacted]@gmail.com&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--password <span style="color:#e6db74">&#34;@keychain:notarization-tool&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--asc-provider <span style="color:#e6db74">&#34;UXXXXXXXXX&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--primary-bundle-id <span style="color:#e6db74">&#34;com.zscaler.zscalerclientconnector&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--file <span style="color:#e6db74">&#34;/Users/nathan/package/zccinstaller.pkg&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>RequestUUID <span style="color:#f92672">=</span> 53acc70a-XXXX-XXXX-XXXX-XXXXXXXXXXXX
</span></span></code></pre></div><p>If you receive an error that the tool is not on your machine, ensure you have <a href="https://developer.apple.com/xcode/resources/">Xcode</a> and <a href="https://developer.apple.com/download/more/?=command%20line%20tools">Xcode Command-line Tools</a> installed.</p>
<p>The command will take a while to run as it is uploading your <code>.pkg</code> file to Apple. Once done, it will return a UUID which you can use to check the status of your notarization request:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>xcrun altool --notarization-info <span style="color:#e6db74">&#34;53acc70a-XXXX-XXXX-XXXX-XXXXXXXXXXXX&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--username <span style="color:#e6db74">&#34;[redacted]@gmail.com&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--password <span style="color:#e6db74">&#34;@keychain:notarization-tool&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Date: 2020-07-06 10:37:20 +0000
</span></span><span style="display:flex;"><span>Hash: <span style="color:#f92672">[</span>redacted<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>LogFileURL: https://osxapps-ssl.itunes.apple.com/itunes-assets/Enigma114/<span style="color:#f92672">[</span>redacted<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>RequestUUID: 53acc70a-XXXX-XXXX-XXXX-XXXXXXXXXXXX
</span></span><span style="display:flex;"><span>Status: success
</span></span><span style="display:flex;"><span>Status Code: <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>Status Message: Package Approved
</span></span></code></pre></div><p>Once the process is complete (mine took under 10 minutes), you&rsquo;ll recieve a confirmation email as to whether your request was successful or not.</p>
<h3 id="staple-the-notorization-ticket">Staple the Notorization Ticket</h3>
<p>The last step is to staple the notarization ticket to the <code>.pkg</code> file. This ensures that a Mac device that is offline can still validate that the <code>.pkg</code> file is notarized:</p>
<pre tabindex="0"><code>xcrun stapler staple /path/to/pkg.pkg
</code></pre><p>Note: If your command fails, wait a few minutes and try again. If your command continuously fails, and your traffic is going through ZIA or another proxy, you may need to bypass <code>api.apple-cloudkit.com</code> from SSL inspection due to certificate pinning.</p>
<p>Validate the staple action was successful:</p>
<pre tabindex="0"><code>xcrun stapler validate /path/to/pkg.pkg
</code></pre><h2 id="5-test-the-pkg">5. Test the PKG</h2>
<p>Before going further, test your PKG file by running it and seeing if it successfully installs the Zscaler Client Connector silently. Make sure you don&rsquo;t already have ZCC installed when doing this however!</p>
<p>If you have an existing installation of ZCC, you can remove it under <code>Applications/Zscaler/Uninstall-Zscaler-App</code></p>
<h2 id="6-create-an-intunemac-file">6. Create an .intunemac file</h2>
<p>Once you&rsquo;ve verified your PKG file functions correctly, we need to wrap it for use with Intune.</p>
<p>Download the <a href="https://github.com/msintuneappsdk/intune-app-wrapping-tool-mac/releases/">Intune App Wrapping Tool for Mac</a> (this is a Microsoft-owned repository).</p>
<p>Next:</p>
<ol>
<li>Unzip the source code folder</li>
<li>Open Terminal</li>
<li>Change directory to where the <code>IntuneAppUtil</code> file is located</li>
<li>Make the <code>IntuneAppUtil</code> file executable:</li>
</ol>
<pre tabindex="0"><code>chmod +x IntuneAppUtil
</code></pre><p>Locate the PKG file you created above and use the <code>IntuneAppUtil</code> tool to wrap the <code>.pkg</code> file to a <code>.intunemac</code> file:</p>
<pre tabindex="0"><code>./IntuneAppUtil -v -c /path/to/zscaler-installer.pkg -o /output/directory/path
</code></pre><p>For example:</p>
<pre tabindex="0"><code>./IntuneAppUtil -c /Users/nathan/package/zappinstaller.pkg -o /Users/nathan/package

...
Creating intunemac file for /Users/nathan/Downloads/Zscaler-osx-2.1.2.38-installer.pkg
Composing the intunemac file output
Output written to /Users/nathan/Downloads/ZscalerInstaller.pkg.intunemac.

IntuneAppUtil successfully processed &#34;ZscalerInstaller.pkg&#34;,
to deploy refer to the product documentation.
</code></pre><p>If everything went well, you should see the <code>.intunemac</code> file in your specified output directory.</p>
<h2 id="7-add-a-new-line-of-business-app-in-mem">7. Add a new Line-of-Business app in MEM</h2>
<h3 id="add-a-new-line-of-business-lob-app-1">Add a new Line of Business (LoB) App</h3>
<p>In the <strong>Apps</strong> menu of the <a href="https://endpoint.microsoft.com/">MEM portal</a>, navigate to <strong>Apps &gt; All Apps &gt; Add</strong>. In the panel that appears, scroll to the bottom and under the <strong>Other</strong> heading, select <strong>Line-of-business app</strong>.</p>
<p><img src="3.png" alt="3"></p>
<p>When prompted to select an app package file, <strong>upload the</strong> <code>.intunemac</code> <strong>file you created above</strong> and click OK.</p>
<h3 id="customize-the-app-details-1">Customize the App Details</h3>
<p>Fill in the required details about the app:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Content</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Name</strong></td>
<td>Enter <strong>Zscaler Client Connector 2.X.X.X - macOS 2.X.X.X</strong> (where 2.X.X.X is the version number of the app - this will help you distinguish what version is being distributed by Intune)</td>
</tr>
<tr>
<td><strong>Description</strong></td>
<td>Enter <strong>Zscaler Client Connector for macOS</strong></td>
</tr>
<tr>
<td><strong>Publisher</strong></td>
<td>Enter <strong>Zscaler, Inc</strong></td>
</tr>
<tr>
<td><strong>Minimum operating system</strong></td>
<td>Select <strong>OS X Yosemite 10.10</strong> (ZCC supports macOS 10.10+)</td>
</tr>
<tr>
<td><strong>Ignore app version</strong></td>
<td>Set to <strong>Yes</strong>. ZCC will automatically update itself once deployed, so Intune can safely ignore the version the user has installed after deployment.</td>
</tr>
<tr>
<td><strong>Category</strong></td>
<td>(Optional) Select an app category to allocate the Zscaler Client Connector to.</td>
</tr>
</tbody>
</table>
<p><img src="7.png" alt="7"></p>
<p>Click <strong>Next</strong> to move to the <strong>Assignments</strong> tab.</p>
<h3 id="assign-users-to-the-app-1">Assign Users to the App</h3>
<p>There are two different sections you can allocate users or groups to depending on how you want the app rolled out to users:</p>
<ul>
<li><strong>Required</strong> = The app is MANDATORY for these users/groups. Any user or group in this section will have the App automatically pushed out to them.</li>
<li><strong>Available for enrolled devices</strong> = The app is OPTIONAL for these users/groups. The app will not be automatically pushed and the users can go to download the app themselves from within the Company Portal.</li>
</ul>
<p>Assign your users or groups to the ZCC app for macOS accordingly.</p>
<p><img src="5.png" alt="5"></p>
<p>Click <strong>Next</strong> to continue and then <strong>Create</strong> on the following screen. Your macOS Line-of-Business application will be created and the <code>.intunemac</code> file will upload - be sure to wait until it&rsquo;s complete.</p>
<p>Done!</p>
]]></content>
        </item>
        
        <item>
            <title>Integrate Zscaler with Azure Sentinel</title>
            <link>https://nathancatania.com/posts/integrate-zia-with-azure-sentinel/</link>
            <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/integrate-zia-with-azure-sentinel/</guid>
            <description>Azure Sentinel is a cloud-based SIEM solution by Microsoft. Zscaler Internet Access (ZIA) integrates with a wide variety of SIEM solutions, and Sentinel is no different. In this guide, we&amp;rsquo;ll walk through how to configure ZIA to send logs in real-time to Sentinel.
Caution! Be very careful if you&amp;rsquo;re deploying this as part of a demo or lab environment as the costs we will incur can ramp up quickly! You will incur charges for one new VM as part of this guide (in addition to an existing NSS VM if you also deployed it in Azure), PLUS data ingestion charges for an Azure Sentinel workspace.</description>
            <content type="html"><![CDATA[<p>Azure Sentinel is a cloud-based SIEM solution by Microsoft. Zscaler Internet Access (ZIA) integrates with a wide variety of SIEM solutions, and Sentinel is no different. In this guide, we&rsquo;ll walk through how to configure ZIA to send logs in real-time to Sentinel.</p>
<blockquote>
<p><strong>Caution!</strong> Be very careful if you&rsquo;re deploying this as part of a demo or lab environment as the costs we will incur can ramp up quickly! You will incur charges for one new VM as part of this guide (in addition to an existing NSS VM if you also deployed it in Azure), PLUS data ingestion charges for an Azure Sentinel workspace.</p>
</blockquote>
<h1 id="requirements">Requirements</h1>
<h2 id="1-zscaler-nss">1. Zscaler NSS</h2>
<p>To stream Zscaler logs to Sentinel, you will need to have deployed Zscaler&rsquo;s Nanolog Streaming Service (NSS) VM and configured it in the ZIA admin portal. This will allow you to stream logs from Zscaler&rsquo;s logging clusters (called Nanolog) towards a SIEM or product of your choice (in this case, Sentinel).</p>
<p><strong>Nanolog Streaming Service</strong> is an option under the Administration panel in ZIA. If you don&rsquo;t see it there, check that your subscription contains the NSS feature.</p>
<p>You can deploy the VM for NSS on-prem (available as an OVA image) or in AWS or Azure. <strong>For Sentinel integration, I  strongly recommend you deploy NSS in Azure</strong>: you can <a href="/posts/deploy-zscaler-nss-in-azure/">review my guide on how to do so here</a>. Zscaler documentation is available for <a href="https://help.zscaler.com/zia/nss-deployment-guide-vmware-vsphere">VMware</a> and <a href="https://help.zscaler.com/zia/nss-deployment-guide-amazon-web-services">AWS</a>.</p>
<p>Your NSS VM must have a state of <strong>Healthy</strong> to be able to integrate with Sentinel.</p>
<p><img src="0.png" alt="0"></p>
<blockquote>
<p>Why do I need to deploy a VM to stream logs to a SIEM? Can&rsquo;t Zscaler just send logs to my SIEM directly?</p>
</blockquote>
<p>Your logs are stored in Zscaler&rsquo;s Nanolog clusters in a highly compressed and encoded format. For security reasons, the logging cluster has no mechanism to decode these before they are sent. The NSS VM connects to both the Nanolog cluster and the Zscaler control plane, grabs the logs, decodes them, and forwards them to your SIEM over a TCP connection.</p>
<h2 id="2-azure-subscription--administrator-credentials">2. Azure Subscription + Administrator Credentials</h2>
<p>As part of this guide, we will be creating a small VM that will ingest our logs into Sentinel, and a Log Analytics Workspace to store our ingested data. Both of these will result in billable charges (VM running costs + storage for the logs), hence you will need an active Azure billing subscription and administrator access to your Azure Portal.</p>
<h1 id="configure-sentinel">Configure Sentinel</h1>
<p>In this section, we will cover the Azure-specific configuration required for Sentinel integration; including:</p>
<ul>
<li>Deploying a Data Connector VM</li>
<li>Creating &amp; Configuring a Sentinel Instance</li>
<li>Configuring the Zscaler Connector in Sentinel</li>
</ul>
<h2 id="1-create-the-data-connector-vm">1. Create the Data Connector VM</h2>
<p>In order to ingest Zscaler logs into Sentinel, we need to deploy a &ldquo;Data Connector VM&rdquo;. This VM will run the Microsoft agent required to send log messages to Sentinel and will be the destination to which we will stream the Zscaler logs from NSS.</p>
<blockquote>
<p>Why do I need all these VMs? First I had to deploy NSS, and now I need this Data Connector VM! Why can&rsquo;t I just send logs straight from Zscaler to Azure Sentinel?</p>
</blockquote>
<p>I talked briefly about why NSS is required for log streaming above. Think of it as an intermediate log gateway.</p>
<p>NSS forwards the uncompressed logs via a TCP connection towards one or more destinations (as defined by you in the ZIA portal). Sentinel doesn&rsquo;t have an open endpoint that you can stream to, hence we need to create one in the form of the Data Connector VM.</p>
<h3 id="create-a-new-virtual-machine">Create a new Virtual Machine</h3>
<p>To start, from the Azure Portal, search for or select <strong>Virtual Machines</strong>.</p>
<p><img src="1.png" alt="1"></p>
<p>Click <strong>Add</strong> to create a new <strong>Virtual Machine</strong>.</p>
<p><img src="2.png" alt="2"></p>
<p>On the next screen, populate the basic info for your new VM.</p>
<ul>
<li>For the Image / OS, select the latest Ubuntu Server LTS version (currently 18.04 LTS).</li>
<li>For the VM size, you shouldn&rsquo;t need anything too big. I used <strong>Standard B2s</strong>, which provides 2 vCPUs and 4GB memory.
<ul>
<li>If you are expecting data from a large number of users, I would pick a size with 8GB memory (or 16GB if you have more than 45,000 users in your organization).</li>
</ul>
</li>
<li>If you deployed your NSS instance in Azure (and I highly recommend that you do), you should try and use the same Resource Group and vNet as the NSS VM.</li>
<li><strong>Note down the username for the VM</strong> as you will be unable to connect to the VM later on without this. You can change this to whatever you like.</li>
</ul>
<p>My basic settings are shown in the screenshot below:</p>
<p><img src="3.png" alt="3"></p>
<p>For disks:</p>
<ul>
<li>You won&rsquo;t need a great deal of disk space and shouldn&rsquo;t need any additional data disks beyond the OS disk.</li>
<li>I would definitely recommend an SSD over HDD for the faster IO as the VM will be handling logs.</li>
</ul>
<p>For Networking:</p>
<ul>
<li>If you deployed your NSS VM in Azure, try and use the same vNet and Subnet for the Data Connector VM as the NSS Service Interface.</li>
<li>The data connector <strong>must</strong> have <strong>TCP 514 open inbound</strong>. You will want to restrict this to only accept connections from the source IP of your NSS VM. If you deployed NSS in Azure, this will the private IP of the <strong>service interface of the NSS VM</strong>; most likely a 10.0.0.0/24 address.</li>
<li>You may also want to enable inbound access on port 22 from your own source IP so you can SSH to and configure the VM.</li>
</ul>
<p>On the <strong>Networking</strong> tab, select <strong>Advanced</strong> for <strong>NIC network security group</strong>, and then click <strong>Create new</strong>, to create a new Network Security Group (NSG).</p>
<p><img src="4.png" alt="4"></p>
<p>If you&rsquo;re not familiar with NSGs, think of them as a firewall. We&rsquo;re going to define rules to allow/deny connectivity to and from our VM.</p>
<p>In the screenshot below, I&rsquo;ve created 3 rules:</p>
<ul>
<li>Permit inbound SSH access from my own IP address to the Data Connector VM.
<ul>
<li>There should be a default SSH rule already, but you may want to modify it to restrict access from your own source IP address. Else, anyone will be able to hit your VM on port 22.</li>
</ul>
</li>
<li>Permit inbound connectivity on TCP port 514 from the source IP of my NSS VM&rsquo;s service interface (10.0.0.4 in the example screenshot below).
<ul>
<li>This rule is absolutely <strong>critical</strong> if you want Sentinel integration to work.</li>
</ul>
</li>
<li>Permit outbound connectivity to all destinations for internet access on the VM.
<ul>
<li>NSGs should have a default outbound rule already, but in the example below I explicitly created the rule for illustration purposes.</li>
</ul>
</li>
</ul>
<p><img src="5.png" alt="5"></p>
<p>Once you&rsquo;ve configured your NSG, save and create your VM once you&rsquo;re satisfied with the rest of your settings. Once provisioned, you will see the Data Connector VM running alongside any existing VMs in your portal:</p>
<p><img src="7.png" alt="7"></p>
<h3 id="connect-to-the-data-connector-vm">Connect to the Data Connector VM</h3>
<p>We will SSH to our new VM to verify connectivity and prepare it for the configuration package to be installed later.</p>
<pre tabindex="0"><code>ssh &lt;username&gt;@&lt;DataConnectorVM-IP&gt;

...
Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 5.3.0-1032-azure x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage
 
nathan@SentinelDataConnector:~$
</code></pre><p>First, check you have connectivity to the internet:</p>
<pre tabindex="0"><code>nathan@SentinelDataConnector:~$ ping 1.1.1.1
...
PING 1.1.1.1 (1.1.1.1) 56(84) bytes of data.
64 bytes from 1.1.1.1: icmp_seq=1 ttl=56 time=1.26 ms

--- 1.1.1.1 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.261/1.261/1.261/0.000 ms
</code></pre><p>Next, check you have connectivity to the NSS VM (specifically the service interface). For me, this is 10.0.0.4 in the same vNet:</p>
<pre tabindex="0"><code>nathan@SentinelDataConnector:~$ ping 10.0.0.4
...
PING 10.0.0.4 (10.0.0.4) 56(84) bytes of data.
64 bytes from 10.0.0.4: icmp_seq=1 ttl=64 time=1.40 ms
^C
--- 10.0.0.4 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.408/1.408/1.408/0.000 ms
</code></pre><p>Lastly, fetch the latest updates for the VM and install them. Reboot the VM when you&rsquo;re finished for good measure.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>nathan@SentinelDataConnector:~$ sudo apt-get update <span style="color:#f92672">&amp;&amp;</span> apt-get dist-upgrade
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>nathan@SentinelDataConnector:~$ sudo reboot
</span></span></code></pre></div><h3 id="troubleshooting-vm-connectivity">Troubleshooting VM Connectivity</h3>
<p>If you can&rsquo;t SSH to your VM, have no outbound/internet connectivity, or can&rsquo;t reach the NSS VM, then your first point of  call should be checking the Network Security Group you assigned to the VM.</p>
<p>You can edit the NSG by searching for &ldquo;Network Security Groups&rdquo; in the Azure Portal. Select your NSG, and alter or add to the inbound and outbound rules as required.</p>
<p><img src="6.png" alt="6"></p>
<p>For SSH, you must enable destination port TCP 22 in the inbound direction. If you&rsquo;re restricting this to your source IP, you could temporarily open this up to any IP, but I would revert this once you gain connectivity as this exposes the VM to the broader internet. If you&rsquo;re still having issues connecting via SSH, check that the IP assigned to the VM is correct, wait a little bit longer for the VM to finish booting (although this should be quick), or restart the VM from the Azure Virtual Machines menu.</p>
<p>For connectivity to the NSS VM: If you&rsquo;ve deployed the NSS VM in Azure, connectivity should be covered by the default<code>AllowVnetOutBound</code> outbound rule, although you may wish to explicitly define a rule restricting TCP 514 from the source IP of the NSS VM only.</p>
<p>Allowing internet access should be one of the default outbound rules, <code>AllowInternetOutBound</code>, but you should verify this rule is set to <code>Allow</code> and is above the <code>DenyAllOutBound</code> rule.</p>
<p>Rule order matters when working with NSGs. Rules are evaluated top-to-bottom and on a &ldquo;first match&rdquo; basis. Your own rules should all have low priority values so that they don&rsquo;t get overwritten by the default rules at the bottom of the list. Specifically, make sure the priority of your rules is <strong>less than</strong> 65000.</p>
<h2 id="2-optional-create-a-sentinel-instance">2. (Optional) Create a Sentinel Instance</h2>
<p>Once the Data Connector VM has been configured we can move on to creating a Sentinel Instance. If you already have an existing Sentinel Instance, you can skip this step.</p>
<p>In your Azure Portal, search for &ldquo;<strong>Azure Sentinel</strong>&rdquo;.</p>
<p><img src="8.png" alt="8"></p>
<p>Click <strong>Add</strong> to connect a new workspace.</p>
<p><img src="9.png" alt="9"></p>
<p>Click <strong>Create a new workspace</strong>.</p>
<p><img src="10.png" alt="10"></p>
<p>On the next screen, select a Resource Group, region, and give your workspace a globally unique name. When you&rsquo;re ready, review your config and create the workspace.</p>
<p><img src="11.png" alt="11"></p>
<p>You should now see your new workspace listed under your Azure Sentinel workspaces (if you&rsquo;ve lost this screen, simply search for the &ldquo;Azure Sentinel&rdquo; app again at the top of the Azure Portal).</p>
<h2 id="3-configure-the-zscaler-connector--data-connector-vm">3. Configure the Zscaler Connector &amp; Data Connector VM</h2>
<p>In this section, we will enable the Zscaler Connector for Azure Sentinel and copy the config needed by the Data Connector VM.</p>
<h3 id="copy-the-configuration-command">Copy the Configuration Command</h3>
<p>Select your workspace from your list of Sentinel workspaces (if you&rsquo;ve lost this screen, simply search for the &ldquo;Azure Sentinel&rdquo; app again at the top of the Azure Portal).</p>
<p><img src="12.png" alt="12"></p>
<p>Under <strong>Configuration</strong> in the left-side menu of your Sentinel workspace, select <strong>Data connectors</strong>.</p>
<p><img src="13.png" alt="13"></p>
<p>In the search box, type &ldquo;<strong>Zscaler</strong>&rdquo; to filter down the list of available data connectors. Select the <strong>Zscaler</strong> connector and click <strong>Open connector page</strong> to add and configure it.</p>
<p><img src="14.png" alt="14"></p>
<p>Under the <strong>Configuration</strong> section, copy the command highlighted in the screenshot below (this is unique to your Sentinel instance).</p>
<p><img src="15.png" alt="15"></p>
<h3 id="configure-the-data-connector-vm">Configure the Data Connector VM</h3>
<p>Connect back to the Data Connector VM you provisioned earlier:</p>
<pre tabindex="0"><code>ssh &lt;username&gt;@&lt;DataConnectorVM-IP&gt;

...
nathan@SentinelDataConnector:~$
</code></pre><p>Paste in and execute the command you copied above from the Zscaler Connector configuration page:</p>
<pre tabindex="0"><code>nathan@SentinelDataConnector:~$ sudo wget https://raw.githubusercontent.com/Azure/Azure-Sentinel/master/DataConnectors/CEF/cef_installer.py&amp;&amp;sudo python cef_installer.py [snip]
...
...
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.28.133
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.28.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
...
...
Restarting rsyslog daemon.
sudo service rsyslog restart
Rsyslog daemon restarted successfully
Trying to restart omsagent
Omsagent restarted successfully
Installation completed
nathan@SentinelDataConnector:~$ 
</code></pre><p>Note: I&rsquo;ve included part of the command above as an example. Don&rsquo;t copy and paste this though as it won&rsquo;t work for you. Copy and paste it from the config page of the Zscaler Connector - the command contains a token that is unique to you.</p>
<h3 id="verifying-connectivity">Verifying Connectivity</h3>
<p>If everything was installed and is running correctly, the Data Connector VM should be listening on TCP 514:</p>
<pre tabindex="0"><code>root@SentinelDataConnector:~# netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address      Foreign Address    State       PID/Program name    
tcp        0      0 127.0.0.1:25226    0.0.0.0:*          LISTEN      107202/ruby         
tcp        0      0 0.0.0.0:25324      0.0.0.0:*          LISTEN      107202/ruby         
tcp        0      0 127.0.0.53:53      0.0.0.0:*          LISTEN      97325/systemd-resol 
tcp        0      0 0.0.0.0:22         0.0.0.0:*          LISTEN      1617/sshd           
tcp        0      0 0.0.0.0:514        0.0.0.0:*          LISTEN      107103/rsyslogd     
</code></pre><p>You may need to run the above as the <code>root</code> user to see the program name.</p>
<p>You should also see the Azure collector agent running (as two ruby scripts).</p>
<h3 id="troubleshooting">Troubleshooting</h3>
<p>Back on the Zscaler Connector page, there is a second command available to troubleshoot the data connector and Azure collection scripts. Scroll down and copy/paste the second command at the bottom of the page.</p>
<p><img src="16.png" alt="16"></p>
<p>This will check connectivity and restart the rsyslog and collection processes.</p>
<h1 id="configure-the-zscaler-log-feeds">Configure the Zscaler Log Feeds</h1>
<p>If you have reached this point without issue, well done! We&rsquo;re almost there! In this section, we&rsquo;ll configure the NSS log feed required to send data to Sentinel.</p>
<p>An NSS log feed specifies the data you wish to stream from Nanolog: You can stream everything, or filter the data to only receive what you care about (security events, information relating to a specific user, etc).</p>
<p>Note that there are two types of NSS VM deployments: One dedicated to Web Logs, and the other dedicated to Firewall Logs. You pick the type when you first deploy an NSS VM. While Sentinel can ingest both web and firewall logs, this guide will only focus on web logs. To stream firewall logs, you will need to deploy a second NSS VM and associate it with the <strong>Firewall</strong> log type. A single NSS instance can only stream one type of logs: either web or firewall; not both.</p>
<p>Streaming both types of logs to Sentinel is recommended to give you the biggest dataset to work with. If you decide to go down this path, only a single instance of the Data Connector VM is needed, although you may also wish to deploy a second one to keep a logical separation between log streaming components (and to help with scale if you are a larger organization).</p>
<h2 id="add-a-new-nss-feed">Add a New NSS Feed</h2>
<p>In your ZIA portal, navigate to <strong>Administration &gt; Nanolog Streaming Service</strong>.</p>
<p><img src="17.png" alt="17"></p>
<p>Select the <strong>NSS Feeds</strong> tab, then select <strong>Add NSS Feed</strong>.</p>
<p><img src="18.png" alt="18"></p>
<p>Fill in the feed details as per the below table:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feed Name</td>
<td>Unique name for the feed, eg: &ldquo;Azure Sentinel&rdquo;</td>
</tr>
<tr>
<td>NSS Server</td>
<td>The NSS VM that will be responsible for fetching and streaming the logs for this feed. Ideally, this should be deployed in Azure as a VM.</td>
</tr>
<tr>
<td>SIEM IP Address</td>
<td><strong>The IP address of the Data Connector VM.</strong> Mine was in the same vNet as my NSS VM and was set to 10.0.0.5.</td>
</tr>
<tr>
<td>SIEM TCP Port</td>
<td>The TCP port to stream the logs to. Set this to port <strong>514</strong>.</td>
</tr>
<tr>
<td>Log Type</td>
<td>This field will vary depending on the type of NSS VM you have associated (ie: Web or Firewall log streaming). Ensure <strong>Web Log</strong> is selected if you are using an NSS for Web VM.</td>
</tr>
<tr>
<td>Feed Output Type</td>
<td><strong>Custom</strong></td>
</tr>
</tbody>
</table>
<p><img src="19.png" alt="19"></p>
<p>Ensure the Feed Output type is set to <strong>Custom</strong>. In the <strong>Feed Output Format</strong> text field, delete any pre-populated template, and paste in one of the following.</p>
<p>For Web logs:</p>
<pre tabindex="0"><code>%s{mon} %02d{dd} %02d{hh}:%02d{mm}:%02d{ss} zscaler-nss
CEF:0|Zscaler|NSSWeblog|5.7|%s{action}|%s{reason}|3| act=%s{action}
reason=%s{reason} app=%s{proto} dhost=%s{ehost} dst=%s{sip} src=%s{cintip}
sourceTranslatedAddress=%s{cip} in=%d{respsize} out=%d{reqsize}
request=%s{eurl} requestContext=%s{ereferer} outcome=%s{respcode}
requestClientApplication=%s{ua} requestMethod=%s{reqmethod}
suser=%s{login} spriv=%s{location} externalId=%d{recordid}
fileType=%s{filetype} destinationServiceName=%s{appname} cat=%s{urlcat}
deviceDirection=1 cn1=%d{riskscore} cn1Label=riskscore cs1=%s{dept}
cs1Label=dept cs2=%s{urlcat} cs2Label=urlcat cs3=%s{malwareclass}
cs3Label=malwareclass cs4=%s{malwarecat} cs4Label=malwarecat
cs5=%s{threatname} cs5Label=threatname cs6=md5hash cs6Label=%s{bamd5}
rulelabel=%s{rulelabel} ruletype=%s{ruletype} urlclass=%s{urlclass}
devicemodel=%s{devicemodel}\n
</code></pre><p>For Firewall logs:</p>
<pre tabindex="0"><code>%s{mon} %02d{dd} %02d{hh}:%02d{mm}:%02d{ss} zscaler-nss-fw
CEF:0|Zscaler|NSSFWlog|5.7|%s{action}|%s{rulelabel}|3| act=%s{action}
suser=%s{login} src=%s{csip} spt=%d{csport} dst=%s{cdip} dpt=%d{cdport}
deviceTranslatedAddress=%s{ssip} deviceTranslatedPort=%d{ssport}
destinationTranslatedAddress=%s{sdip} destinationTranslatedPort=%d{sdport}
sourceTranslatedAddress=%s{tsip} sourceTranslatedPort=%d{tsport}
proto=%s{ipproto} tunnelType=%s{ttype} dnat=%s{dnat} stateful=%s{stateful}
spriv=%s{location} reason=%s{rulelabel} in=%ld{inbytes} out=%ld{outbytes}
deviceDirection=1 cs1=%s{dept} cs1Label=dept cs2=%s{nwsvc}
cs2Label=nwService cs3=%s{nwapp} cs3Label=nwApp cs4=%s{aggregate}
cs4Label=aggregated cs5=%s{threatcat} cs5Label=threatcat
cs6=%s{threatname} cs6label=threatname cn1=%d{durationms}
cn1Label=durationms cn2=%d{numsessions} cn2Label=numsessions
cs5Label=ipCat cs5=%s{ipcat} destCountry=%s{destcountry}
avgduration=%d{avgduration}\n
</code></pre><p>Scroll to the bottom of the window to define filters for the data (if required). By default, everything will be streaming to Sentinel.</p>
<p>When you have finished, click <strong>Save</strong> and <strong>Activate</strong> your changes.</p>
<h2 id="optional-check-nss">(Optional) Check NSS</h2>
<p>You may want to log into the NSS VM and check that it has picked up the new feed. NSS will usually take under 5-10 minutes to pick up the feed, but in some circumstances, this can take up to an hour.</p>
<p>SSH or connect to your NSS VM, and run the following command to check the feed status:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss troubleshoot feeds
...
NSS is live 
Currently active feeds: 1
Feed name: Azure Sentinel:
  Connection Status:
	[10.0.0.4:9471 -&gt; 10.0.0.5:514] : Stable
  Other health checks:
	Feed is stable. No suspicious events detected.
</code></pre><p>Note that this command may take a few minutes to run.</p>
<p>Here we can see that the feed called <code>Azure Sentinel</code> that I created above has been picked up by my NSS VM; and is in an active and stable state. The Service Interface of my NSS VM has an IP of 10.0.0.4. My Data Connector VM has an IP of 10.0.0.5, and we can see the NSS VM sending data to this IP on TCP 514; exactly as we configured the feed to.</p>
<h1 id="examine-the-data">Examine the Data</h1>
<p>There are 4 workbook templates available in Sentinel that can be used to explore and visualize the data obtained from Zscaler:</p>
<table>
<thead>
<tr>
<th>Workbook</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Zscaler Firewall</td>
<td>Explore all cloud firewall activity in your Zscaler instance including non-web related networking events, security events, firewall rules, and bandwidth consumption.</td>
</tr>
<tr>
<td>Zscaler Office 365 Apps</td>
<td>Explore the Microsoft apps running on your network and their bandwidth consumption. It also helps identify phishing attempts in which attackers disguised themselves as Microsoft services.</td>
</tr>
<tr>
<td>Zscaler Threats</td>
<td>Visualize your threat landscape including blocked malware, IPS/AV rules, and blocked cloud apps. Threats are displayed by threat categories, filetypes, inbound vs outbound threats, usernames, user location, and more.</td>
</tr>
<tr>
<td>Zscaler Web Overview</td>
<td>Visualize security and networking events related to web transactions, types of devices, and bandwidth consumption.</td>
</tr>
</tbody>
</table>
<p>In your Sentinel instance, select <strong>Workbooks</strong> from the left-side menu, and search for <strong>Zscaler</strong>.</p>
<p><img src="20.png" alt="20"></p>
<p>Select a workbook, and click <strong>View Template</strong> to explore your data. Click <strong>Save</strong> to create a copy of the workbook template.</p>
<p><img src="21.png" alt="21"></p>
<p>If you&rsquo;re not seeing any data populate into the workbook, check your NSS VM as per the above section. In rare circumstances, it can take up to an hour for the feed to be picked up by NSS once defined in the ZIA portal.</p>
<p>You should also verify that your Network Services Group applied to the NSS and Data Connector VMs permits the two to talk. The Data Connector VM requires an <strong>inbound</strong> rule on port 514, otherwise the traffic will be blocked by default.</p>
<blockquote>
<p><strong>Caution!</strong> If you are running this in a lab environment, you will be racking up three sets of charges: The NSS VM (if you deployed it in Azure), the Data Connector VM, and charges to ingest the logs into Azure Sentinel. You may wish to toggle the VMs on and off as needed to avoid racking up large usage charges!</p>
</blockquote>
<h1 id="finish">Finish</h1>
<p>Congratulations! You have now integrated Zscaler Internet Access with your Azure Sentinel SIEM instance!</p>
<p>If you deployed this for lab or demo purposes, <strong>make sure you don&rsquo;t forget about the running NSS and Data Connector VMs!</strong> Ensure you stop and de-allocate resources after you&rsquo;re done so you don&rsquo;t continue to be charged.</p>
]]></content>
        </item>
        
        <item>
            <title>Integrate Zscaler with Microsoft Cloud App Security (MCAS)</title>
            <link>https://nathancatania.com/posts/integrate-zia-and-mcas/</link>
            <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/integrate-zia-and-mcas/</guid>
            <description>Microsoft Cloud App Security (MCAS) is Microsoft&amp;rsquo;s CASB product. We can integrate this with Zscaler Internet Access (ZIA) - and vice-versa.
ZIA will be able to pull data from MCAS under the Cloud Applications dashboard, and MCAS will be able to push custom URL categories to your ZIA tenant for your specified sanctioned/unsanctioned applications - which you can then configure allow/coach/block rules for Zscaler to enforce as required.
You must have a subscription for both MCAS and Zscaler&amp;rsquo;s Nanolog Streaming Service (NSS) to be able to integrate the two products.</description>
            <content type="html"><![CDATA[<p>Microsoft Cloud App Security (MCAS) is Microsoft&rsquo;s CASB product. We can integrate this with Zscaler Internet Access (ZIA) - and vice-versa.</p>
<p>ZIA will be able to pull data from MCAS under the Cloud Applications dashboard, and MCAS will be able to push custom URL categories to your ZIA tenant for your specified sanctioned/unsanctioned applications - which you can then configure allow/coach/block rules for Zscaler to enforce as required.</p>
<p>You must have a subscription for both MCAS and Zscaler&rsquo;s Nanolog Streaming Service (NSS) to be able to integrate the two products.</p>
<h1 id="requirements">Requirements</h1>
<h2 id="1-zscaler-nss">1. Zscaler NSS</h2>
<p>To stream Zscaler logs to MCAS, you will need to have deployed and configured Zscaler&rsquo;s Nanolog Streaming Service (NSS) in the ZIA admin portal - this allows you to stream logs from their logging clusters (called Nanolog) towards a SIEM or product of your choice (in this case, MCAS).</p>
<p>You can deploy the VM for NSS on-prem (available as an OVA image) or in AWS or Azure (Azure is strongly recommended).</p>
<p>For deployment in Azure, you can <a href="/posts/deploy-zscaler-nss-in-azure/">review my guide here</a>.</p>
<p>Zscaler documentation is available for <a href="https://help.zscaler.com/zia/nss-deployment-guide-vmware-vsphere">VMware</a> and <a href="https://help.zscaler.com/zia/nss-deployment-guide-amazon-web-services">AWS</a>.</p>
<p>Your NSS VM must have a state of <strong>Healthy</strong> to be able to integrate with MCAS.</p>
<p><img src="0.png" alt="0"></p>
<p>NB: Your NSS VM must have at least 8GB of memory for MCAS integration. If you&rsquo;re running a 4GB instance as a demo/lab NSS VM, this will not work and you&rsquo;ll need to deploy another instance with at 8GB assigned.</p>
<h2 id="2-zscaler-mcas-nss-feed">2. Zscaler MCAS NSS Feed</h2>
<p>Once you have deployed Zscaler NSS above, you&rsquo;ll also need to have an MCAS Feed configured before you can properly integrate with MCAS.</p>
<p>An NSS feed specifies the data you wish to stream from Nanolog: You can stream everything, or filter the data to only receive what you care about (security events, information relating to a specific user, etc).</p>
<p>An MCAS NSS Feed, is an NSS Feed specifically pre-formatted for ingestion into MCAS.</p>
<h3 id="add-a-new-mcas-nss-feed">Add a New MCAS NSS Feed</h3>
<p>In your ZIA portal, navigate to <strong>Administration &gt; Nanolog Streaming Service</strong>.</p>
<p><img src="1.png" alt="1"></p>
<p>Select the <strong>NSS Feeds</strong> tab, then select <strong>Add MCAS NSS Feed</strong>.</p>
<p><img src="2.png" alt="2"></p>
<p>Give the feed a name, select the NSS Server / VM instance that is associated with streaming this feed, and make sure you set the feed to <strong>Enabled</strong>. You can optionally define filters for the feed at the bottom of the panel. By default, EVERYTHING will be streamed to MCAS.</p>
<p><img src="3.png" alt="3"></p>
<p>When you are done, click <strong>Save</strong>, then <strong>Activate</strong> your changes. This will apply the feed to the NSS VM you selected.</p>
<h1 id="configure-mcas">Configure MCAS</h1>
<p>In this section, we&rsquo;ll focus on the MCAS specific config, including:</p>
<ul>
<li>Generating an API token</li>
<li>Setting at least 1 app as unsanctioned</li>
<li>Adding NSS as a data source</li>
</ul>
<h2 id="access-the-mcas-portal">Access the MCAS Portal</h2>
<p>You can access your MCAS Dashboard at the following link:
<a href="https://portal.cloudappsecurity.com/">https://portal.cloudappsecurity.com/</a></p>
<p>Alternatively, you access MCAS via the <a href="https://security.microsoft.com/">Microsoft 365 Admin Center</a>, under Security &gt; More Resources &gt; Cloud App Security.</p>
<h2 id="generate-an-mcas-api-token">Generate an MCAS API Token</h2>
<p>From the MCAS dashboard, click the <strong>Settings</strong> icon at the top right, and select <strong>Security extensions</strong>.</p>
<p><img src="4.png" alt="4"></p>
<p>On the <strong>API tokens</strong> tab, click the + icon to create a new token.</p>
<p><img src="5.png" alt="5"></p>
<p>Give the token a name (eg: <code>Zscaler Integration</code>) and click <strong>Generate</strong>.</p>
<p><strong>Note down both the API token and URL</strong> on screen as you will need these later! After you close this window, the token will NOT be shown again.</p>
<h2 id="configure-an-unsanctioned-app">Configure an Unsanctioned App</h2>
<p>To verify that the integration is working correctly, you must <a href="https://docs.microsoft.com/en-us/cloud-app-security/governance-discovery">configure at least one unsanctioned application</a>.</p>
<p>In the MCAS portal, navigate to <strong>Discover &gt; Cloud app catalog</strong>. Search for an application, then under <strong>Actions</strong>, click the three dots and select <strong>Unsanctioned</strong>.</p>
<p><img src="6.png" alt="6"></p>
<p>Apps that you set as unsanctioned will be pushed to Zscaler every 2 hours.</p>
<h2 id="add-zscaler-nss-as-a-data-source">Add Zscaler NSS as a Data Source</h2>
<p>You must <a href="https://docs.microsoft.com/en-us/cloud-app-security/zscaler-integration">explicitly configure MCAS</a> to accept logs from NSS by adding NSS as a Data Source within the MCAS portal.</p>
<p>From the MCAS dashboard, click the <strong>Settings</strong> icon at the top right, and select <strong>Log collectors</strong>.</p>
<p><img src="7.png" alt="7"></p>
<p>Make sure <strong>Automatic log upload</strong> is selected in the sidebar and that you are on the <strong>Data sources</strong> tab.</p>
<p>Click <strong>Add data source&hellip;</strong></p>
<p><img src="8.png" alt="8"></p>
<p>Enter the following information:</p>
<ul>
<li>Name = <strong>NSS</strong></li>
<li>Source = <strong>Zscaler - QRadar LEEF</strong></li>
<li>Receiver type = <strong>Syslog - UDP</strong></li>
</ul>
<p>Note: These three fields must be EXACTLY as the above - including the name. <strong>If the data source name is anything other than <strong><code>NSS</code></strong>, MCAS will not receive the log data from NSS.</strong></p>
<p><img src="9.png" alt="9"></p>
<p>Optionally set a comment, and click <strong>Add</strong>.</p>
<h1 id="configure-zscaler-zia">Configure Zscaler (ZIA)</h1>
<p>In this section, we&rsquo;ll configure MCAS integration on the Zscaler side by adding the MCAS API token to the ZIA admin portal, and (optionally) configure a URL filtering policy to block the MCAS unsanctioned apps.</p>
<h2 id="provide-the-mcas-api-token">Provide the MCAS API Token</h2>
<p>Navigate to <strong>Administration &gt; Partner Integrations</strong>.</p>
<p><img src="10.png" alt="10"></p>
<p>Under the <strong>Microsoft Cloud App Security</strong> tab, <strong>paste in your MCAS API Token</strong> in the area provided and click <strong>Test</strong>.</p>
<p><img src="11.png" alt="11"></p>
<p>This will validate your token, and if correct, will begin synchronization with MCAS.</p>
<p>If you receive an error, make sure you&rsquo;ve configured at least one application as unsanctioned (as per the above).</p>
<h2 id="optional-block-or-caution-access-to-unsanctioned-apps">(Optional) Block (or Caution) Access to unsanctioned apps</h2>
<p>Unsanctioned apps synchronized from MCAS are put into a custom URL category called <strong>MCAS Unsanctioned Apps</strong>. Block or caution on access to these by creating a URL Filtering Policy.</p>
<p>Navigate to <strong>Policy &gt; URL &amp; Cloud App Control</strong>.</p>
<p><img src="12.png" alt="12"></p>
<p>Click <strong>Add URL Filtering Policy</strong> and under the <strong>URL Categories</strong> dropdown, search for and select <strong>MCAS Unsanctioned Apps</strong>.</p>
<p><img src="13.png" alt="13"></p>
<p>Target this policy to specific users/groups/departments/locations as needed, and select an appropriate action (Allow, Caution, or Block). Click <strong>Save</strong> when finished and activate your changes.</p>
<p>Wait a moment, then attempt to visit one of the apps you marked in MCAS as unsanctioned.</p>
<p>In this example, Reddit was marked as unsanctioned and configured with a Caution action in the URL Filtering Policy. Attempting to access Reddit as a user going through ZIA now results in the following:</p>
<p><img src="14.png" alt="14"></p>
<p>If you your block does not apply, check that you have SSL Inspection enabled and that you aren&rsquo;t accidentally bypassing/exempting the site. If you can see the Zscaler Root CA and Intermediate Root CA when examining the certificate of the site, then SSL inspection is working as intended.</p>
<p><img src="15.png" alt="15"></p>
<h1 id="configure-the-zscaler-nss-server-vm">Configure the Zscaler NSS Server VM</h1>
<p>The last bit of config we need to do is to explicitly configure the NSS VM for MCAS by providing it with the MCAS API token. This will allow the NSS VM to make a connection to your MCAS tenant and forward logs.</p>
<h2 id="add-your-mcas-api-token-and-domain-to-nss">Add your MCAS API Token and Domain to NSS</h2>
<p>Log into your NSS VM. In my case, I&rsquo;ll SSH to it:</p>
<pre tabindex="0"><code>ssh zsroot@&lt;ip-of-nss-vm&gt;

Last login: Mon Jun 29 11:21:27 2020 from 10.0.88.4
ZscalerOS 10-R (SMKERNEL) #124: Fri Nov  2 17:44:46 PDT 2018
[zsroot@NSS ~]$ 
</code></pre><p>Run the <code>configure-mcas</code> command, and paste in your MCAS API token and MCAS domain when prompted:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss configure-mcas

token (Authentication token for uploading to MCAS) []:
domain (MCAS domain like mycompany.portal.cloudappsecurity.com) []:
</code></pre><p><strong>DO NOT</strong> enter the full MCAS URL - enter the domain part only. For example, if your URL is <code>https://company.us3.portal.cloudappsecurity.com/</code>, drop the <code>https://</code> and trailing <code>/</code> and simply enter <code>company.us3.portal.cloudappsecurity.com</code></p>
<p>If you enter the full URL, the connection to MCAS will fail.</p>
<p>Restart the NSS service when you are finished:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss restart
</code></pre><h2 id="verify-logs-are-being-streamed-from-nss">Verify Logs are being streamed from NSS</h2>
<p>You can monitor  <code>/sc/log/zbridge.log</code> file to ensure logs are being streamed to NSS. Log upload will occur every hour (note the multiple uploads and timestamps in the output below):</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ tail -f /sc/log/zbridge.log

[...snip... after starting the nss service...]
[2020-07-03 13:01:22] INFO Initialize MCAS handler
[2020-07-03 13:01:22] INFO Creating MCAS workers
[2020-07-03 13:01:22] INFO Created Worker 1
[2020-07-03 14:01:39] INFO Check and upload. queue size=1380
[2020-07-03 14:01:39] INFO Initiate Upload
[2020-07-03 14:01:47] INFO Initiate Response: OK
[2020-07-03 14:01:47] INFO Return url=https://prod5usw2console1.blob.core.windows.net/discovery-logs/[REDACTED]
[2020-07-03 14:01:47] INFO Perform Upload. Payload size=24632 queue size=1380
[2020-07-03 14:01:48] INFO Upload Response: Created
[2020-07-03 14:01:48] INFO Finalize Upload
[2020-07-03 14:01:50] INFO Finalize Response: OK
[2020-07-03 15:02:07] INFO Check and upload. queue size=778
[2020-07-03 15:02:07] INFO Initiate Upload
[2020-07-03 15:02:11] INFO Initiate Response: OK
[2020-07-03 15:02:11] INFO Return url=https://prod5usw2console1.blob.core.windows.net/discovery-logs/[REDACTED]
[2020-07-03 15:02:11] INFO Perform Upload. Payload size=13611 queue size=778
[2020-07-03 15:02:12] INFO Upload Response: Created
[2020-07-03 15:02:12] INFO Finalize Upload
[2020-07-03 15:02:13] INFO Finalize Response: OK
</code></pre><p>You can also check whether the NSS VM is aware of the MCAS feed you configured in ZIA by running the <code>nss troubleshoot feeds</code> command:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss troubleshoot feeds

NSS is live 
Currently active feeds: 1
Feed name: NSS:
  Connection Status:
	[127.0.0.1:54493 -&gt; 127.0.0.1:13010] : Stable
  Other health checks:
	Feed is stable. No suspicious events detected.
</code></pre><p>This command can take several minutes to complete, so be patient.</p>
<h2 id="verify-logs-are-being-received-by-mcas">Verify logs are being received by MCAS</h2>
<p>In the MCAS Portal, check the Data Source you configured above (Settings &gt; Log collectors). After some time, you should see the <strong>Uploaded logs</strong> field increment:</p>
<p><img src="16.png" alt="16"></p>
<h1 id="finish">Finish</h1>
<p>You have now integrated Zscaler ZIA with Microsoft Cloud App Security!</p>
<p>Having issues with logs not appearing in MCAS? Read on&hellip;</p>
<h1 id="troubleshooting">Troubleshooting</h1>
<p>If MCAS isn&rsquo;t recieving your logs, this can usually be boiled down to a few things:</p>
<ul>
<li>Network Configuration</li>
<li>Incorrect API Token</li>
<li>Incorrect MCAS Domain or the URL was entered instead of the domain</li>
<li>Not restarting the NSS service after configuring the NSS VM with the MCAS API token &amp; domain</li>
<li>The data source configured in the MCAS portal is not using the named <code>NSS</code> (see the screenshot above).</li>
<li>Patience</li>
</ul>
<p>Keep in mind that logs will not show in MCAS immediately: These are sent by NSS every hour, but you can verify that NSS is uploading them correctly. Also, MCAS can take a while to process them once they&rsquo;ve been received.</p>
<h2 id="verify-network-connectivity-to-mcas">Verify Network Connectivity to MCAS</h2>
<p>From the NSS VM, check you can check connectivity to MCAS by telnetting to your MCAS domain on port 443:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ telnet oblivioninc.us3.portal.cloudappsecurity.com 443
Trying 40.90.218.198...
Connected to m365x855557.us3.portal.cloudappsecurity.com.
Escape character is &#39;^]&#39;.
</code></pre><p>This will confirm whether you can resolve and reach where the logs will be submitted to.</p>
<h2 id="verify-your-api-token-and-domain-are-correct">Verify your API token and domain are correct</h2>
<p>You can use cURL to check whether both of these are valid or not. Run the following command on your own machine (don&rsquo;t run this on the NSS VM) - substitute the token and URL for your own:</p>
<pre tabindex="0"><code>curl -v &#34;https://oblivioninc.us3.portal.cloudappsecurity.com/api/discovery_block_scripts/?format=120&amp;type=banned&#34; -H &#34;Authorization: Token QhwZGlcXGhoxxxxxx[snip]xxxxxxxGxoW&#34;
</code></pre><p>If both your token and domain are valid, this command will return a list of your unsanctioned applications in MCAS:</p>
<pre tabindex="0"><code>*   Trying 40.90.218.198...
* Connected to oblivioninc.us3.portal.cloudappsecurity.com (40.90.218.198) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH
[snip]
*  SSL certificate verify ok.
&gt; GET /api/discovery_block_scripts/?format=120&amp;type=banned HTTP/1.1
&gt; Host: oblivioninc.us3.portal.cloudappsecurity.com
&gt; Authorization: Token QhwZGlxxxxxxxxxxx[snip]xxxxxxxxxxxxxxxxxxxxxx
&gt; 
&lt; HTTP/1.1 200 OK
&lt; Server: nginx
&lt; Date: Wed, 01 Jul 2020 10:59:56 GMT
&lt; Content-Type: text/plain
&lt; Transfer-Encoding: chunked
[snip]
&lt; strict-transport-security: max-age=31536000
&lt; x-content-type-options: nosniff
&lt;
.reddit.com
.redd.it
.redditmedia.com
</code></pre><h2 id="verify-your-api-token-and-mcas-domain-were-entered-correctly-in-the-nss-vm">Verify your API token and MCAS domain were entered correctly in the NSS VM</h2>
<p>Your MCAS API token and domain are stored in the <code>/sc/conf/zbridge-mcas.properties</code> file. Verify you entered them correctly:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ cat /sc/conf/zbridge-mcas.properties

# Authentication token for uploading the traffic logs
token=QhwZGlcxxxxxxxxxxxx[redacted]xxxxxxxxxxxxxx
# MCAS domain like mycompany.portal.cloudappsecurity.com
domain=oblivioninc.us3.portal.cloudappsecurity.com

# Data source name
inputStream=NSS

# Number of transactions in one batch
#batchSize=100000

# Flush interval of the batch in seconds
#flushInterval=3600
</code></pre><p>Ensure the <code>token</code> field accurately contains your MCAS API token.</p>
<p>Ensure the domain field is correct and includes the domain only! If you see <code>http://</code> or <code>https://</code> or any trailing <code>/</code>, you&rsquo;ve entered it incorrectly.</p>
<p>If you need to fix anything up, run the <code>nss configure-mcas</code> command again. Don&rsquo;t forget to restart the NSS service afterward (<code>nss restart</code>).</p>
<h2 id="restart-the-nss-service">Restart the NSS Service</h2>
<p>After any change, you should restart the NSS service:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss restart
</code></pre><h2 id="turn-on-debug-logging">Turn on DEBUG logging</h2>
<p>By default, <code>zbridge.log</code> will only log <code>INFO</code> and higher. You can turn on <code>DEBUG</code> logging by editing the <code>/sc/conf/zbridge-log4j.properties</code> file as follows:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ vi /sc/conf/zbridge-mcas.properties

log4j.rootLogger=INFO,FILE         # Change INFO to DEBUG
log4j.logger.kafka=INFO,FILE       # Change INFO to DEBUG

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

log4j.appender.FILE=org.apache.log4j.RollingFileAppender
log4j.appender.FILE.File=/sc/log/zbridge.log
log4j.appender.FILE.layout=org.apache.log4j.PatternLayout
log4j.appender.FILE.layout.ConversionPattern=[%d] %p %m (%c)%n
log4j.appender.FILE.MaxFileSize=1024MB
log4j.appender.FILE.MaxBackupIndex=7


# Turn on all our debugging info - UNCOMMENT THESE!
#log4j.logger.kafka.producer.async.DefaultEventHandler=DEBUG,stdout
#log4j.logger.kafka.consumer.PartitionTopicInfo=TRACE,stdout
#log4j.logger.kafka.request.logger=TRACE,fileAppender
#log4j.additivity.kafka.request.logger=false
#log4j.logger.kafka.network.Processor=TRACE,fileAppender
#log4j.additivity.kafka.network.Processor=false
#log4j.logger.org.I0Itec.zkclient.ZkClient=DEBUG
</code></pre><p>Edit the file as per the comments: For the first two lines, change <code>INFO</code> to <code>DEBUG</code>, then uncomment the last 7 lines. Restart the NSS service when you are done and check the <code>zbridge.log</code> file:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ tail -f /sc/log/zbridge.log

[2020-07-01 14:16:16,962] INFO Upload Response: Created (com.zscaler.bridge.proxy.ProxyConfig)
[2020-07-01 14:16:16,962] INFO Finalize Upload (com.zscaler.bridge.proxy.ProxyConfig)
[2020-07-01 14:16:16,963] DEBUG CookieSpec selected: best-match (org.apache.http.client.protocol.RequestAddCookies)
[2020-07-01 14:16:16,963] DEBUG Cookie [version: 0][name: cas_sessionid][value: xxxxxxxxxxxxxxxxxxxxxxxxxxxxx][domain: .us3.portal.cloudappsecurity.com][path: /][expiry: Wed Jul 01 15:16:13 IST 2020] match [(secure)oblivioninc.us3.portal.cloudappsecurity.com:443/api/v1/discovery/done_upload] (org.apache.http.client.protocol.RequestAddCookies)
[2020-07-01 14:16:16,963] DEBUG Auth cache not set in the context (org.apache.http.client.protocol.RequestAuthCache)
[2020-07-01 14:16:16,963] DEBUG Connection request: [route: {s}-&gt;https://oblivioninc.us3.portal.cloudappsecurity.com:443][total kept alive: 2; route allocated: 1 of 20; total allocated: 2 of 200] (org.apache.http.impl.conn.PoolingHttpClientConnectionManager)
[2020-07-01 14:16:16,963] DEBUG Connection leased: [id: 5][route: {s}-&gt;https://oblivioninc.us3.portal.cloudappsecurity.com:443][total kept alive: 1; route allocated: 1 of 20; total allocated: 2 of 200] (org.apache.http.impl.conn.PoolingHttpClientConnectionManager)
</code></pre><p>The log file will now be very noisy but may help.</p>
<h2 id="check-the-mcas-data-source-is-correctly-named">Check the MCAS data source is correctly named</h2>
<p>When configuring a new data source in MCAS (Settings &gt; Log collectors) to accept data from NSS, it must be named <code>NSS</code> EXACTLY. Naming the feed anything different will result in MCAS dropping the logs it receives from NSS.</p>
<p><img src="17.png" alt="17"></p>
]]></content>
        </item>
        
        <item>
            <title>Deploy Zscaler NSS in Azure</title>
            <link>https://nathancatania.com/posts/deploy-zscaler-nss-in-azure/</link>
            <pubDate>Mon, 29 Jun 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploy-zscaler-nss-in-azure/</guid>
            <description>This guide will cover deployment of a Nanolog Streaming Service (NSS) VM within Azure. NSS can also be deployed on-premise using an OVA file, or in AWS.
If you&amp;rsquo;re planning to integrate with Microsoft Cloud App Security (MCAS) or Azure Sentinel, you&amp;rsquo;ll require a healthy NSS deployment, and it is highly recommended that you use Azure.
Why do I need to deploy a VM to stream logs to a SIEM? Can&amp;rsquo;t Zscaler just send logs to my SIEM directly?</description>
            <content type="html"><![CDATA[<p>This guide will cover deployment of a Nanolog Streaming Service (NSS) VM within Azure. NSS can also be deployed on-premise using an OVA file, or in AWS.</p>
<p>If you&rsquo;re planning to integrate with Microsoft Cloud App Security (MCAS) or Azure Sentinel, you&rsquo;ll require a healthy NSS deployment, and it is highly recommended that you use Azure.</p>
<blockquote>
<p>Why do I need to deploy a VM to stream logs to a SIEM? Can&rsquo;t Zscaler just send logs to my SIEM directly?</p>
</blockquote>
<p>Your logs are stored in Zscaler&rsquo;s Nanolog clusters in a highly compressed and encoded format. The NSS VM connects to both the Nanolog cluster and the Zscaler control plane, grabs the logs, decodes them, and forwards them to your SIEM over a TCP connection. Think of NSS as a log gateway!</p>
<h1 id="before-you-begin">Before you begin</h1>
<h2 id="be-aware-of-potential-charges">Be aware of potential charges</h2>
<p>You can&rsquo;t follow this guide without an Azure subscription. If you&rsquo;re deploying in as part of demo or lab environment, be careful: This guide WILL rack up some charges for VM and storage resources in Azure.</p>
<p>If you&rsquo;re using the Azure Free Account, you should have US$200 of credit to use as part of your free subscription and may be able to avoid charges.</p>
<p>Proceed at your own risk.</p>
<h2 id="youll-need-a-subscription-to-the-nss-feature">You&rsquo;ll need a subscription to the NSS feature</h2>
<p>Not all Zscaler subscriptions allow you to use NSS. In the ZIA Portal, navigate the <strong>Administration</strong> tab. If you don&rsquo;t see <strong>Nanolog Streaming Service</strong> listed as an option, then you are most likely not subscribed to the NSS feature and will need to chat to your account team.</p>
<hr>
<h1 id="part-1---create-an-nss-virtual-appliance">Part 1 - Create an NSS Virtual Appliance</h1>
<ol>
<li>Log into the ZIA admin portal and navigate to <strong>Administration &gt; Nanolog Streaming Service</strong>.</li>
<li>Select <strong>Add NSS Server</strong></li>
<li>Give the server a name, select <strong>NSS for Web</strong> (or firewall, depending on your use case), set it to <strong>Enabled</strong>, then click <strong>Save</strong>. Activate your changes.</li>
</ol>
<h2 id="nss-vm-system-requirements">NSS VM System Requirements</h2>
<h3 id="cpu">CPU</h3>
<p>2 vCPUs (one for the control plane, one for the data plane)</p>
<h3 id="memory">Memory</h3>
<p>Depending upon whether this is a lab/demo or production deployment, memory requirements (and hence, the Azure instance type you deploy on) will be different. A production deployment depends on the number of users ZIA is/will be deployed to:</p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Memory Required</th>
</tr>
</thead>
<tbody>
<tr>
<td>Lab/Demo</td>
<td>4GB</td>
</tr>
<tr>
<td>&lt;15,000 users</td>
<td>8GB</td>
</tr>
<tr>
<td>&lt;40,000 users</td>
<td>16GB</td>
</tr>
<tr>
<td>&lt;100,000 users</td>
<td>32GB</td>
</tr>
</tbody>
</table>
<p>Note: If you are planning on integrating with <strong>Microsoft Cloud App Security (MCAS)</strong>, you MUST deploy with at least 8GB of memory. Using 4GB for a Lab/Demo environment will not work.</p>
<hr>
<h1 id="part-2---resource-creation">Part 2 - Resource Creation</h1>
<p>You&rsquo;ll need the following information handy to deploy NSS in Azure:</p>
<ul>
<li>Azure subscription (this <strong>can</strong> be the free tier - you&rsquo;ll have access to US$200 credit with it which will help)</li>
<li>Resource Group</li>
<li>Virtual Network</li>
<li>Storage Account with two containers/blobs</li>
</ul>
<p>If you have some or all of these already, you can skip forward as needed.</p>
<h2 id="1-create-an-azure-subscription">1. Create an Azure Subscription</h2>
<p>You need an Azure Subscription (even if it is part of the free tier) to continue. In the Azure Portal search bar (at the top of the page), search for &ldquo;<strong>Subscriptions</strong>&rdquo; and validate you have a valid subscription.</p>
<p><img src="1.png" alt="1"></p>
<p>Ensure you have an existing subscription present, you click <strong>Add</strong> to create one if you need to.</p>
<p><strong>Warning!</strong> You have the potential to rack up large charges if you aren&rsquo;t careful! Proceed at your own risk!</p>
<h2 id="2-create-a-resource-group">2. Create a Resource Group</h2>
<p>A Resource Group houses related resources and services for something deployed in Azure.</p>
<p>If you don&rsquo;t have a usable Resource Group already, you&rsquo;ll need to create one. In the Azure Portal search bar (at the top of the page), search for &ldquo;<strong>Resource Groups</strong>&rdquo;.</p>
<p><img src="2.png" alt="2"></p>
<p>Click <strong>Add</strong> to create a new one. Associate it with your subscription, give it a name, and select your closest Azure region.</p>
<p>In the screenshot above, the Resource Group I&rsquo;ll be using is called <code>AzureLab</code>, which is linked to the <code>Pay-As-You-Go</code> subscription in the <code>Australia East</code> region.</p>
<h2 id="3-create-a-virtual-network">3. Create a Virtual Network</h2>
<p>You&rsquo;ll need (ideally) two Virtual Network (vNet) subnets to deploy NSS. In the Azure Portal search bar (at the top of the page), search for &ldquo;<strong>Virtual networks</strong>&rdquo;.</p>
<p>Click <strong>Add</strong> to create a new vNet (or select an existing one). If you&rsquo;re creating a new one:</p>
<ul>
<li>Under the <strong>Basics</strong> tab, associate the new vNet with your subscription and resource group from above. Give it a name and ensure it&rsquo;s created in the same region.</li>
<li>Under the <strong>IP Addresses</strong> tab, the default 10.X.X.X/16 IPv4 address space should be fine. This will give you 65536 usable addresses in the entire vNet which is more than enough!</li>
<li>There should already be a <code>default</code> subnet - a /24 range which will be a subset of the /16 address space above. Leave this as it is and create a new /24 subnet. One of these will be for the management interface of the NSS VM, the other for the service interface.
<ul>
<li>When creating a new subnet, NAT Gateway, Security Group, Route table, and Services can all be left as None or their default values for now.</li>
</ul>
</li>
<li>Under the <strong>Security</strong> tab, leave DDoS protection and Firewall <strong>Disabled</strong>.</li>
<li>When you are finished, click <strong>Review + create</strong>.</li>
</ul>
<p>In the image below, I have an vNet called <code>vNetLab</code> which has a global 10.0.0.0/16 address space; with two subnets:</p>
<ul>
<li><code>default</code> = 10.0.0.0/24</li>
<li><code>mgmt</code> = 10.0.1.0/24</li>
</ul>
<p><img src="3.png" alt="3"></p>
<h2 id="4-create-a-storage-account">4. Create a Storage Account</h2>
<p>The Storage Account will house the VHD files for our NSS VM. In the Azure Portal search bar (at the top of the page), search for &ldquo;<strong>Storage accounts</strong>&rdquo;.</p>
<p>Click <strong>Add</strong> to create a new Storage Account.</p>
<p>Associate the Storage Account with your existing subscription and Resource Group. Provide it with a <strong>globally unique name</strong>. Ensure the location is the same as the one associated with your Resource Group.</p>
<p>For the cheapest option for a lab deployment, select the following:</p>
<ul>
<li>Performance = <strong>Standard</strong></li>
<li>Account kind = <strong>StorageV2 (general purpose v2)</strong></li>
<li>Replication = <strong>Locally-redundant storage (LRS)</strong></li>
<li>Access tier = <strong>Hot</strong></li>
</ul>
<p><img src="4.png" alt="4"></p>
<p>Under the <strong>Networking</strong> tab, for a lab/demo deployment select <strong>Public endpoint (all networks)</strong>: This will ensure you can immediately connect to the storage account. For a more secure deployment (ie: production), you might want to select either of the other two options.</p>
<p>Under the <strong>Data Protection</strong> tab, for a lab deployment, everything should be set to <strong>Disabled</strong>.</p>
<p>Under the <strong>Advanced</strong> tab, for a lab deployment, set everything as <strong>Disabled</strong>.</p>
<p>Click <strong>Review + create</strong> when you are done.</p>
<h2 id="5-create-two-blob-containers">5. Create two Blob Containers</h2>
<p>Open the Storage Account you just created, and in the left-side-menu, select <strong>Containers</strong>. Create two containers here: one will be used to copy the VHD files from Zscaler&rsquo;s storage account, and the other will be used to deploy the NSS VM itself.</p>
<p><img src="5.png" alt="5"></p>
<hr>
<h1 id="part-3---copy-the-os-and-data-vhd-images">Part 3 - Copy the OS and Data VHD images</h1>
<p>These are 32GB and 500GB respectively. Zscaler makes these available on their Storage Account which you can use to copy them across to your own to avoid transfer charges (not to mention the time of downloading &amp; re-uploading that amount of data).</p>
<p>In this section, we will copy the two VHD images to the Storage Account and blob containers we created earlier, and then use these to initialize the NSS VM.</p>
<h2 id="1-download-azure-storage-explorer">1. Download Azure Storage Explorer</h2>
<p>You can also do this <a href="https://help.zscaler.com/zia/nss-deployment-guide-microsoft-azure#step_4_PS">via PowerShell</a>, but that is outside the scope of this guide.</p>
<p>Download link (all platforms): <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">https://azure.microsoft.com/en-us/features/storage-explorer/</a></p>
<h2 id="2-sign-in-to-your-azure-account">2. Sign in to your Azure Account</h2>
<p>Open Azure Storage Explorer, click the &ldquo;plug&rdquo; icon in the sidebar, then select <strong>Add an Azure Account</strong>. Click <strong>Next</strong> and you will be redirected to sign in to Azure via Microsoft SSO. Sign in using your Azure admin credentials.</p>
<p><img src="6.png" alt="6"></p>
<p>Once you have logged in, you should see your Azure subscription in the side panel.</p>
<h2 id="3-connect-to-the-zscaler-storage-account">3. Connect to the Zscaler Storage Account</h2>
<p>Next, we need to connect to the Zscaler Storage Account to access the NSS VHDs.</p>
<p>Click the plug icon again in the sidebar (as you did above), but this time select <strong>Use a shared access signature (SAS) URI</strong>.</p>
<blockquote>
<p><strong>Stop!</strong> You will need a SAS URI token from Zscaler to proceed!</p>
</blockquote>
<p>You need a SAS token to authenticate with the Zscaler Storage Account. To obtain one:</p>
<ul>
<li>If you are a Zscaler employee, <a href="https://community.zscaler.com/t/tokens-for-nss-on-azure-vhd/3255">click here</a> to visit the Community forum and obtain a token directly.</li>
<li>Otherwise, you will need to raise a support ticket requesting a SAS token for NSS deployment in Azure.</li>
</ul>
<p>Once you have your SAS token, you can fill in the fields in Azure Storage Explorer as prompted:</p>
<ul>
<li>Display name = ZscalerNSS</li>
<li>URI = This is region dependant (see the table below), and MUST contain the SAS token as a URL argument.</li>
</ul>
<table>
<thead>
<tr>
<th>Region</th>
<th>URI</th>
</tr>
</thead>
<tbody>
<tr>
<td>USA</td>
<td><a href="https://zsprod.blob.core.windows.net/?%5BSAStoken%5D">https://zsprod.blob.core.windows.net/?[SAStoken]</a></td>
</tr>
<tr>
<td>Europe</td>
<td><a href="https://zsprodeu.blob.core.windows.net/?%5BSAStoken%5D">https://zsprodeu.blob.core.windows.net/?[SAStoken]</a></td>
</tr>
<tr>
<td>Australia</td>
<td><a href="https://zsprodau.blob.core.windows.net/?%5BSAStoken%5D">https://zsprodau.blob.core.windows.net/?[SAStoken]</a></td>
</tr>
</tbody>
</table>
<p>For example, for deploying in Australia, my full URI would look like:</p>
<pre tabindex="0"><code>https://zsprodau.blob.core.windows.net/?sv=2019-02-02&amp;ss=b&amp;srt=sco&amp;sp=rl&amp;se=2023-03-12T09:14:30Z&amp;st=2020-03-12T00:14:30Z&amp;spr=https&amp;sig=XXXXXXXXXXXXXXXXXXXXXXXXX
</code></pre><p>Pay close attention to the format above as it is important. If you have an issue with Azure Storage Explorer not accepting the URI, check the formatting. <strong>Do not use any of the URLs provided to you ending in</strong> <code>.vhd</code>.</p>
<p><img src="7.png" alt="7"></p>
<p>Click <strong>Next</strong> when done, followed by <strong>Connect</strong>.</p>
<h2 id="4-error-unable-to-get-local-issuer-certificate">4. Error: Unable to get local issuer certificate</h2>
<p><img src="8.png" alt="8"></p>
<p>If you receive this error, it is most likely because your connection is being SSL inspected, and Azure Storage Explorer does not like this. You will need to add an SSL inspection bypass for <code>.blob.core.windows.net</code> to resolve the issue.</p>
<p>For ZIA, navigate to <strong>Policy &gt; SSL Inspection</strong> in the ZIA admin portal. Add <code>.blob.core.windows.net</code> to the list of URLs to bypass from SSL Inspection. Save and activate your changes.</p>
<p>Wait a moment, then <strong>right-click on the storage account and click Refresh</strong>. If you just try and load the storage account again, you&rsquo;ll continuously get the same error as it is cached.</p>
<p><img src="9.png" alt="9"></p>
<p>The error should be resolved.</p>
<h2 id="5-copy-the-vhd-files">5. Copy the VHD files</h2>
<p>In the side panel of Azure Storage Explorer, expand the <strong>Zscaler NSS Storage (SAS)</strong> storage account, and select the <strong>nss</strong> blob container.</p>
<p><img src="10.png" alt="10"></p>
<p>Select both of the VHD images listed and click <strong>Copy</strong>.</p>
<p>Next, under the Azure subscription you connected to earlier, expand the storage account you created earlier and select the blob container you created to store a copy of the VHD files. Click <strong>Paste</strong> and the files will begin to transfer. This is a 532GB file transfer so it may take a minute or two.</p>
<p><img src="11.png" alt="11"></p>
<p>Note: You&rsquo;re now consuming storage on Azure and there is a charge associated with this. Every region is different, but using the settings I selected above, my cost was estimated to be approx US$11 per month for a single blob container. This is just for storage. Using a 2nd blob container for the VM itself PLUS VM charges will get expensive quickly; particularly for a home lab deployment. You may wish to reconsider running this in a lab environment long-term.</p>
<p><img src="12.png" alt="12"></p>
<h2 id="6-verify-the-transfer--copy-urls">6. Verify the Transfer &amp; Copy URLs</h2>
<p>In the Azure Portal, go to your storage account and look at the blob container you transferred the VHD files to. You&rsquo;ll see them listed there.</p>
<p><img src="13.png" alt="13"></p>
<p>Click on each file and copy the URL listed - we&rsquo;ll need these later to deploy the NSS VM.</p>
<p><img src="14.png" alt="14"></p>
<hr>
<h1 id="part-4---deploy-the-nss-vm">Part 4 - Deploy the NSS VM</h1>
<p>We need to use PowerShell to deploy the NSS VM via a script.</p>
<ul>
<li>If you&rsquo;re on a Windows device, you should have PowerShell already installed.</li>
<li>If you are on Mac OS, you&rsquo;ll need to install PowerShell via Homebrew.</li>
</ul>
<h2 id="1-install-powershell-on-mac-os">1. Install PowerShell on Mac OS</h2>
<ol>
<li><a href="https://brew.sh/">Install Homebrew</a> if you haven&rsquo;t already. Open Terminal:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>/bin/bash -c <span style="color:#e6db74">&#34;</span><span style="color:#66d9ef">$(</span>curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh<span style="color:#66d9ef">)</span><span style="color:#e6db74">&#34;</span>
</span></span></code></pre></div><ol start="2">
<li>Install PowerShell:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>brew cask install powershell
</span></span></code></pre></div><ol start="3">
<li>Invoke PowerShell:</li>
</ol>
<pre tabindex="0"><code>pwsh
</code></pre><ol start="4">
<li>You should now be on the PowerShell prompt:</li>
</ol>
<pre tabindex="0"><code>$ pwsh

PowerShell 7.0.2
Copyright (c) Microsoft Corporation. All rights reserved.

https://aka.ms/powershell
Type &#39;help&#39; to get help.

PS /Users/nathan&gt;
</code></pre><h2 id="2-install--import-the-azure-modules">2. Install &amp; Import the Azure Modules</h2>
<p>These modules let us perform tasks on Azure via PowerShell:</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; Install-Module Az
PS /Users/nathan&gt; Import-Module Az 
</code></pre><h2 id="3-connect-to-your-azure-account">3. Connect to your Azure account</h2>
<p>You&rsquo;ll need to sign-in and authenticate using your Azure admin credentials:</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; Connect-AzAccount

WARNING: To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code XXXXXXXXX to authenticate.
</code></pre><p>Go to <a href="https://microsoft.com/devicelogin">https://microsoft.com/devicelogin</a> and enter the code provided.</p>
<p>Return to PowerShell and press Enter/Return. After a few moments your subscriptions will appear.</p>
<h2 id="4-list-all-vm-sizes-for-your-azure-region">4. List all VM sizes for your Azure region</h2>
<p>We need to grab the name of the Azure instance type we&rsquo;ll be deploying the NSS VM on.</p>
<p>You can use the <a href="https://azure.microsoft.com/en-us/pricing/calculator/?service=virtual-machines">Azure Pricing Calculator</a> to determine which instance type is best (and how much it will cost you). Be sure to select your region for accurate availability and pricing. Not every instance type is available in every region.</p>
<p>You&rsquo;ll need an instance with 2 vCPUs and either:</p>
<ul>
<li>4GB memory (lab deployment)</li>
<li>8GB memory (MCAS or typical production deployment)</li>
<li>16GB memory (15K-40K users - large enterprise)</li>
<li>32GB memory (40K-100K users - huge enterprise)</li>
</ul>
<p>If you&rsquo;re not sure, just find something with 8GB of memory + 2 vCPUs.</p>
<p>Next, list all of the VM sizes for your selected region in PowerShell:</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; Get-AzVmSize -Location &#34;Australia East&#34;

Name                   NumberOfCores MemoryInMB
----                   ------------- ----------
Standard_B1ls                      1        512
Standard_B1ms                      1       2048
Standard_B1s                       1       1024
Standard_B2ms                      2       8192
Standard_B2s                       2       4096
Standard_B4ms                      4      16384
Standard_B8ms                      8      32768
Standard_B12ms                    12      49152
Standard_B16ms                    16      65536
Standard_B20ms                    20      81920
Standard_D1_v2                     1       3584
Standard_D2_v2                     2       7168
Standard_D3_v2                     4      14336
Standard_D4_v2                     8      28672 
[..snip..]
</code></pre><p>NB: The table above has been trimmed to fit.</p>
<p>Locate your desired instance, and copy down the name as it&rsquo;s printed in the terminal window. We&rsquo;ll need this for our PowerShell script which will deploy the NSS VM.</p>
<p>In my case, I&rsquo;ll be using <code>Standard_A4_v2</code> which has 2 vCPUs and 8GB memory.</p>
<p><strong>Be very careful! VM instances become expensive over a whole month!</strong> If left on for 30 days, the <code>Standard_A4_v2</code> instance type would cost be  <strong>~US$153!</strong> Proceed at your own risk!</p>
<h2 id="5-enable-compatibility-mode-for-azurerm">5. Enable Compatibility Mode for AzureRM</h2>
<p>The current Zscaler deployment script uses the old AzureRM modules which have been depreciated. We need to enable compatibility for them:</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; Enable-AzureRmAlias -Scope CurrentUser
</code></pre><p>If you get an error similar to:</p>
<pre tabindex="0"><code>Enable-AzureRmAlias: Could not find a part of the path &#39;/Users/nathan/.config/powershell/profile.ps1&#39;
</code></pre><p>You&rsquo;ll need to create the <code>powershell</code> directly under <code>/Users/&lt;YourUsername&gt;/.config/</code>:</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; cd ~/.config
PS /Users/nathan/.config&gt; mkdir powershell
</code></pre><h2 id="6-windows-enable-unsigned-scripts">6. (Windows) Enable Unsigned Scripts</h2>
<p>Allow powershell to run unsigned scripts (not needed/supported on macOS):</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
</code></pre><h2 id="7-create-the-deployment-config-file">7. Create the Deployment Config File</h2>
<p>Copy the following into a file called <code>conf_file.txt</code> and replace with your data:</p>
<pre tabindex="0"><code>name=AzureNSS
location=australiaeast
rgname=AzureLab
createrg=n
storename=zsnsslab
createstorage=n
vnetrg=AzureLab
vnetname=vNetLab
vnetprefix=10.0.0.0/16
mgmtsubnetname=mgmt
mgmtsubnetprefix=10.0.1.0/24
svcsubnetname=default
svcsubnetprefix=10.0.0.0/24
niccount=2
mgmtdyn=n
vmsize=Standard_A4_v2
dstStorageURI=https://zsnsslab.blob.core.windows.net
dstContainer=zsnssproduction
srcOsURI=https://zsnsslab.blob.core.windows.net/zsnssdeployment/znss_4_0_4_osdisk.vhd
srcDataURI=https://zsnsslab.blob.core.windows.net/zsnssdeployment/znss_4_0_4_datadisk.vhd
</code></pre><p>A description of each of these fields is below:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>name</code></td>
<td>The name to be assigned to the NSS VM when deployed</td>
</tr>
<tr>
<td><code>location</code></td>
<td>The Azure region to deploy the VM to. This should be in lowercase with no spaces.</td>
</tr>
<tr>
<td><code>rgname</code></td>
<td>The name of the Resource Group to be used for VM deployment.</td>
</tr>
<tr>
<td><code>createrg</code></td>
<td><code>y</code> or <code>n</code> depending if you want the above RG to be created or not. Set it to <code>n</code> as it should exist already.</td>
</tr>
<tr>
<td><code>storename</code></td>
<td>The name of the Storage Account to use.</td>
</tr>
<tr>
<td><code>createstorage</code></td>
<td><code>y</code> or <code>n</code> depending if you want the above RG to be created or not. Set it to <code>n</code> as it should exist already.</td>
</tr>
<tr>
<td><code>vnetrg</code></td>
<td>The resource group that the vNet for the VM exists in. Will probably be the same as <code>rgname</code> above.</td>
</tr>
<tr>
<td><code>vnetname</code></td>
<td>The Azure vNet to which the VM should be attached.</td>
</tr>
<tr>
<td><code>vnetprefix</code></td>
<td>The IPv4 address space assigned to the vNet in CIDR form. This will probably be the 10.X.X.X/16 range.</td>
</tr>
<tr>
<td><code>mgmtsubnetname</code></td>
<td>The name of the subnet you created within the vNet for the NSS management interface.</td>
</tr>
<tr>
<td><code>mgmtsubnetprefix</code></td>
<td>The subnet address prefix (in CIDR) of the subnet you created within the vNet for the NSS management interface. Could be 10.X.Y.X/24.</td>
</tr>
<tr>
<td><code>svcsubnetname</code></td>
<td>The name of the subnet you created within the vNet for the NSS service interface.</td>
</tr>
<tr>
<td><code>svcsubnetprefix</code></td>
<td>The subnet address prefix (in CIDR) of the subnet you created within the vNet for the NSS service interface. Could be 10.X.Z.X/24.</td>
</tr>
<tr>
<td><code>niccount</code></td>
<td>The number of NICs to assign to the VM. This should be set to <code>2</code> for NSS.</td>
</tr>
<tr>
<td><code>mgmtdyn</code></td>
<td>Set this to <code>n</code></td>
</tr>
<tr>
<td><code>vmsize</code></td>
<td>The name of the Instance type/size to deploy the VM to (obtained above). Eg: Standard_A4_v2</td>
</tr>
<tr>
<td><code>dstStorageURI</code></td>
<td>The URI for your storage account. Remove the trailing <code>/</code>. This is typically in the format https://<!-- raw HTML omitted -->.blob.core.windows.net</td>
</tr>
<tr>
<td><code>dstContainer</code></td>
<td>Name of the destination blob container within your storage account to create the VM disks. You would have created this in Part 2, Step 4.</td>
</tr>
<tr>
<td><code>srcOsURI</code></td>
<td>The URI of the OS Disk .vhd file from your storage account that you copied in Part 3, Step 6.</td>
</tr>
<tr>
<td><code>srcDataURI</code></td>
<td>The URI of the Data Disk .vhd file from your storage account that you copied in Part 3, Step 6.</td>
</tr>
</tbody>
</table>
<h2 id="8-download-the-deployment-script">8. Download the Deployment Script</h2>
<p>Download the NSS deployment script here:</p>
<p><a href="https://help.zscaler.com/downloads/zia/documentation-knowledgebase/analytics/nss/nss-deployment-guides/nss-deployment-guide-microsoft-azure/deployment_script%5B1%5D.ps1">https://help.zscaler.com/downloads/zia/documentation-knowledgebase/analytics/nss/nss-deployment-guides/nss-deployment-guide-microsoft-azure/deployment_script[1].ps1</a></p>
<p>Save the file as <code>deployment_script.ps1</code> in the same folder as the <code>conf_file.txt</code> configuration file.</p>
<h2 id="9-run-the-deployment-script">9. Run the Deployment Script</h2>
<p>From the PowerShell prompt, run the deployment script. You may be prompted to sign in again:</p>
<pre tabindex="0"><code>PS /Users/nathan&gt; .\deployment_script.ps1 conf_file.txt
</code></pre><p>When prompted, select the subscription to use, and (optionally) whether or not to use Public IP addresses for the two NICs. If this is a lab environment and you want to immediately be able to SSH to the NSS VM after deployment, you might want to select <code>y</code> for this part.</p>
<h2 id="10-verify-the-vm-has-been-deployed">10. Verify the VM has been deployed</h2>
<p>Check whether the NSS VM has been deployed in the Azure Portal. In the search bar at the top of the portal, search for &ldquo;<strong>Virtual Machines</strong>&rdquo;. Validate that your new NSS VM is present and running.</p>
<p><img src="15.png" alt="15"></p>
<h2 id="11-optional-update-security-groups">11. (Optional) Update Security Groups</h2>
<p>If you chose to assign public IP addresses to your NSS VM during deployment, you may wish to lock this down with some rules to prevent anyone from being able to hit your VM.</p>
<p>As a start, you should only allow outbound connections to Zscaler&rsquo;s required IP ranges. You can find these at the following URLs (depending on your Zscaler cloud):</p>
<ul>
<li><a href="https://ips.zscaler.net/nss">https://ips.zscaler.net/nss</a></li>
<li><a href="https://ips.zscalerone.net/nss">https://ips.zscalerone.net/nss</a></li>
<li><a href="https://ips.zscalertwo.net/nss">https://ips.zscalertwo.net/nss</a></li>
<li><a href="https://ips.zscalerthree.net/nss">https://ips.zscalerthree.net/nss</a></li>
<li><a href="https://ips.zscloud.net/nss">https://ips.zscloud.net/nss</a></li>
</ul>
<p>You may also want to restrict inbound connectors to those on port 22 from your source IP only.</p>
<p>Apart from SSH management, NSS only requires connections to both the Zscaler Cloud and your SIEM/destination in the outbound direction. Not inbound connectivity is mandatory.</p>
<p>To create a security group, search for &ldquo;<strong>Network security groups</strong>&rdquo; in the Azure Portal. Click <strong>Add</strong> to create a new one.</p>
<p>You&rsquo;ll need to then edit the security group, and apply it to the respective network interfaces created under the vNet in use by the VM.</p>
<p>For more information, <a href="https://docs.microsoft.com/en-us/azure/virtual-network/manage-network-security-group">see the Microsoft documentation, here</a>.</p>
<hr>
<h1 id="part-5---configure-the-nss-vm">Part 5 - Configure the NSS VM</h1>
<p>Now that the NSS VM has been deployed, we need to configure it and associate it with our ZIA instance.</p>
<h2 id="1-connect-to-the-vm">1. Connect to the VM</h2>
<p>First, locate the IP address in use for the management interface. Under <strong>Virtual Machines</strong> in the Azure Portal, select the NSS VM, and on the <strong>Overview</strong> page, note either the Public or Private IP address assigned (under the Networking heading).</p>
<p><img src="16.png" alt="16"></p>
<h2 id="2-review-the-initial-nss-config">2. Review the initial NSS config</h2>
<p>Review the NSS initial config to check whether the service interface has been configured correctly:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss dump-config

Detected an Azure VM!!
Configured Values:
	CloudName:Failed to read SSL Certificate
	nameserver:168.63.129.16	
	smnet_dev:
	Default gateway for Service IP:
	Routes for Siem N/w:
</code></pre><p>If the <code>smnet_dev</code> and <code>Default gateway for Service IP</code> fields are blank, check the Networking menu of the NSS VM you deployed in Azure:</p>
<p><img src="17.png" alt="17"></p>
<p>Note down the private IP of the 2nd network interface <code>&lt;VMname&gt;_nic_1</code>, then run the <code>nss configure</code> command to set the service interface IPs:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss configure

Detected an Azure VM!!
nameserver:168.63.129.16 (Options &lt;c:change, d:delete, n:no change&gt;) [n]n
Do you wish to add a new nameserver? &lt;n:no y:yes&gt; [n]: n
smnet_dev (Service interface IP address with netmask) []: 10.0.0.4/24
smnet_dflt_gw (Service interface default gateway IP address) []: 10.0.0.1
Successfully Applied Changes
</code></pre><p>When prompted, enter the IP address in CIDR format for the service interface (see above for formatting), and the IP address of the gateway for the service interface (if you use a /24 subnet, this will be the .1 IP address)</p>
<h2 id="3-download-the-ssl-certificate-package">3. Download the SSL Certificate Package</h2>
<p>Download the SSL Certificate package for your NSS VM from the ZIA portal under <strong>Administration &gt; Nanolog Streaming Service</strong>.</p>
<p><img src="18.png" alt="18"></p>
<p>WARNING: This package is different for each NSS VM you have listed. Sharing the same certificate between NSS deployments will cause connection flapping.</p>
<p>Copy this package to the NSS VM:</p>
<pre tabindex="0"><code>scp NssCertificate.zip zsroot@&lt;ip&gt;:
</code></pre><p>Install the certificate package on the NSS VM:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss install-cert NssCertificate.zip
</code></pre><p>Check the configuration:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss dump-config
Detected an Azure VM!!
Configured Values:
	CloudName:zscaler.net
	nameserver:168.63.129.16	
	smnet_dev:10.0.0.4/24	
	Default gateway for Service IP:10.0.0.1	
	Routes for Siem N/w:
</code></pre><p>If the SSL package was installed correctly, you will see your cloud name referenced in the configuration (eg: zscaler.net).</p>
<h2 id="4-update-the-nss-service">4. Update the NSS Service</h2>
<p>The NSS service on the fresh VM is probably out-of-date. To update it, run the <code>nss update-now</code> command:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss update-now
</code></pre><p>Updating may take some time&hellip;</p>
<p>You can check the current version with <code>nss checkversion</code>:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss checkversion
</code></pre><h2 id="5-start-the-nss-service">5. Start the NSS Service</h2>
<p>To start the NSS service, run <code>nss start</code>:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss start
</code></pre><p>This will NOT start NSS on boot by default. You should enable autostart:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss enable-autostart
</code></pre><h2 id="6-verify-connectivity">6. Verify Connectivity</h2>
<p>To check active connections from NSS, run the following command:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss troubleshoot netstat | grep tcp
</code></pre><p>NSS only requires outbound connectivity to the Zscaler Cloud and your SIEM/destination. No inbound connectivity is necessary (unless you&rsquo;ve enabled SSH).</p>
<p>A healthy NSS instance will have two TCP connections in the <code>ESTABLISHED</code> state:</p>
<pre tabindex="0"><code>[zsroot@NSS ~]$ sudo nss troubleshoot netstat | grep tcp
//+SHARED MEMORY KEY 17 (/sc/)
tcp          0(  0%)       69(  0%) 10.0.0.4.2942          104.129.193.102.443   ESTABLISHED
tcp          0(  0%)        0(  0%) 10.0.0.4.2110          104.129.193.102.443   TIME_WAIT
</code></pre><p>If you only see one connection, wait a few minutes and check again. If neither connection is in the <code>ESTABLISHED</code> state, or you are still missing a connection, check your firewall and ensure you have reachability to the Zscaler infrastructure. You can check the network requirements for NSS using the links below (select the link corresponding to the Zscaler cloud you have been provisioned on):</p>
<ul>
<li><a href="https://ips.zscaler.net/nss">https://ips.zscaler.net/nss</a></li>
<li><a href="https://ips.zscalerone.net/nss">https://ips.zscalerone.net/nss</a></li>
<li><a href="https://ips.zscalertwo.net/nss">https://ips.zscalertwo.net/nss</a></li>
<li><a href="https://ips.zscalerthree.net/nss">https://ips.zscalerthree.net/nss</a></li>
<li><a href="https://ips.zscloud.net/nss">https://ips.zscloud.net/nss</a></li>
</ul>
<p>Return to the ZIA portal, and under <strong>Administration &gt; Nanolog Streaming Service</strong>, the NSS instance you just deployed <em>should</em> now read as <strong>Healthy</strong>:</p>
<p><img src="19.png" alt="19"></p>
<hr>
<h1 id="part-6---add-nss-feeds-to-stream-data">Part 6 - Add NSS Feeds to Stream Data</h1>
<p>NSS Feeds configured in the ZIA portal explicitly tell your NSS VM instance what data to stream, where to stream it, and in what format it is required.</p>
<p>Each NSS VM can be configured with up to 8 data feeds.</p>
<h2 id="1-configure-an-nss-feed">1. Configure an NSS Feed</h2>
<p>To configure an NSS Feed, go to Administration &gt; Nanolog Streaming Service, then select the <strong>NSS Feeds</strong> tab. Click <strong>Add NSS Feed</strong>.</p>
<p><img src="20.png" alt="20"></p>
<p>Fill in the following data when prompted:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>The name of the NSS Feed</td>
</tr>
<tr>
<td>NSS Server</td>
<td>Which NSS VM is responsible for streaming this feed.</td>
</tr>
<tr>
<td>SIEM Destination Type</td>
<td>Select whether to use an IP or FQDN (domain) to specify the destination SIEM you would like to stream data to.</td>
</tr>
<tr>
<td>SIEM TCP Port</td>
<td>The destination TCP port the SIEM expects to receive data on.</td>
</tr>
<tr>
<td>Log Type</td>
<td>Typically you will want to select Web, but alerts can be streamed in RFC compliant Syslog as well.</td>
</tr>
<tr>
<td>Feed Output Type</td>
<td>The format (as shown in the window) that the logs will be streamed to the SIEM in (see the note below)</td>
</tr>
<tr>
<td>Filters</td>
<td>By default, the NSS feed will stream EVERYTHING. You can filter down the data stream to only specific data that you care about using the tabs at the bottom of the configuration window.</td>
</tr>
</tbody>
</table>
<p><img src="21.png" alt="21"></p>
<p>Click <strong>Save</strong> when you are done and activate your changes.</p>
<p>Note that Zscaler has formal <a href="https://www.zscaler.com/partners/technology/siem-analytics">partnerships</a> with several SIEM vendors, and in many cases has co-written deployment guides for them. If you don&rsquo;t see your SIEM listed in the Feed Output Type, check to see if they don&rsquo;t already have an article on Zscaler integration. Failing that, odds are they can probably ingest one of the existing formats; like QRadar LEEF, or Arcsight CEF.</p>
<p>Zscaler documentation covers how to configure feeds for a variety of features:</p>
<ul>
<li><a href="https://help.zscaler.com/zia/adding-nss-feeds-alerts">Adding an NSS Feed for Alerts</a></li>
<li><a href="https://help.zscaler.com/zia/adding-nss-feeds-dns-logs">Adding NSS Feeds for DNS Logs</a></li>
<li><a href="https://help.zscaler.com/zia/adding-nss-feeds-firewall-logs">Adding NSS Feeds for Firewall Logs</a></li>
<li><a href="https://help.zscaler.com/zia/adding-nss-feeds-tunnel-logs">Adding NSS Feeds for Tunnel Logs</a></li>
<li><a href="https://help.zscaler.com/zia/adding-nss-feeds-web-logs">Adding NSS Feeds for Web Logs</a></li>
</ul>
<h2 id="2-configuring-mcas">2. Configuring MCAS</h2>
<p>If you&rsquo;re looking to integrate with Microsoft Cloud App Security (MCAS), <a href="/posts/integrate-zia-and-mcas">I&rsquo;ve written a detailed guide here</a>.</p>
<hr>
<h1 id="finish">Finish</h1>
<p>You should now have a healthy NSS deployment in Azure.</p>
<p>If you deployed this for lab or demo purposes, <strong>make sure you don&rsquo;t forget about the running NSS VM!</strong> Ensure you stop and de-allocate resources after you&rsquo;re done so you don&rsquo;t continue to be charged.</p>
]]></content>
        </item>
        
        <item>
            <title>Configure Pi-Hole DNS &#43; Cloudflare DNS over HTTPS (DoH) on a Raspberry Pi</title>
            <link>https://nathancatania.com/posts/pihole-dns-doh/</link>
            <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/pihole-dns-doh/</guid>
            <description>Block ads, trackers, and malware from any local device without having to use an ad-blocker; while securing your DNS traffic at the same time - sounds good!
First, what is Pi-Hole? According to Jacob Salmela, the creator of Pi-Hole:
Pi-hole is a network-wide ad blocker. Instead of installing adblockers on every device and every browser, you can install Pi-hole once on your network, and it will protect all of your devices.</description>
            <content type="html"><![CDATA[<p>Block ads, trackers, and malware from any local device without having to use an ad-blocker; while securing your DNS traffic at the same time - sounds good!</p>
<p>First, what is Pi-Hole? According to <a href="https://www.raspberrypi.org/blog/pi-hole-raspberry-pi/">Jacob Salmela, the creator of Pi-Hole</a>:</p>
<blockquote>
<p>Pi-hole is a network-wide ad blocker. Instead of installing adblockers on every device and every browser, you can install Pi-hole once on your network, and it will protect all of your devices. Because it works differently than a browser-based ad-blocker, Pi-hole also blocks ads in non-traditional places, such as in games and on smart TVs.</p>
</blockquote>
<p>That sounds pretty great!</p>
<p>This guide will cover the following deployment onto a Raspberry Pi (although any Linux-based device/OS can be used):</p>
<ul>
<li>Pi-Hole will be installed and used as DNS for all home devices to block ads, trackers, and malware domains.</li>
<li>DNS over HTTPs (using Cloudflare) will be configured to secure our upstream DNS requests.</li>
</ul>
<p>Let&rsquo;s get started!</p>
<hr>
<h1 id="configure-cloudflare-dns-over-https-doh">Configure Cloudflare DNS over HTTPS (DoH)</h1>
<p>While Pi-Hole will be used as our local DNS server, it will need to query an upstream DNS provider (like Google, or Cloudflare) itself to return a result (provided the query has not already been cached by Pi-Hole). Typically you would set the upstream DNS provider in Pi-Hole to 1.1.1.1 (Cloudflare) or 8.8.8.8 (Google), however these requests are not secured in transit.</p>
<p>We&rsquo;re going to use DNS over HTTPS (DoH) to secure our DNS requests to Cloudflare across our ISP&rsquo;s network to provide us with more privacy.</p>
<h2 id="what-is-doh-and-why-should-i-bother">What is DoH and why should I bother?</h2>
<h3 id="the-problem-with-dns-and-isps">The problem with DNS and ISPs</h3>
<p>DNS was not designed with security in mind. Queries are sent in plaintext across your ISP&rsquo;s network and are not encrypted or authenticated by default. This is true even if the site you are visiting uses HTTPS: the DNS query to resolve the domain is still sent unencrypted.</p>
<p>Why is this an issue? The same reason why you shouldn&rsquo;t do sensitive things like banking or online shopping on an insecure website: your data can be intercepted, read, and logged at any point in transit. For example, when you visited this webpage on my domain, nathancatania.com, anyone capturing network traffic would see your DNS query to resolve my domain and know that you were attempting to visit it. You can try this yourself, if you are so inclined, with Wireshark.</p>
<p>Many ISPs around the world will log your data, and in many cases are legally required to do so by local governments. Your DNS requests can paint a picture of your internet usage just like your browser history can, and having this logged at any point along can raise significant privacy concerns.</p>
<p>Unsecured DNS also raises the concern of Man-In-The-Middle attacks, where your DNS request could be intercepted and changed without your knowledge or consent. Instead of your requested domain resolving to 1.2.3.4, it might be changed to resolve to 5.6.7.8 instead - which could be a malicious domain or a copy of the original domain designed for phishing.
DNSSEC is a mechanism to help prevent this by authenticating that a DNS record has not been altered in transit. However, <a href="https://developers.cloudflare.com/1.1.1.1/dns-over-https/">according to Cloudflare</a>, only a single-digit percentage of domains use DNSSEC today. Additionally, DNSSEC does not provide confidentiality and will not prevent entities from snooping on your DNS requests.</p>
<h3 id="what-is-dns-over-https-doh">What is DNS over HTTPS (DoH)?</h3>
<p>DNS over HTTPS (DoH) is a method of securing your DNS requests, by sending the request to an HTTPS endpoint. This means that your DNS request appears as normal HTTPS (encrypted) web traffic instead of an actual DNS packet. All your ISP sees is secure HTTPS traffic coming from your network: no more DNS traffic that can be snooped on.</p>
<h3 id="the-subjective-issue-with-doh">The (subjective) issue with DoH</h3>
<p>It is worth noting that DoH itself presents some privacy issues as well: There are only a handful of DNS providers that support DoH (Cloudflare, Google, etc) and by using DoH, you would be trusting your DNS traffic to one of these larger centralized entities (although the same would be true if you just set 1.1.1.1 or 8.8.8.8 as your DNS provider anyway): How do you know that these companies are safely and responsibly handling your data? You don&rsquo;t.</p>
<p>There is also the argument that using DoH centralizes DNS to a few larger providers, giving them too much power over the internet as a whole. DNS was designed to be highly distributed across the internet, and the concept of DoH goes against that principle.</p>
<h3 id="what-should-i-do">What should I do?</h3>
<p>This boils down to: Who do you trust more? Your ISP, a company like Cloudflare or Google, or no-one but yourself?</p>
<ul>
<li>If you answered &ldquo;My ISP&rdquo;, then DoH probably isn&rsquo;t for you and you can keep on doing what you&rsquo;ve been doing for DNS up until now. You might consider using DoH if your ISP&rsquo;s DNS service offers it.</li>
<li>If you answered &ldquo;Cloudflare, Google, etc&rdquo;, then DoH is for you.</li>
<li>If you answered &ldquo;No-one but myself&rdquo;, then a solution like <a href="https://nlnetlabs.nl/projects/unbound/about/">Unbound</a> (a recursive and caching DNS resolver) is probably a better solution for you. I don&rsquo;t cover Unbound in this post, but may in the future.</li>
<li>If all you care about is the &ldquo;bad guys&rdquo; not being able to see your data, then DoH is also for you.</li>
</ul>
<p>In this post, we&rsquo;ll be using Cloudflare DoH.</p>
<h2 id="trying-out-cloudflare-doh">Trying out Cloudflare DoH</h2>
<p>DNS requests occur via an HTTPS endpoint. We can test this using cURL and JSON.</p>
<p>IPv4 (A record) request for <code>example.com</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>curl -H <span style="color:#e6db74">&#39;accept: application/dns-json&#39;</span> <span style="color:#e6db74">&#39;https://cloudflare-dns.com/dns-query?name=example.com&amp;type=A&#39;</span>
</span></span></code></pre></div><p>Response for <code>example.com</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Status&#34;</span>: <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;TC&#34;</span>: <span style="color:#66d9ef">false</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;RD&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;RA&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;AD&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;CD&#34;</span>: <span style="color:#66d9ef">false</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Question&#34;</span>: [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;example.com.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Answer&#34;</span>: [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;example.com.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;TTL&#34;</span>: <span style="color:#ae81ff">1409</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;data&#34;</span>: <span style="color:#e6db74">&#34;93.184.216.34&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>IPv6 (AAAA record) request for <code>example.com</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -H <span style="color:#e6db74">&#39;accept: application/dns-json&#39;</span> <span style="color:#e6db74">&#39;https://cloudflare-dns.com/dns-query?name=example.com&amp;type=AAAA&#39;</span>
</span></span></code></pre></div><p>Response for <code>example.com</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Status&#34;</span>: <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;TC&#34;</span>: <span style="color:#66d9ef">false</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;RD&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;RA&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;AD&#34;</span>: <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;CD&#34;</span>: <span style="color:#66d9ef">false</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Question&#34;</span>: [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;example.com.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#ae81ff">28</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  ],
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Answer&#34;</span>: [
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;example.com.&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#ae81ff">28</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;TTL&#34;</span>: <span style="color:#ae81ff">10226</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;data&#34;</span>: <span style="color:#e6db74">&#34;2606:2800:220:1:248:1893:25c8:1946&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="configuring-cloudflare-doh-on-a-raspberry-pi">Configuring Cloudflare DoH on a Raspberry Pi</h2>
<p>The source for much of this was the <a href="https://docs.pi-hole.net/guides/dns-over-https/">official Pi-Hole documentation on DoH</a>.</p>
<p>The method detailed here should work for non-Raspberry Pi systems, but you may need to switch out the ARM binary.</p>
<h3 id="install-the-cloudflared-daemon">Install the cloudflared daemon</h3>
<p>We&rsquo;re going to use <code>cloudflared</code> (or an &lsquo;Argo Tunnel&rsquo; as Cloudflare call it) as our DoH proxy. This will listen for DNS queries on port 5353 (or any custom port you specify), and proxy the requests received to the Cloudflare DoH endpoint. The response received from Cloudflare is then returned via the proxy back to the host that sent the original DNS query.</p>
<p>Why port 5353 and not 53? You can specify any port that isn&rsquo;t in use, apart from port 53. 53 is the standard port for DNS, and Pi-Hole will already be using this port to listen for DNS queries from our local hosts/devices.</p>
<ol>
<li>Create a new <em>service account</em> to run the <code>cloudflared</code> daemon:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo useradd -s /usr/sbin/nologin -r -M cloudflared
</span></span></code></pre></div><ol start="2">
<li>Download the binary tgz for <code>ARMv6</code> devices. The download link can be verified <a href="https://developers.cloudflare.com/argo-tunnel/downloads/">here</a>. If you&rsquo;re <em>not</em> using an RPi, then pick a non-ARM binary.</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-arm.tgz
</span></span></code></pre></div><ol start="3">
<li>Unpack the binary, and copy it to the <code>/usr/local/bin</code> directory, and make it executable:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tar -xzvf cloudflared-stable-linux-arm.tgz
</span></span><span style="display:flex;"><span>sudo cp ./cloudflared /usr/local/bin
</span></span><span style="display:flex;"><span>sudo chmod +x /usr/local/bin/cloudflared
</span></span></code></pre></div><ol start="4">
<li>Change permissions so the <code>cloudflared</code> service account can access it:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo chown cloudflared:cloudflared /usr/local/bin/cloudflared
</span></span></code></pre></div><ol start="5">
<li>Check the binary is working. This should show the version:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cloudflared -v
</span></span><span style="display:flex;"><span>&gt; cloudflared version 2019.9.0 <span style="color:#f92672">(</span>built 2019-09-06-0334 UTC<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>If you get a segmentation fault, you may need to compile from <a href="https://github.com/cloudflare/cloudflared">source</a> as per the issue reported <a href="https://github.com/cloudflare/cloudflared/issues/38">here</a>.</p>
<h3 id="create-the-configuration-file">Create the Configuration File</h3>
<p>We need to create a configuration file for cloudflared  at <code>/etc/default/cloudflared</code> which specifies:</p>
<ol>
<li>The local port to listen on for DNS requests. These will be proxied upstream to Cloudflare using DoH. As per the Pi-Hole documentation, I used <code>5053</code> (although this could be any valid port).</li>
<li>The upstream HTTPS endpoint(s). We&rsquo;ll use <code>https://1.1.1.1/dns-query</code> and <code>https://1.0.0.1/dns-query</code>.</li>
</ol>
<p>The options specified in this file will be passed to the <code>cloudflared</code> daemon.</p>
<p>Create the configuration file (CTRL+X to save and quit):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo nano /etc/default/cloudflared
</span></span></code></pre></div><p>Add the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#75715e"># Commandline args for cloudflared</span>
</span></span><span style="display:flex;"><span>CLOUDFLARED_OPTS<span style="color:#f92672">=</span>--port <span style="color:#ae81ff">5053</span> --upstream https://1.1.1.1/dns-query --upstream https://1.0.0.1/dns-query
</span></span></code></pre></div><p>Change the port as required. This will listen for DNS requests on port 5053 (DNS is normally port 53) and will proxy it to either of the 1.1.1.1 or 1.0.0.1 HTTPS endpoints.</p>
<p>Change the permissions for the configuration file so the <code>cloudflared</code> service account can access it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo chown cloudflared:cloudflared /etc/default/cloudflared
</span></span></code></pre></div><h3 id="run-at-startup">Run at Startup</h3>
<p>The above is all well and good, but it requires the <code>cloudflared</code> daemon to be started manually after each restart and/or error.</p>
<p>Courtesy of Pi-Hole, we can use the below to create a <code>systemd</code> service that will automatically run on boot and restart on any error.</p>
<p>Create the service file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo nano /lib/systemd/system/cloudflared.service
</span></span></code></pre></div><p>Add the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>Unit<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Description<span style="color:#f92672">=</span>cloudflared DNS over HTTPS proxy
</span></span><span style="display:flex;"><span>After<span style="color:#f92672">=</span>syslog.target network-online.target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Service<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Type<span style="color:#f92672">=</span>simple
</span></span><span style="display:flex;"><span>User<span style="color:#f92672">=</span>cloudflared
</span></span><span style="display:flex;"><span>EnvironmentFile<span style="color:#f92672">=</span>/etc/default/cloudflared
</span></span><span style="display:flex;"><span>ExecStart<span style="color:#f92672">=</span>/usr/local/bin/cloudflared proxy-dns $CLOUDFLARED_OPTS
</span></span><span style="display:flex;"><span>Restart<span style="color:#f92672">=</span>on-failure
</span></span><span style="display:flex;"><span>RestartSec<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>KillMode<span style="color:#f92672">=</span>process
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>Install<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>WantedBy<span style="color:#f92672">=</span>multi-user.target
</span></span></code></pre></div><p>Load the service, set it to run at startup, and start the service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo systemctl daemon-reload
</span></span><span style="display:flex;"><span>sudo systemctl enable cloudflared
</span></span><span style="display:flex;"><span>sudo systemctl start cloudflared
</span></span></code></pre></div><p>Check the status:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo systemctl status cloudflared
</span></span></code></pre></div><p>It should be running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>● cloudflared.service - cloudflared DNS over HTTPS proxy
</span></span><span style="display:flex;"><span>   Loaded: loaded <span style="color:#f92672">(</span>/lib/systemd/system/cloudflared.service; enabled; vendor preset: enabled<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   Active: active <span style="color:#f92672">(</span>running<span style="color:#f92672">)</span> since Sun 2019-09-29 15:37:44 AEST; <span style="color:#ae81ff">3</span> weeks <span style="color:#ae81ff">1</span> days ago
</span></span><span style="display:flex;"><span> Main PID: <span style="color:#ae81ff">652</span> <span style="color:#f92672">(</span>cloudflared<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    Tasks: <span style="color:#ae81ff">14</span> <span style="color:#f92672">(</span>limit: 2200<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>   Memory: 35.6M
</span></span><span style="display:flex;"><span>   CGroup: /system.slice/cloudflared.service
</span></span><span style="display:flex;"><span>           └─652 /usr/local/bin/cloudflared proxy-dns --port <span style="color:#ae81ff">5053</span> --upstream https://1.1.1.1/dns-query --upstream https://1.0.0.1/dns-query
</span></span></code></pre></div><p>If you encounter an issue, you can view the log output of the service using the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo journalctl -u cloudflared
</span></span></code></pre></div><h2 id="verify-the-dns-requests-are-proxied-correctly">Verify the DNS requests are proxied correctly</h2>
<p>To verify, use <code>nslookup</code> specifying your custom port (5053 above) and <code>127.0.0.1</code> (localhost) as the DNS server.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>nslookup -port<span style="color:#f92672">=</span><span style="color:#ae81ff">5053</span> example.com 127.0.0.1
</span></span></code></pre></div><p>If everything is working correctly, you should see a response as per the below:</p>
<pre tabindex="0"><code>Server:   127.0.0.1
Address:  127.0.0.1#5053

Non-authoritative answer:
Name: example.com
Address: 93.184.216.34
Name: example.com
Address: 2606:2800:220:1:248:1893:25c8:1946
</code></pre><p>Note that the server is the localhost/Raspberry Pi and the port is 5053 which we defined above. We successfully get a response using these parameters which means DoH has been configured correctly and is working. Testing with <code>example.com</code> we should see an identical result to our earlier test.</p>
<h2 id="done">Done!</h2>
<p>You now have a DNS proxy running on your Raspberry Pi. If you were to tell clients to use your Raspberry Pi for DNS and to send requests on port 5053 (instead of port 53), they will get a response after the Raspberry Pi forwards the DNS request to Cloudflare over HTTPS.</p>
<h2 id="troubleshooting">Troubleshooting</h2>
<p>If <code>nslookup</code> doesn&rsquo;t return anything or looks like it hangs, then your request is not being proxied using DoH. This indicates either a config issue (check the port you specified and whether your HTTPS endpoints in your config file are correct), or you could have an issue with your networking (your specified port could already be in use or the request/response is being blocked by a firewall).</p>
<hr>
<h1 id="configure-pi-hole">Configure Pi-Hole</h1>
<p>In the next step, we will install Pi-Hole and tell it to use 127.0.0.1 (localhost), Port 5053 as its upstream DNS. All DNS requests sent to this location will be proxied using DoH to Cloudflare.</p>
<p>When you&rsquo;re done with this section, you&rsquo;ll be able to set the IP address of your Pi-Hole system (eg: 10.0.0.5) as your DNS provider on your devices, or in your router/modem, and all ads on the web will magically disappear!</p>
<h2 id="requirements">Requirements</h2>
<p>There are a couple of things you&rsquo;ll need to check and have in place before continuing.</p>
<h3 id="check-your-network-interfaces">Check your Network Interfaces</h3>
<p>Your Raspberry Pi (or similar instance) probably has multiple network interfaces. In the case of the RPi, you&rsquo;ll have at least 3: loopback/localhost (<code>lo0</code>), ethernet (<code>eth0</code>), and wireless (<code>wlan0</code>). You&rsquo;ll need to note down the interface that Pi-Hole will use and listen for incoming DNS requests on.</p>
<p>I would strongly advise you to NOT use wireless or Wi-Fi for Pi-Hole, and instead use a wired connection (<code>eth0</code> or similar).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>nathan@pi:~ $ ip -c address
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span style="display:flex;"><span>    inet 127.0.0.1/8 scope host lo
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 ::1/128 scope host 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc pfifo_fast state UP group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/ether b8:27:eb:XX:XX:XX brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 10.0.0.5/24 brd 10.0.0.255 scope global noprefixroute eth0
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::e0bc:::/64 scope link 
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>3: wlan0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc pfifo_fast state DOWN group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/ether b8:27:eb:XX:XX:XX brd ff:ff:ff:ff:ff:ff
</span></span></code></pre></div><h3 id="assign-a-static-ip-address">Assign a Static IP Address</h3>
<p>The system that Pi-Hole is installed on <strong>must</strong> have a static IP address, or it&rsquo;s current IP address reserved in your DHCP server or modem/router. You&rsquo;ll be pointing all of your devices to use Pi-Hole as their DNS, so if Pi-Hole&rsquo;s IP address changes, all of your devices will break.</p>
<p>To set a static IP on the Raspberry Pi, edit <code>/etc/dhcpcd.conf</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>nathan@pi:~ $ sudo nano /etc/dhcpcd.conf
</span></span></code></pre></div><p>Define a static IP, gateway, and DNS under &ldquo;<em>Example static IP configuration</em>&rdquo;, and (optionally) define the hostname:</p>
<pre tabindex="0"><code>[..snip...]

# Inform the DHCP server of our hostname for DDNS.
pi.yourdomain.internal

[..snip..]

# Example static IP configuration:
interface eth0
static ip_address=10.0.0.5/24
#static ip6_address=fd51:42f8::::/64
static routers=10.0.0.1
static domain_name_servers=1.1.1.1 1.0.0.1
</code></pre><p>Use <code>CTRL+X</code> then <code>Y</code> to exit. Reboot when you have finished:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>nathan@pi:~ $ sudo reboot
</span></span></code></pre></div><h2 id="download-the-pi-hole-installer">Download the Pi-Hole installer</h2>
<p>For reference, you may want to have a read of the <a href="https://github.com/pi-hole/pi-hole">Pi-Hole documentation</a>.</p>
<p>Download and run the Pi-Hole installer:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>wget -O basic-install.sh https://install.pi-hole.net
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>sudo bash basic-install.sh
</span></span></code></pre></div><h2 id="configure-the-installer">Configure the Installer</h2>
<p>Upon running the installer, you&rsquo;ll be taken to a colored screen. Follow the prompts and the instructions below to install Pi-Hole.</p>
<ol>
<li>When prompted, select the network interface to use for Pi-Hole (recommended: <code>eth0</code> for an RPi):</li>
</ol>
<p><img src="1.png" alt="1"></p>
<ol start="2">
<li>For the <strong>Upstream DNS Provider</strong>, select anything for the time being (Google, Cloudflare, etc). We will change this later.</li>
</ol>
<p><img src="2.png" alt="2"></p>
<ol start="3">
<li>For the blocklists, leave the default selected and continue:</li>
</ol>
<p><img src="3.png" alt="3"></p>
<ol start="4">
<li>
<p>Select whether to enable IPv4 and/or IPv6. If you&rsquo;re not sure, leave this option as the default (both options selected).</p>
</li>
<li>
<p>The following step will ask you to confirm the Static IP address and Gateway. The IP and Gateway displayed on-screen <em>should</em> match the static IP you set earlier. If not, you can alter it here (most likely you selected the wrong interface at Step 1).</p>
</li>
</ol>
<p>Most of the remaining configuration can be left as the default:</p>
<ul>
<li>Ensure the web interface is installed. In the following step, ensure you also install the webserver (Lighttpd).</li>
<li>Ensure queries are logged. If you have tight or severe security concerns you might want to disable this.</li>
<li>When prompted to select a <a href="https://docs.pi-hole.net/ftldns/privacylevels/">privacy mode</a>, the setting is up to you.
<ul>
<li>Everything is stored locally on the Pi-Hole device, so for some lovely analytics, you might want to select &ldquo;Show everything&rdquo;.</li>
<li>Conversely, if you are concerned about the privacy of the logs, you might want to select settings 1, 2, or 3.</li>
</ul>
</li>
</ul>
<p><img src="4.png" alt="4"></p>
<p>At this point, your configuration is done and Pi-Hole will finish installing. When the process is finished, you&rsquo;ll get one final screen with your default admin credentials.</p>
<p><img src="5.png" alt="5"></p>
<p>Ignore the default password: You should change it to something more secure. You can change (or reset) the password from the command-line:</p>
<pre tabindex="0"><code>sudo pihole -a -p
</code></pre><p>Setting a blank password will disable the password requirement for the Admin UI (not recommended).</p>
<h2 id="adding-firewall-rules">Adding Firewall Rules</h2>
<p>Depending on your device, you may need to permit inbound connections from TCP 80 and UDP 53. This will allow you to access the Web UI and for Pi-Hole to receive DNS queries from devices.</p>
<p>If you&rsquo;re using a Raspberry Pi, you can do this using <code>ufw</code>:</p>
<pre tabindex="0"><code>sudo ufw limit ssh
sudo ufw allow dns
sudo ufw allow 80/tcp
</code></pre><p>The first line will allow through SSH connections for management. You may or may not want to do this. As Pi-Hole is not exposed inbound from the internet and is local to your home network, this should be OK from a security standpoint.</p>
<p>Lastly, you need to enable <code>ufw</code> for the settings to take effect:</p>
<pre tabindex="0"><code>sudo ufw enable
</code></pre><p>You can check the status of <code>ufw</code> and it&rsquo;s associated rules using the below command:</p>
<pre tabindex="0"><code>nathan@pi:~ $ sudo ufw status
Status: active

To                         Action      From
--                         ------      ----
22/tcp                     LIMIT       Anywhere                  
80/tcp                     ALLOW       Anywhere                  
DNS                        ALLOW       Anywhere                  
22/tcp (v6)                LIMIT       Anywhere (v6)             
80/tcp (v6)                ALLOW       Anywhere (v6)             
DNS (v6)                   ALLOW       Anywhere (v6)             
</code></pre><h2 id="access-the-admin-web-interface">Access the Admin Web Interface</h2>
<p>Open your web browser and navigate to:</p>
<pre tabindex="0"><code>http://&lt;pi-hole-ip&gt;/admin
</code></pre><p>Where <code>&lt;pi-hole-ip&gt;</code> is the static IP address you set for Pi-Hole. The admin UI should appear.</p>
<ul>
<li>If you get a blank screen with the Pi-Hole logo only, make sure you added the <code>/admin</code> at the end of the URL.</li>
</ul>
<p>If you&rsquo;re getting a <code>CONNECTION_REFUSED</code> error or similar, check to see that you have configured your firewall rules correctly to allow inbound connections on port 80.</p>
<p>Alternatively, check the other IP addresses of any other network interfaces you have; <code>wlan0</code>, <code>lo0</code> etc. You may have selected the wrong interface when installing Pi-Hole. You can re-run the installer again to fix this.</p>
<p>Click <strong>Login</strong> in the side panel to log into the Dashboard using the admin password you set earlier.</p>
<p><img src="6.png" alt="6"></p>
<p>Your Dashboard will start to populate data once your devices start using Pi-Hole for DNS.</p>
<p>If you notice that some sites stop working once you start using Pi-Hole, you can bypass the block under <strong>Whitelist</strong>.</p>
<h3 id="managing-blocks-adlists">Managing Blocks (Adlists)</h3>
<p>To manage/add/remove Adlists (lists of domains that should be blocked), go to <strong>Group Management &gt; Adlists</strong>. The two default adlists should be listed. Here are some other common lists:</p>
<pre tabindex="0"><code>http://sysctl.org/cameleon/hosts
https://s3.amazonaws.com/lists.disconnect.me/simple_tracking.txt
https://s3.amazonaws.com/lists.disconnect.me/simple_ad.txt
https://hosts-file.net/ad_servers.txt
</code></pre><p>Anything listed as an entry in any of your Adlists will be blocked.</p>
<h2 id="set-cloudflare-doh-as-the-upstream-dns-provider">Set Cloudflare DoH as the Upstream DNS provider</h2>
<p>We now need to tell Pi-Hole to use our DoH configuration for DNS queries.</p>
<p>Under <strong>Settings</strong>, click the <strong>DNS</strong> tab. De-select everything under <strong>Upstream DNS Servers</strong> and then add the following as a custom server:</p>
<pre tabindex="0"><code>127.0.0.1#5053
</code></pre><p>Replace <code>5053</code> with whatever port you set the <code>cloudflared</code> daemon to listen on for requests.</p>
<p>Under <strong>Interface listening behavior</strong> select the option to <strong>Listen only on interface eth0</strong> (or whatever interface you configured Pi-Hole on).</p>
<p>Lastly under <strong>Advanced DNS settings</strong>, check the box to <strong>enable</strong> the first 3 options:</p>
<ul>
<li>Never forward non-FQDNs</li>
<li>Never forward reverse lookups for private IP ranges</li>
<li>Use DNSSEC</li>
</ul>
<p><img src="7.png" alt="7"></p>
<h2 id="verify-dns-resolution-is-functioning-correctly">Verify DNS resolution is functioning correctly</h2>
<p>On another device, manually set the DNS to point to the IP address of your Pi-Hole system, eg: 10.0.0.5. Alternatively, alter the <code>dhcpcd.conf</code> file on your RPi to point to its IP address.</p>
<p>You should start to see DNS query traffic within the Pi-Hole Dashboard. Try querying <code>example.com</code>:</p>
<pre tabindex="0"><code>nathan@pi:~ $ nslookup example.com
Server:   10.0.0.5
Address:  10.0.0.5#53

Non-authoritative answer:
Name: example.com
Address: 93.184.216.34
Name: example.com
Address: 2606:2800:220:1:248:1893:25c8:1946
</code></pre><p><img src="8.png" alt="8"></p>
<p>You can also review the <strong>Query Log</strong> in the admin UI:</p>
<p><img src="9.png" alt="9"></p>
<h2 id="troubleshooting-1">Troubleshooting</h2>
<p>If <code>nslookup</code> doesn&rsquo;t return anything or looks like it hangs, then your request is not being proxied through Cloudflare DoH. Check that <code>cloudflared</code> is running and that you can query it directly from the Pi-Hole host:</p>
<pre tabindex="0"><code>nslookup -port=5053 example.com 127.0.0.1
</code></pre><p>If this fails, there could be a <code>cloudflared</code> config issue. Check the port you specified and whether the DoH endpoints/URLs are correct in the config file.</p>
<p>If the above command returns a result, then your issue is localized to Pi-Hole itself. Make sure any firewall in use (including <code>ufw</code>) is permitting DNS traffic inbound to the Pi-Hole host. DNS is port 53 (typically UDP, but TCP can be used as a fallback).</p>
<pre tabindex="0"><code>nathan@pi:~ $ sudo ufw status
Status: active

To                         Action      From
--                         ------      ----               
DNS                        ALLOW       Anywhere                  
...
</code></pre><p>Check to see if TCP/UDP 53 is open on the Pi-Hole device (UDP entries will not have &ldquo;LISTEN&rdquo; next to them. This is OK: unlike TCP, UDP is connectionless):</p>
<pre tabindex="0"><code>nathan@pi:~ $ netstat -ln | grep 53
tcp        0      0 0.0.0.0:53              0.0.0.0:*               LISTEN     
tcp        0      0 127.0.0.1:5053          0.0.0.0:*               LISTEN     
udp        0      0 0.0.0.0:53              0.0.0.0:*                          
udp        0      0 0.0.0.0:5353            0.0.0.0:*                          
udp        0      0 0.0.0.0:53149           0.0.0.0:*                          
udp        0      0 127.0.0.1:5053          0.0.0.0:*                          
</code></pre><p>You can also use the <code>pihole</code> command to manage Pi-Hole from the command-line.</p>
<p>Check the status of Pi-Hole:</p>
<pre tabindex="0"><code>nathan@pi:~ $ pihole status
  [✓] DNS service is running
  [✓] Pi-hole blocking is Enabled
</code></pre><p>Debug Pi-Hole (this produces a LOT of information for you to parse):</p>
<pre tabindex="0"><code>nathan@pi:~ $ pihole debug
[..snip..]
********************************************
********************************************
[✓] ** FINISHED DEBUGGING! **

[?] Would you like to upload the log? [y/N] n
    * Log will NOT be uploaded to tricorder.
    * A local copy of the debug log can be found at: /var/log/pihole_debug.log
    
    
nathan@pi:~ $ cat /var/log/pihole_debug.log
...
...
</code></pre><p>You can also try restarting the DNS service and subsystems:</p>
<pre tabindex="0"><code>nathan@pi:~ $ pihole restartdns
</code></pre><hr>
<h1 id="finish">Finish</h1>
<p>You should now have a working Pi-Hole deployment that forwards requests upstream to Cloudflare using DoH.</p>
<p>The last thing you need to do is get all of your devices to use your Pi-Hole DNS.</p>
<p>You could do this manually by setting the DNS on each device, or you could go the easy route and set your DHCP server (eg: your ISP modem/router) to use the Pi-Hole IP instead. This way, when a device obtains it&rsquo;s network settings via DHCP, it will automatically get the Pi-Hole IP address for it&rsquo;s DNS settings without you having to reconfigure every device manually.</p>
]]></content>
        </item>
        
        <item>
            <title>Deploying ZPA ZEN Connectors</title>
            <link>https://nathancatania.com/posts/deploying-zpa-zen-connectors/</link>
            <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploying-zpa-zen-connectors/</guid>
            <description>Disclaimer: I am an employee of Zscaler. These are my own notes from a ZPA homelab deployment and may be incorrect or against best practice. You should consult the Zscaler help portal for official documentation.
Connector Provisioning First, we are going to define the connector in the ZPA admin portal and generate the required provisioning key. The provisioning key authenticates the connector when it calls home to the ZPA cloud (via it&amp;rsquo;s established control channel), and associates it to your ZPA instance.</description>
            <content type="html"><![CDATA[<blockquote>
<p>Disclaimer: I am an employee of Zscaler. These are my own notes from a ZPA homelab deployment and may be incorrect or against best practice. You should consult the <a href="https://help.zscaler.com">Zscaler help portal</a> for official documentation.</p>
</blockquote>
<h1 id="connector-provisioning">Connector Provisioning</h1>
<p>First, we are going to define the connector in the ZPA admin portal and generate the required provisioning key. The provisioning key authenticates the connector when it calls home to the ZPA cloud (via it&rsquo;s established control channel), and associates it to your ZPA instance.</p>
<p>Log into the ZPA admin portal and navigate using the side menu to <strong>Administration</strong> &gt; <strong>Connectors</strong>.</p>
<figure><img src="zc1.png"
         alt="Access Connector management from the Administration menu"/><figcaption>
            <p>Access Connector management from the Administration menu</p>
        </figcaption>
</figure>

<p>In the top-right corner, click <strong>Add Connector</strong> to open the wizard workflow.</p>
<h2 id="step-1---provisioning-key">Step 1 - Provisioning Key</h2>
<p>Create a new provisioning key, or choose an existing one if you already have one that is able to be used.</p>
<p>If you elect to use an existing key, ensure it has not reached the maximum number of uses defined or the connector connector provisioning will fail. You can alter how many times an existing key can be used under <strong>Administration</strong> &gt; <strong>Connector Provisioning Keys</strong>.</p>
<p>Click <strong>Next</strong>.</p>
<p><img src="zc2.png" alt="2"></p>
<h2 id="step-2---signing-certificate">Step 2 - Signing Certificate</h2>
<p>Next choose the intermediate CA to be used to sign the identity and server certificates on the connector. When prompted, select <strong>Connector</strong>, then click <strong>Next</strong>.</p>
<p><img src="zc3.png" alt="3"></p>
<h2 id="step-3---connector-groups">Step 3 - Connector Groups</h2>
<p>Create a new <strong>Connector Group</strong>, or select an existing one.</p>
<p>Connector Groups are a logical grouping of connectors, and help facilitate high availability and horizontal scaling. Each connector belongs to a specific Connector Group. Connectors are updated weekly and are brought down and up again for automatic software updates on a round-robin basis within the group.</p>
<p>If creating a new group, you will need to specify a 4 hour weekly upgrade interval in which all connectors within this group will take turns automatically updating and rebooting. You will also need to specify the geographic location of the connectors in the group.</p>
<p>When you are finished, click <strong>Next</strong>.</p>
<p><img src="zc4.png" alt="4"></p>
<h2 id="step-4---provisioning-key-details">Step 4 - Provisioning Key Details</h2>
<p>If in Step 1 you elected to create a NEW Provisioning Key, you will be prompted to <strong>give it a name and set the MAXIMUM number of times it can be re-used</strong> for other new connectors. This is an API enforced value, meaning it can be changed from within the ZPA admin portal (Administration &gt; Connector Provisioning Keys) at a later stage.</p>
<p>It may be worth setting a key re-usabilty value based on the number of connectors you plan on deploying in a single Connector Group. This will assist you when it comes to scaling your connectors for a specific LAN segment.</p>
<p><strong>Any connectors deployed with this Provisioning Key will be named after the key, so you&rsquo;ll want to give it a descriptive name.</strong> For example, a key with the name &lsquo;Melbourne&rsquo;, will have its associated connectors automatically named <code>Melbourne-1</code>, <code>Melbourne-2</code>, and so on.</p>
<p>If you elected to use an existing key, you will be shown how many times it has already been used.</p>
<p>Click <strong>Next</strong> when ready.</p>
<p><img src="zc5.png" alt="5"></p>
<h2 id="step-5-6---review-selection-and-generate-the-provisioning-key">Step 5-6 - Review Selection and Generate the Provisioning Key</h2>
<p>Once you have reviewed the information on the <strong>Review</strong> tab, click <strong>Save</strong>.</p>
<p><strong>Your Provisioning Key will be generated and displayed.</strong></p>
<p><strong>IMPORTANT: This key is CONFIDENTIAL INFORMATION and should be stored securely.</strong> Depending on the number of times you specified the key can be re-used, anyone with your provisioning key could deploy a connector and have it associated with your Connector Group and ZPA instance. Treat it like an API key and secure it.</p>
<p>Selecting a deployment platform at the bottom of the window will load an inline help article from <code>help.zscaler.com</code> guiding you through the deployment process.</p>
<p><img src="zc6.png" alt="6"></p>
<h2 id="next-steps">Next Steps</h2>
<p>Click <strong>Done</strong> when you are ready.</p>
<p><strong>Only connectors that have been BOTH provisioned and enrolled will show up under Administration &gt; Connectors!</strong> We have provisioned the connector in the admin portal, but still need to deploy the connector and wait until it calls home to the ZPA cloud to enroll itself. Only then will it show in the list.</p>
<p>You can click on the <strong>Connector Groups</strong> tab or <strong>Connector Provisioning Keys</strong> tab at the top to review these details respectively.</p>
<h1 id="connector-minimum-requirements">Connector Minimum Requirements</h1>
<h2 id="requirement-1---deploy-connectors-in-pairs">Requirement 1 - Deploy Connectors in pairs</h2>
<p>Zscaler recommends you deploy connectors in pairs. Why? To ensure high-availability of your private applications.</p>
<p>As you would have specified when creating a Connector Group above, connectors have a weekly scheduled slot in which they perform an automatic software update. This causes the connector briefly go offline as it needs to reboot to complete the update process. Connectors in a group are never updated at the same time.</p>
<p>Hence, if you deploy connectors (at least) in pairs, when one connector begins to update, your applications will still be accessible through the second connector. When the first connector comes back up, the second connector will begin to update. This process repeats until all connectors in a group are updated.</p>
<h2 id="requirement-2---compute-resources-per-connector">Requirement 2 - Compute Resources per Connector</h2>
<p>Every connector has the following minimum resource requirements:</p>
<ul>
<li>2 vCPUs</li>
<li>4GB RAM</li>
<li>8GB Disk (~1GB thin provisioning)</li>
<li>1 NIC</li>
</ul>
<p>This provides each connector with a maximum throughput capacity of ~500 Mbps. If you need to scale beyond that, Zscaler recommends you deploy multiple connectors rather than simply increasing the resources allocated to the connector VM. This has an added bonus of increasing your overall resiliency to connector failure.</p>
<p>In a lab environment, you will get away with 2GB RAM allocation, but this is not supported.</p>
<h2 id="requirement-3---static-mac-address">Requirement 3 - Static MAC address</h2>
<p>The connector must have a static MAC address.</p>
<p>This is to do with the virtual hardware fingerprinting that ZPA does for connectors. MAC address is one element used to generate the unique fingerprint. If the MAC is changed at all, including on reboot, then the fingerprint will have been altered and the connector access to the ZPA cloud will be blocked for security reasons.</p>
<h2 id="requirement-4---internal-and-external-dns-resolution">Requirement 4 - Internal and External DNS Resolution</h2>
<p>The connector must be able to resolve both internal and external hostnames.</p>
<p>The connector should be deployed on the same LAN segment as the private applications it is providing access to.</p>
<h2 id="requirement-5---outbound-connectivity-on-port-443">Requirement 5 - Outbound connectivity on port 443</h2>
<p>The connector requires outbound access on port 443 in order to function. No inbound ports are required to be open.</p>
<p>For a complete list outbound firewall rules required, see <a href="https://ips.zscaler.net/zpa">https://ips.zscaler.net/zpa</a></p>
<h2 id="requirement-6---bypass-ssl-inspection">Requirement 6 - Bypass SSL Inspection</h2>
<p>You cannot do SSL inspection or decryption on any traffic coming from a connector. Only the Zscaler ZPA certificates are trusted. If the connector sees another certificate other than the ZPA one (due to how SSL inspection works), it will not pass traffic for security reasons.</p>
<p>You must bypass SSL inspection/decryption for connector traffic.</p>
<p>If you are using Zscaler Internet Access (ZIA), then the bypasses are automatically done for you.</p>
<h2 id="static-ips--dhcp">Static IPs &amp; DHCP</h2>
<p>Both static assignment of networking details and DHCP are supported connectors. Given that a connector is a key piece of networking infrastructure, static addressing is recommended.</p>
<h1 id="connector-deployment---vmware-vsphere-esxi">Connector Deployment - VMware vSphere (ESXi)</h1>
<p>For this guide, I&rsquo;ll be using the free vSphere Hypervisor (6.7).</p>
<ol>
<li>
<p>Download the connector OVA using the URL below:</p>
<p><a href="https://dist.private.zscaler.com/vms/VMware/2018.10/zpa-connector-2018.10.ova">https://dist.private.zscaler.com/vms/VMware/2018.10/zpa-connector-2018.10.ova</a></p>
<p>If you are using vCenter, then you should be able to simply paste in the URL to the OVF deployment tool.</p>
</li>
<li>
<p>Login to the vSphere UI. Select <strong>Virtual Machines</strong> from the side menu and select <strong>Create / Register VM</strong> at the top-left.</p>
</li>
<li>
<p>Select option 2 <strong>Deploy a virutal machine from an OVF or OVA file</strong>, then on the next screen give the VM a name (I called mine <code>Z-Connector-1</code> and <code>Z-Connector-2</code>), and click to upload the <code>ZPA_Connector.ova</code> file.</p>
</li>
</ol>
<p><img src="esx1.png" alt="7"></p>
<ol start="4">
<li>Select storage options, click <strong>Next</strong>, then select the network segement you wish to deploy the connector to. This should ideally be the same LAN segment that some of your applications are on.
For <strong>Disk Provisioning</strong>, leave it set to <strong>Thin</strong>.</li>
</ol>
<p><img src="esx3.png" alt="8"></p>
<ol start="5">
<li>Review your settings and click <strong>Finish</strong> to deploy the OVA.</li>
</ol>
<p>If you get an <code>Unsupported attribute 'initialBoot' on element 'InstallSection'</code> error when deploying, try again using one one of the OVAs below:</p>
<ul>
<li>If you are using vSphere:
<a href="https://dist.private.zscaler.com/vms/VMware/Latest/ZPA_Connector_Basic.ova">https://dist.private.zscaler.com/vms/VMware/Latest/ZPA_Connector_Basic.ova</a></li>
<li>If you are using vCenter
<a href="https://dist.private.zscaler.com/vms/VMware/Latest/ZPA_Connector_Basic.ova">https://dist.private.zscaler.com/vms/VMware/Latest/ZPA_Connector.ova</a></li>
</ul>
<p>If you are still hitting the error, try updating your ESXi client.</p>
<h1 id="connector-configuration--housekeeping">Connector Configuration &amp; Housekeeping</h1>
<p>Here we will login to the connector, change the default password, set network information (if not obtained via DHCP), and (optionally) enable SSH.</p>
<p>We will also manually update the connector from the command line. <strong>This is highly recommended the first time you deploy a connector.</strong></p>
<p>Some of these steps may only be required if you deployed the connector as a VM, and not as a package or in AWS/Azure.</p>
<p>It may take 15 minutes for the default <code>admin</code> user to be created. If login to the connector initially fails, wait some time and then try again.</p>
<h2 id="change-the-default-password">Change the default password</h2>
<ol>
<li>Log in to the connector using the <strong>username</strong> <code>admin</code> and <strong>default password</strong> <code>zscaler</code></li>
</ol>
<p><img src="cli1.png" alt="9"></p>
<ol start="2">
<li>
<p>Use the <code>passwd</code> command to change the current password for the <code>admin</code> user</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ passwd 
</span></span><span style="display:flex;"><span>Changing password <span style="color:#66d9ef">for</span> user admin. 
</span></span><span style="display:flex;"><span>Changing password <span style="color:#66d9ef">for</span> admin. 
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>current<span style="color:#f92672">)</span> UNIX password:
</span></span><span style="display:flex;"><span>New password:
</span></span><span style="display:flex;"><span>Retype new password:
</span></span><span style="display:flex;"><span>passwd: all authentication tokens updated successfully. 
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$
</span></span></code></pre></div></li>
<li>
<p>Log out of the connector when finished.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ logout
</span></span></code></pre></div></li>
</ol>
<h2 id="set-network-information">Set Network Information</h2>
<p>VM based connectors are set to use DHCP by default. Alternatively, to set static information:</p>
<ol>
<li>
<p>To set a static IP address, edit <code>/etc/sysconfig/network-scripts/ifcfg-eth0</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo nano /etc/sysconfig/network-scripts/ifcfg-eth0
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>DEVICE<span style="color:#f92672">=</span>eth0
</span></span><span style="display:flex;"><span>BOOTPROTO<span style="color:#f92672">=</span>none
</span></span><span style="display:flex;"><span>ONBOOT<span style="color:#f92672">=</span>yes
</span></span><span style="display:flex;"><span>NETWORK<span style="color:#f92672">=</span>10.0.10.0
</span></span><span style="display:flex;"><span>NETMASK<span style="color:#f92672">=</span>255.255.255.0
</span></span><span style="display:flex;"><span>IPADDR<span style="color:#f92672">=</span>10.0.10.16
</span></span><span style="display:flex;"><span>USERCTL<span style="color:#f92672">=</span>no
</span></span></code></pre></div></li>
<li>
<p>To set the default gateway, edit <code>/etc/sysconfig/network</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo nano /etc/sysconfig/network
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>NETWORKING<span style="color:#f92672">=</span>yes 
</span></span><span style="display:flex;"><span>GATEWAY<span style="color:#f92672">=</span>10.0.10.1
</span></span></code></pre></div></li>
<li>
<p>To set DNS (connectors must be able to resolve internal and external hostnames), edit <code>/etc/resolv.conf</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo nano /etc/resolv.conf
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>nameserver 10.0.10.2
</span></span><span style="display:flex;"><span>nameserver 10.0.10.22 
</span></span><span style="display:flex;"><span>search example.com
</span></span></code></pre></div></li>
<li>
<p>To set NTP servers, edit <code>/etc/chrony.conf</code>
These should ideally be internal NTP servers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo nano /etc/chrony.conf
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>server 0.zscaler.pool.ntp.org iburst
</span></span><span style="display:flex;"><span>server 1.zscaler.pool.ntp.org iburst
</span></span><span style="display:flex;"><span>server 2.zscaler.pool.ntp.org iburst
</span></span><span style="display:flex;"><span>server 3.zscaler.pool.ntp.org iburst
</span></span></code></pre></div></li>
<li>
<p>Restart the <code>network</code> and <code>chronyd</code> services for your changes to take effect.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl restart network
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl restart chronyd
</span></span></code></pre></div></li>
</ol>
<p>The Zscaler <a href="https://help.zscaler.com/zpa/connector-deployment-guide-vmware-platforms">documentation</a> has additonal information on how to:</p>
<ul>
<li>Configure additional network interfaces</li>
<li>Set static routes</li>
<li>Configure the connector and/or yum to use a Proxy Server.</li>
</ul>
<h2 id="enable-ssh-temporarily-or-permanently">Enable SSH (temporarily or permanently)</h2>
<p>To <strong>temporarily</strong> enable SSH:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl start sshd
</span></span></code></pre></div><p>This will persist until next reboot. You can use <code>stop</code> in place of <code>start</code> to disable SSH once you are done.</p>
<p>To <strong>permanently</strong> enable SSH, also run the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl enable sshd
</span></span></code></pre></div><h2 id="highly-recommended-manually-update-the-connector">[Highly Recommended] Manually Update the Connector</h2>
<p>Update the system packages:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo yum update -y
</span></span></code></pre></div><p>Reboot the connector (preferred) or restart the <code>zpa-connector</code> service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo reboot
</span></span><span style="display:flex;"><span>OR
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl restart zpa-connector
</span></span></code></pre></div><p>The Zscaler <a href="https://help.zscaler.com/zpa/managing-deployed-connectors#upgradingtheconnectorpackage">documentation</a> covers alternative scenarios, such as updating with a proxy server, or without access to the package repository.</p>
<h2 id="view-connector-logs">View Connector Logs</h2>
<p>Use <code>journalctl</code> to view the logs for the <code>zpa-connector</code> service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo journalctl -u zpa-connector
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>-------- Connector Status:ID<span style="color:#f92672">=</span>144133100000000000:Name<span style="color:#f92672">=</span>Homelab Key-1:Ver<span style="color:#f92672">=</span>19.65.2 --------
</span></span><span style="display:flex;"><span>Certificate will expire in <span style="color:#ae81ff">377</span> days, <span style="color:#ae81ff">23</span> hours, <span style="color:#ae81ff">47</span> minutes, <span style="color:#ae81ff">38</span> seconds
</span></span><span style="display:flex;"><span>Control connection state: fohh_connection_connected, local:<span style="color:#f92672">[</span>10.0.10.30<span style="color:#f92672">]</span>:53040 
</span></span><span style="display:flex;"><span>remote:broker1c.syd4.prod.zpath.net...2.196<span style="color:#f92672">]</span>:443
</span></span><span style="display:flex;"><span>RPC Messages: BrkRq <span style="color:#f92672">=</span> 0, BrkRqAck <span style="color:#f92672">=</span> 0|0, BindReq <span style="color:#f92672">=</span> 0|0, BindReqAck <span style="color:#f92672">=</span> 0, ...
</span></span><span style="display:flex;"><span>Broker data connection count <span style="color:#f92672">=</span> 0, backed_off connections <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>Data Transfer: Total ToBroker <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> bytes, Total FromBroker <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> bytes
</span></span><span style="display:flex;"><span>Mtunnels: Total Created <span style="color:#f92672">=</span> 0, Total Freed <span style="color:#f92672">=</span> 0, Current Active <span style="color:#f92672">=</span> 0, Alloc <span style="color:#f92672">=</span> 0, ...
</span></span><span style="display:flex;"><span>Registered apps count <span style="color:#f92672">=</span> 0, alive app <span style="color:#f92672">=</span> 0, passive_health <span style="color:#f92672">=</span> 0, service_count <span style="color:#f92672">=</span> 0, ...
</span></span><span style="display:flex;"><span>Time skew: + 0.000000s
</span></span><span style="display:flex;"><span>Control channel successfully connected to Zscaler Cloud
</span></span><span style="display:flex;"><span>Connector- waiting <span style="color:#66d9ef">for</span> time synchronization
</span></span><span style="display:flex;"><span>Connector- Time synchronized, Local time - 737.427447s <span style="color:#f92672">=</span> cloud_time
</span></span><span style="display:flex;"><span>zscaler-update: Zscaler software update: Currently installed version verified as 19.65.2
</span></span></code></pre></div><p>This can also be dumped to a file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo journalctl -u zpa-connector &gt; zpa-logs.txt
</span></span></code></pre></div><h2 id="start-stop-or-restart-the-connector-service">Start, Stop, or Restart the Connector Service</h2>
<p>The ZPA connector runs as a service called <code>zpa-connector and can be controlled via </code>systemctl`:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl start zpa-connector
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl stop zpa-connector
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl restart zpa-connector
</span></span></code></pre></div><p>You can also check the status of the connector service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl status zpa-connector
</span></span></code></pre></div><h1 id="enrolling-the-connector">Enrolling the Connector</h1>
<p>In this section we will provide the connector with the Provisioning Key (PK) and complete its enrollment. After this step, you will see the connector listed in the admin portal.</p>
<p>You must stop the <code>zpa-connector</code> service first. If the connector does not detect the PK after it boots, it will only check for it again once every 24 hours.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl stop zpa-connector
</span></span></code></pre></div><p>Create a file <code>/opt/zscaler/var/provision_key</code> with permissions <code>644</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo touch /opt/zscaler/var/provision_key
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo chmod <span style="color:#ae81ff">644</span> /opt/zscaler/var/provision_key
</span></span></code></pre></div><p>Copy the PK into the <code>provision_key</code> file. Make sure you encase it in double quotes <code>&quot; &quot;</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo echo <span style="color:#e6db74">&#34;&lt;Your-Provisioning-Key&gt;&#34;</span> | sudo tee /opt/zscaler/var/provision_key
</span></span></code></pre></div><p>Note: <strong>Beware of the type of double quotation marks you use</strong> when you paste in the provisioning key! If you&rsquo;re copying and pasting into a console window, this can be auto-corrected to a left or right quotation mark (Unicode <code>U+201C</code> and <code>U+201D</code>) instead of the standard neutral double quotes (Unicode <code>U+0022</code>). If this happens the command will fail and the provisioning key will be incorrect.</p>
<p>You might be better off manually typing <code>sudo echo &quot;</code>, pasting the provisioning key, manually typing the closing quote mark, then pasting the remaining part of the command <code> | sudo tee /opt/zscaler/var/provision_key</code>.</p>
<p>Check the key is correct:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo cat /opt/zscaler/var/provision_key
</span></span></code></pre></div><p>Start the <code>zpa-connector</code> service again:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@zpa-connector ~<span style="color:#f92672">]</span>$ sudo systemctl start zpa-connector
</span></span></code></pre></div><p>Check the logs (see above) to verify enrollment progress.</p>
<h1 id="verifying-connector-status-and-health">Verifying Connector Status and Health</h1>
<p>If the connector has been enrolled successfully, you&rsquo;ll now see it present in the list of connectors under <strong>Administration</strong> &gt; <strong>Connectors</strong>.</p>
<p><img src="zc7.png" alt="10"></p>
<p>Don&rsquo;t worry if some of the fields have not populated yet.</p>
<p>You can check the health of the connector under the <strong>Dashboard</strong> &gt; <strong>Health</strong> tab.</p>
<p><img src="zc8.png" alt="11"></p>
<p>This tab will only show healthy connectors by default.</p>
<h1 id="next-steps-1">Next Steps</h1>
<p>Congratulations! You&rsquo;ve deployed your first ZPA connector!
Now go and repeat the same process for a second one so they are deployed in a pair.</p>
<p>In the next guide we&rsquo;ll define some Applications in the admin portal and get them working with the connector(s).</p>
]]></content>
        </item>
        
        <item>
            <title>Integrate Zscaler ZPA with Azure AD</title>
            <link>https://nathancatania.com/posts/configuring-zscaler-zpa-to-use-azure-ad/</link>
            <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/configuring-zscaler-zpa-to-use-azure-ad/</guid>
            <description>This guide will cover configuring Azure AD as the Identity Provider (IdP) for ZPA. Our users defined in Azure AD will be able to authenticate with Z-App/ZPA using Microsoft Single Sign-on (SSO), and we&amp;rsquo;ll also be able to create access policies for our private applications based on user identity and attributes.
If you followed my previous post covering ZIA integration with Azure AD, then the first few steps will be (mostly) the same.</description>
            <content type="html"><![CDATA[<p>This guide will cover configuring Azure AD as the Identity Provider (IdP) for ZPA. Our users defined in Azure AD will be able to authenticate with Z-App/ZPA using Microsoft Single Sign-on (SSO), and we&rsquo;ll also be able to create access policies for our private applications based on user identity and attributes.</p>
<p>If you followed my previous post covering ZIA integration with Azure AD, then the first few steps will be (mostly) the same.</p>
<h1 id="add-a-new-identity-provider-in-zpa">Add a New Identity Provider in ZPA</h1>
<p>Log into the <a href="https://admin.private.zscaler.com">ZPA admin portal</a> and go to <strong>Administration</strong> &gt; <strong>IdP Configuration</strong>.</p>
<p><img src="1.png" alt="1"></p>
<p>Click <strong>Add IdP Configuration</strong> at the top-right of the screen.</p>
<p><img src="2.png" alt="2"></p>
<p>Under the <strong>IdP Information</strong> section:</p>
<ol>
<li>Enter a name for the IdP configuration.
ZPA supports multipe IdPs, hence a name is required to differentiate them.</li>
<li>Ensure <strong>User</strong> is selected for <strong>Single Sign-On</strong>.</li>
<li>Select the domain(s) you wish to associate with the IdP configuration.
Zscaler support must add any additional domains to your admin portal first before you can use them.</li>
</ol>
<p><img src="3.png" alt="3"></p>
<p>Click <strong>Next</strong> to continue.</p>
<p>The next tab shows info you&rsquo;ll for the configuration on the Azure AD side. <strong>Download the Service Provider Metadata file</strong> (this will download as a file called <strong>sp_metadata.xml</strong>) as we&rsquo;ll use this in the next section.</p>
<p><img src="4.png" alt="4"></p>
<p>Click <strong>Pause</strong> (this will suspend the IdP config temporarily) and continue to the next section.</p>
<h1 id="add-zpa-as-an-enterprise-application-in-azure-ad">Add ZPA as an Enterprise Application in Azure AD</h1>
<p>From the <a href="https://portal.azure.com">Azure Portal</a>, open the side hamburger menu and click <strong>Azure Active Directory</strong>. You can also search for it using the search bar at the top.</p>
<p><img src="6.png" alt="6"></p>
<p>Under <strong>Manage</strong> in the side menu, click <strong>Enterprise applications</strong>.</p>
<p><img src="7.png" alt="7"></p>
<p>Next, under the <strong>All Applications</strong> menu, click <strong>New Application</strong>.</p>
<p><img src="8.png" alt="8"></p>
<p>In the search box to add a new application, type &ldquo;<strong>Zscaler</strong>&rdquo;.</p>
<p><img src="9.png" alt="9"></p>
<p>Select the <strong>Zscaler Private Access (ZPA)</strong> application and click <strong>Create</strong> (or <strong>Add</strong> depending on whether you are using the old or new enterprise app gallery).</p>
<h1 id="configure-the-zpa-enterprise-application">Configure the ZPA Enterprise Application</h1>
<p>You will now be on the administration page for the ZPA enterprise application you added above (if not, you can get to this page via: Azure Active Directory &gt; Enterprise Applications &gt; All Applications, then click on the ZPA app you added above).</p>
<h2 id="1---configure-saml-based-single-sign-on">1 - Configure SAML-based Single Sign-on</h2>
<p>Under <strong>Manage</strong> in the side menu, click <strong>Single sign-on</strong>, and select <strong>SAML</strong> when prompted. This will place you on the SAML configuration page.</p>
<p><img src="10.png" alt="10"></p>
<p><img src="11.png" alt="11"></p>
<h2 id="2---import-the-zscaler-sp-metadata-file">2 - Import the Zscaler SP Metadata File</h2>
<p>Click <strong>Upload metadata file</strong> at the top, and select the <strong>sp_metadata.xml</strong> file you downloaded from the ZPA admin portal earlier. This will open a panel and pre-populate some of the required info.</p>
<p><img src="12.png" alt="12"></p>
<p>The Sign on URL field will be empty and is required. Copy the example URL, replacing the <code>EXAMPLE</code> at the end with your domain that is being associated with this Azure AD config.</p>
<p>For example, for my domain of <code>oblivion.industries</code>, my Sign on URL would look like:</p>
<pre tabindex="0"><code>https://samlsp.private.zscaler.com/auth/login?domain=oblivion.industries
</code></pre><p><img src="13.png" alt="13"></p>
<p>The Relay State and Logout Url fields should be left blank.</p>
<p>Click <strong>Save</strong> at the top when you are done, and X to close the panel.</p>
<h2 id="3---create-a-saml-signing-certificate">3 - Create a SAML Signing Certificate</h2>
<p>Next to the 3rd step, <strong>SAML Signing Certificate</strong> in the SAML configuration page, click the edit/pencil icon.</p>
<p><img src="14.png" alt="14"></p>
<p>In the panel that appears, make sure the <strong>Signing Algorithm</strong> is <strong>SHA-256</strong> and <strong>Signing Option</strong> is set to <strong>Sign SAML assertion</strong>.</p>
<p>Click <strong>New Certificate</strong> then <strong>Save</strong>. Open the menu by clicking the three dots to the right of the certificate, and download the BOTH the <strong>Base64</strong> certificate and the <strong>Federated Certificate XML</strong>. You should only need the latter, but it can sometimes be helpful to have both.</p>
<p><img src="15.png" alt="15"></p>
<p>Close the panel by clicking X once you&rsquo;ve downloaded the certificate and metadata files.</p>
<h1 id="assign-users--groups-to-the-enterprise-application">Assign Users &amp; Groups to the Enterprise Application</h1>
<p>We now need to assign what users are authorized to use the ZPA Enterprise Application. Only the users or groups specified will be able to sign into ZPA via Microsoft SSO. If you skip this section, your user&rsquo;s won&rsquo;t be able to sign in, and you won&rsquo;t see user data populated in ZIA for you to configure policy around.</p>
<p>Select <strong>Users and groups</strong> from the side menu of the enterprise application, then click <strong>Add user</strong>.</p>
<p><img src="16.png" alt="16"></p>
<p>Select the Users and Groups to be both synced with and provisoned access to ZPA. If you select a group, all members of that group will receive ZPA access.</p>
<p><img src="17.png" alt="17"></p>
<p>When you are finished, click <strong>Assign</strong>.</p>
<h1 id="finish-configuring-the-idp-in-zpa">Finish Configuring the IdP in ZPA</h1>
<p>Return to the ZPA admin portal and click the <strong>resume</strong> button next to the paused IdP configuration (Administration &gt; IdP Configuration).</p>
<p><img src="18.png" alt="18"></p>
<p>For the <strong>IdP Metadata File</strong>, click to <strong>upload the Federated Certificate XML</strong> you download from Azure AD above. <em><strong>This will automatically populate all settings for you; including the certificate.</strong></em></p>
<p>If for some reason the certificate does not populate, you can upload the Base64 certificate you downloaded.</p>
<p><img src="19.png" alt="19"></p>
<p>Scroll to the bottom of the window and change <strong>SCIM Sync</strong> to <strong>Enabled</strong>.</p>
<p>Note down the <strong>SCIM Service Provider Endpoint</strong> URL, and generate a new <strong>Bearer Token</strong>. Note down the Bearer Token as well. You will need both of these in the next step.</p>
<p><img src="20.png" alt="20"></p>
<p>Click <strong>Save</strong> to finish the configuration on the ZPA side. Unlike ZIA, you do not need to activate your changes for them to take effect.</p>
<h1 id="configure-scim-provisioning-in-azure-ad">Configure SCIM Provisioning in Azure AD</h1>
<p>So far we&rsquo;ve configured a way to authenticate our users, but we still need to configure a method to provision &amp; de-provision them in the ZPA database.</p>
<p>You can learn more about SCIM Provisioning <a href="https://help.zscaler.com/zpa/about-scim">here</a>, but in short, it involves the IdP regularly syncing user information with Zscaler via an API. With Azure AD, this sync happens every 40 minutes. Using SCIM is best practice.</p>
<h2 id="1---configure-scim-provisionig-in-azure-ad">1 - Configure SCIM Provisionig in Azure AD</h2>
<p>Return to the ZPA Enterprise Application in Azure AD. This time select <strong>Provisioning</strong> from the side menu and select <strong>Get Started</strong> if prompted.</p>
<p><img src="21.png" alt="21"></p>
<p>Change the <strong>Provisioning Mode</strong> to <strong>Automatic</strong>, and fill in the following fields:</p>
<ul>
<li>For <strong>Tenant URL</strong>, copy and paste the <strong>Base URL</strong> from above.</li>
<li>For <strong>Secret Token</strong>, copy and paste the <strong>Bearer Token</strong> from above.</li>
</ul>
<p>Click <strong>Test Connection</strong> to verify. If you recieve an error about &ldquo;invalid credentials&rdquo;, make sure you saved and activated your change in the step above.</p>
<p><img src="22.png" alt="22"></p>
<p>Click <strong>Save</strong> to continue.</p>
<p>Once your changes have been saved, change <strong>Provisioning Status</strong> to <strong>On</strong>.</p>
<p>Save your changes again and the Scope field should appear.</p>
<p>If you recieve an error, or the scope field is not appearing:</p>
<ul>
<li>Back out of the Provisioning menu and go into it again. This should fix the error and cause the scope menu to appear.</li>
<li>Ensure you have assigned users and/or groups (containing users) to the enterprise application first.</li>
</ul>
<p>For the <strong>Scope</strong>:</p>
<table>
<thead>
<tr>
<th>Scope</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sync only assigned users and groups</strong></td>
<td>Only users and groups explicitly assigned access to this enterprise application (under Users and groups in the side menu) will be provisioned via SCIM to ZPA.</td>
</tr>
<tr>
<td><strong>Sync all users and groups</strong></td>
<td>All users and groups defined in Azure AD are synced with ZPA; irrespective of what was defined under Users and Groups in the side menu.</td>
</tr>
</tbody>
</table>
<p>Set your scope accordingly and click <strong>Save</strong> again. Don&rsquo;t forget to do this or your user information will not sync with ZPA!</p>
<h2 id="3---synchronize">3 - Synchronize</h2>
<p>Your users will sync to ZPA on the next API cycle (every 40 minutes). As this is the first time, you can manually force a sync by clicking the option <strong>Clear current state and restart synchronization</strong> (and then <strong>Save</strong>).</p>
<h2 id="4---verify">4 - Verify</h2>
<p>Once your users and groups have synchronised with ZPA, they&rsquo;ll be visible in the ZPA admin portal under <strong>Administration &gt; SCIM Users</strong> and <strong>Administration &gt; SCIM Groups</strong>.</p>
<p><img src="23.png" alt="23"></p>
<h1 id="import-saml-attributes">Import SAML Attributes</h1>
<p>In order to create policies in ZPA, we need to import the fields we can use (called SAML attributes) from the IdP. This also allows us to test whether user authentication is working correctly.</p>
<blockquote>
<p><strong>IMPORTANT:</strong> I strongly recommend do the next step in an Incognito or Private tab. Failing that, completely sign out of both Azure AD and any Microsoft accounts you are currently signed in as in your current browser session.</p>
<p>The next step will redirect you to Microsoft SSO to sign in with one of our test users, but if an active session to another Microsoft account is detected, it will use that instead. Importing the SAML attributes will then fail, as this account is likely not associated with our Azure AD tenant.</p>
</blockquote>
<p>In the ZPA admin portal, go to <strong>Administration</strong> &gt; <strong>IdP Configuration</strong> and expand the IdP configuration you want to import the attributes from. Under <strong>Import SAML Attributes</strong>, select the domain associated with the IdP you want to import the attributes from and click <strong>Import</strong>.</p>
<p><img src="24.png" alt="24"></p>
<p>Sign in using the credentials of a user that is authorized to use ZPA (ie: a user associated with the ZPA enterprise application). This will test your SSO config so far:</p>
<ul>
<li>If you encounter a Microsoft error (and you&rsquo;re trying this in an incognito or private tab), this indicates an issue with the Microsoft side of the config. Check to see whether the user you are attempting to sign in as has been added to the enterprise application as an authorized user. Additionally, check that your SAML config is correct.</li>
<li>If you encounter a Zscaler branded error, this indicates an issue with the config on the Zscaler side. Note down the error code in the bottom left and check it against a <a href="https://help.zscaler.com/zia/troubleshooting-saml">list of error codes here</a>.</li>
</ul>
<p>If you have a successful login, the SAML JSON response will be captured and used to discover available SAML attributes to import:</p>
<p><img src="25.png" alt="25"></p>
<p>Anything in the left column, <strong>Name</strong>, you should overwrite with a descriptive name. <strong>What you type here will appear when creating an access policy</strong>, so <code>Full Name</code> is a lot easier to understand than <code>...claims_displayname_Azure AD</code> is.</p>
<p>NB: If you have multiple IdPs configured, the name given to the attribute must be unique amongst all of them or it will not import.</p>
<p>Some important mappings you might want to be aware of:</p>
<table>
<thead>
<tr>
<th>SAML Attribute Name</th>
<th>What you should call it</th>
</tr>
</thead>
<tbody>
<tr>
<td>displayname</td>
<td>Full Name</td>
</tr>
<tr>
<td>groups</td>
<td>Group or memberOf</td>
</tr>
<tr>
<td>givenname</td>
<td>First Name</td>
</tr>
<tr>
<td>name</td>
<td>Username (eg: <a href="mailto:user@example.com">user@example.com</a>)</td>
</tr>
<tr>
<td>surname</td>
<td>Surname</td>
</tr>
<tr>
<td>emailaddress</td>
<td>Email Address</td>
</tr>
</tbody>
</table>
<p>You can also use the JSON displayed at the bottom of the page to work out what things should be called based on the captured data.</p>
<p>Note: Only SAML attributes that have not been imported are displayed in the table. If the table is blank or some fields are missing, check you haven&rsquo;t already imported the attribute you&rsquo;re after.</p>
<p>When you are done, click <strong>Save</strong> to finish the import.</p>
<p>You will now be able to create an Access Policy using any of the imported SAML attributes:</p>
<p><img src="26.png" alt="26"></p>
<h1 id="configure-service-entitlement">Configure Service Entitlement</h1>
<p>You now need to explicitly turn on ZPA in the Zscaler App, otherwise ZIA will be the only product to appear when a user signs in. This is called Selective Entitlement and is a way companies can specifically enable ZPA for some employees (eg: remote workers), but not all of them.</p>
<p>In the ZPA admin portal, click the link in the menu to go to the <strong>Zscaler App Portal</strong>.</p>
<p><img src="27.png" alt="27"></p>
<p>Once in the Zscaler App Portal go to <strong>Administration &gt; Zscaler Service Entitlement</strong>.</p>
<p><img src="28.png" alt="28"></p>
<p>IMPORTANT: If you have a brand new ZPA portal, you will not see the option for <strong>Zscaler Service Entitlement</strong> in the Zscaler App Portal. You need to <a href="https://help.zscaler.com/submit-ticket">raise a ticket with support</a> to have this enabled, and can use the following script:</p>
<blockquote>
<p>Hi team. IdP is now configured in ZPA. Please enable ZPA in the Zscaler App Portal at your earliest convenience. Thank you.</p>
</blockquote>
<p><img src="29.png" alt="29"></p>
<p>You can choose to enable ZPA in the Zscaler App globally for all users, or only allow access to specific groups.</p>
<p>IMPORTANT: Group membership is synced from ZIA. If you&rsquo;ve changed group membership or created a new group in Azure AD, you must wait for it to sync to ZIA with SCIM AND wait for it to sync from ZIA to the Zscaler App portal (you can also initate a manual pull from ZIA under Administration &gt; Zscaler App Support &gt; Advanced Configuration)</p>
<p>Select whether to enable ZPA for all users (check the <strong>ZPA Enabled by Default</strong> option), or select users by specifying a group.</p>
<p>Click <strong>Save</strong> when you are finished and return to the ZPA admin portal.</p>
<h1 id="test-the-azure-ad-configuration">Test the Azure AD configuration</h1>
<p>We&rsquo;re going to test everything that we&rsquo;ve done so far. Open Z-App (sign-out if you&rsquo;re already signed in with another user) and sign in with the credentials of one of your Azure AD users that you assigned to the ZPA Enterprise Application.</p>
<p>When you enter the username, Z-App should now redirect you to sign-in with Microsoft. Enter valid user credentials and test the sign-in.</p>
<p><img src="30.png" alt="1"></p>
<p>If everything is working well, and you&rsquo;ve enabled ZPA in the Zscaler App (Zscaler Service Entitlement), the user will be signed in to both ZIA and ZPA (provided Azure AD has been used for the IdP for both). Z-App will minimize itself to your system tray or menu-bar. If you open it, you&rsquo;ll see your user is authenticated.</p>
<p><img src="24.png" alt="24"></p>
<h2 id="testing-sso-in-a-browser">Testing SSO in a Browser</h2>
<p>You can test the IdP configuration outside of the ZPA admin portal using the following URL. Replace <code>EXAMPLE.COM</code> with your company’s domain name as per Azure AD.</p>
<p>IMPORTANT: Test the URL in a Private/Incognito window.</p>
<pre tabindex="0"><code>https://samlsp.private.zscaler.com/auth/v2/login?ssotype=test&amp;domain=EXAMPLE.COM
</code></pre><h2 id="troubleshooting-sign-in">Troubleshooting Sign-in</h2>
<p>If the Microsoft SSO fails, check the config on the Azure AD side. This could be due to:</p>
<ul>
<li>The URLs in the SAML config are not correct.</li>
<li>Your user has not been assigned to the enterprise application.</li>
</ul>
<p>If sign in passes Microsoft SSO, but you get a Zscaler error (as per the image below), check the error code in the bottom right corner against the <a href="https://help.zscaler.com/zia/troubleshooting-saml">list of error codes here</a>. This indicates an issue with the config on the Zscaler side (typically something to do with the certificate you imported from Azure AD).</p>
<p><img src="25.png" alt="25"></p>
<h1 id="finish">Finish</h1>
<p>If all went well, you should now have your ZPA tenant integrated with Azure AD with SAML-based SSO and SCIM user provisioning.</p>
]]></content>
        </item>
        
        <item>
            <title>Integrate Zscaler ZIA with Azure AD</title>
            <link>https://nathancatania.com/posts/configuring-zscaler-zia-to-use-azure-ad/</link>
            <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/configuring-zscaler-zia-to-use-azure-ad/</guid>
            <description>This guide will cover configuring Azure AD as the Identity Provider (IdP) for ZIA. Our users defined in Azure AD will be able to authenticate with Z-App/ZIA using Microsoft Single Sign-on (SSO), and we&amp;rsquo;ll also be able to start creating policies in ZIA centered around the same users, groups, and departments we&amp;rsquo;ve defined.
By integrating with an IdP like Azure AD, we no longer need to manually manage users and their credentials ourselves in the ZIA portal.</description>
            <content type="html"><![CDATA[<p>This guide will cover configuring Azure AD as the Identity Provider (IdP) for ZIA. Our users defined in Azure AD will be able to authenticate with Z-App/ZIA using Microsoft Single Sign-on (SSO), and we&rsquo;ll also be able to start creating policies in ZIA centered around the same users, groups, and departments we&rsquo;ve defined.</p>
<p>By integrating with an IdP like Azure AD, we no longer need to manually manage users and their credentials ourselves in the ZIA portal. We are effectively outsourcing user management and authentication to a 3rd party: Azure AD.</p>
<p>From a user perspective, when they enter their username into Z-App, they&rsquo;ll be redirected to sign in using their company credentials via Microsoft:</p>
<p><img src="1.png" alt="1"></p>
<h1 id="add-a-new-identity-provider-in-zia">Add a New Identity Provider in ZIA</h1>
<p>Log into your ZIA admin portal and go to <strong>Administration &gt; Authentication Settings.</strong></p>
<p><img src="2.png" alt="2"></p>
<p>Change the <strong>Authentication Type</strong> to <strong>SAML</strong> (from Form-Based) and then click the link <strong>Open Identity Providers</strong> (or click the Identity Providers tab at the top).</p>
<p><img src="3.png" alt="3"></p>
<p>Under the <strong>Identity Providers</strong> tab, click <strong>Add Identity Provider</strong>.</p>
<p><img src="4.png" alt="3"></p>
<p>In the window that appears, don&rsquo;t fill anything in yet. Click to download the <strong>SP Metadata</strong> towards the bottom of the window. This will download a file called <strong>zscaler-metadata.xml</strong> that we&rsquo;ll use in the next section.</p>
<p><img src="5.png" alt="5"></p>
<h1 id="add-zia-as-an-enterprise-application-in-azure-ad">Add ZIA as an Enterprise Application in Azure AD</h1>
<p>From the <a href="https://portal.azure.com">Azure Portal</a>, open the side hamburger menu and click <strong>Azure Active Directory</strong>. You can also search for it using the search bar at the top.</p>
<p><img src="6.png" alt="6"></p>
<p>Under <strong>Manage</strong> in the side menu, click <strong>Enterprise applications</strong>.</p>
<p><img src="7.png" alt="7"></p>
<p>Next, under the <strong>All Applications</strong> menu, click <strong>New Application</strong>.</p>
<p><img src="8.png" alt="8"></p>
<p>In the search box to add a new application, type &ldquo;<strong>Zscaler</strong>&rdquo;.</p>
<p><img src="9.png" alt="9"></p>
<p>Select the Zscaler application that corresponds to cloud your ZIA tenant was provisioned on. If you can&rsquo;t remember this, check the URL that you use to log into the admin portal with. For example:</p>
<ul>
<li><code>admin.zscalertwo.net</code> == <strong>Zscaler Two</strong></li>
<li><code>admin.zscaler.net</code> == <strong>Zscaler</strong></li>
<li><code>admin.zscloud.net</code> == <strong>Zscaler ZSCloud</strong></li>
</ul>
<p>Select the correct application and click <strong>Create</strong> (or <strong>Add</strong> depending on whether you are using the old or new enterprise app gallery).</p>
<h1 id="configure-the-zia-enterprise-application">Configure the ZIA Enterprise Application</h1>
<p>You will now be on the administration page for the Zscaler / ZIA enterprise application you added above (if not, you can get to this page via: Azure Active Directory &gt; Enterprise Applications &gt; All Applications, then click on the ZIA app you added above).</p>
<h2 id="1---configure-saml-based-single-sign-on">1 - Configure SAML-based Single Sign-on</h2>
<p>Under <strong>Manage</strong> in the side menu, click <strong>Single sign-on</strong>, and select <strong>SAML</strong> when prompted. This will place you on the SAML configuration page.</p>
<p><img src="10.png" alt="10"></p>
<p><img src="11.png" alt="11"></p>
<h2 id="2---import-the-zscaler-sp-metadata-file">2 - Import the Zscaler SP Metadata File</h2>
<p>Click <strong>Upload metadata file</strong> at the top, and select the <strong>zscaler-metadata.xml</strong> file you downloaded from the ZIA admin portal earlier. This will open a panel and pre-populate some of the required info.</p>
<p><img src="12.png" alt="12"></p>
<p>The Sign on URL field will be empty and is required. This is the same as the pre-populated Reply URL field, so <strong>copy and paste the URL from <em>Reply URL</em> to <em>Sign on URL</em></strong>. This is of the format:</p>
<pre tabindex="0"><code>https://login.&lt;cloudname&gt;.net:443/sfc_sso
</code></pre><p>Leave the <strong>Reply State</strong> and <strong>Logout Url</strong> fields blank.</p>
<p><img src="13.png" alt="13"></p>
<p>When you&rsquo;re done, click <strong>Save</strong> at the top, then X to close the panel.</p>
<h2 id="3---create-a-saml-signing-certificate">3 - Create a SAML Signing Certificate</h2>
<p>Next to the 3rd step, <strong>SAML Signing Certificate</strong> in the SAML configuration page, click the edit/pencil icon.</p>
<p><img src="14.png" alt="14"></p>
<p>In the panel that appears, make sure the <strong>Signing Algorithm</strong> is <strong>SHA-256</strong> and <strong>Signing Option</strong> is set to <strong>Sign SAML assertion</strong>.</p>
<p>Click <strong>New Certificate</strong> then <strong>Save</strong>. Open the menu by clicking the three dots to the right of the certificate, and download the <strong>Base64</strong> certificate.</p>
<p><img src="15.png" alt="15"></p>
<p><strong>IMPORTANT:</strong> The certificate will download as a .cer file. You must change the file extension to <strong>.pem</strong> or it will not be able to be used later on. DO NOT just download the certificate in .pem format as this will cause user authentication to fail. <strong>The certificate downloaded must be the Base64 certificate in .cer format, renamed to .pem.</strong></p>
<p>Close the panel by clicking X once you&rsquo;ve downloaded the certificate.</p>
<h2 id="4---note-down-the-login-url">4 - Note down the Login URL</h2>
<p>Expand the <strong>Configuration URLs</strong> under the <strong>5th step</strong> in the SAML configuration page, and note down/copy the <strong>Login URL</strong>: we&rsquo;ll need this later. The Login URL should be of the format:</p>
<pre tabindex="0"><code>https://login.microsoftonline.com/&lt;unique-token&gt;/saml2
</code></pre><p><img src="16.png" alt="16"></p>
<h1 id="assign-users--groups-to-the-enterprise-application">Assign Users &amp; Groups to the Enterprise Application</h1>
<p>We now need to assign what users are authorized to use the ZIA Enterprise Application. Only the users or groups specified will be able to sign into ZIA via Microsoft SSO. If you skip this section, your user&rsquo;s won&rsquo;t be able to sign in, and you won&rsquo;t see user data populated in ZIA for you to configure policy around.</p>
<p>Select <strong>Users and groups</strong> from the side menu of the enterprise application, then click <strong>Add user</strong>.</p>
<p><img src="17.png" alt="17"></p>
<p>Select the Users and Groups to be both synced with and provisoned access to ZIA. If you select a group, all members of that group will receive ZIA access.</p>
<p><img src="18.png" alt="18"></p>
<p>When you are finished, click <strong>Assign</strong>.</p>
<h1 id="finish-configuring-the-idp-in-zia">Finish Configuring the IdP in ZIA</h1>
<p>Return to the ZIA admin portal and finish configuring the new IdP. Fill in the details as follows:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Name</td>
<td>Enter a descriptive name for the IdP</td>
</tr>
<tr>
<td>Status</td>
<td><strong>Enabled</strong></td>
</tr>
<tr>
<td>SAML Portal URL</td>
<td>Enter the <strong>Login URL</strong> you copied from the SAML configuration page (Step 5 - Set up Zscaler). This is in the format: <code>https://login.microsoftonline.com/&lt;uniquetoken&gt;/saml2</code></td>
</tr>
<tr>
<td>Login Name Attribute</td>
<td>Set this to <code>NameID</code></td>
</tr>
<tr>
<td>Org-Specific Entity ID</td>
<td><strong>Disabled</strong></td>
</tr>
<tr>
<td>Public SSL Certificate</td>
<td>Upload the <strong>Base64 certificate</strong> you downloaded above. It MUST be in .pem format. If it was downloaded as a .cer file, simply <strong>change the extension to .pem</strong></td>
</tr>
<tr>
<td>Vendor</td>
<td><strong>Azure Active Directory</strong></td>
</tr>
<tr>
<td>Authentication Domains</td>
<td>Leave this as Any or select a domain to associate this IdP with. Users signing in with this domain will be redirected to this IdP.</td>
</tr>
<tr>
<td>Sign SAML Request</td>
<td><strong>Disabled</strong> - Azure AD does not support signed SAML responses from the service provider.</td>
</tr>
</tbody>
</table>
<p><img src="19.png" alt="19"></p>
<p>Don&rsquo;t touch any of the options under the <strong>Auto-Provisioning</strong> section just yet.</p>
<p>Click <strong>Save</strong> to save the IdP config and close the window.</p>
<h1 id="configure-scim-user-provisioning">Configure SCIM User Provisioning</h1>
<p>So far we&rsquo;ve configured a way to authenticate our users, but we still need to configure a method to provision them in ZIA so we can create policies that utilize user identities; like URL filtering and DLP.</p>
<p>You can learn more about SCIM Provisioning <a href="https://help.zscaler.com/zia/about-scim">here</a>, but in short, it involves the IdP regularly syncing user information with Zscaler via an API. With Azure AD, this sync happens every 40 minutes. Using SCIM is best practice.</p>
<h2 id="1---edit-identity-provider-settings">1 - Edit Identity Provider Settings</h2>
<p>In the ZIA admin portal, click the edit/pencil icon next to the Azure AD IdP we just added (Administration &gt; Authentication Settings &gt; Identity Providers tab).</p>
<p>This time, under the <strong>Auto-Provisioning Options</strong> section, check the <strong>Enable SCIM-Based Provisioning</strong> checkbox (do NOT enable SAML Auto-Provisioning).</p>
<p><img src="20.png" alt="20"></p>
<p>Note down both the <strong>Base URL</strong> and <strong>Bearer Token</strong> displayed. The Bearer Token is essentially an API key we will give to Azure AD. Clicking Generate Token will invalidate the previous token and display a new one.</p>
<p>Click <strong>Save</strong> when you are done and <strong>ACTIVATE</strong> your changes! <strong>Make sure you do this, or your Bearer Token will not work in the steps below.</strong></p>
<h2 id="2---configure-scim-provisionig-in-azure-ad">2 - Configure SCIM Provisionig in Azure AD</h2>
<p>Return to the ZIA Enterprise Application in Azure AD. This time select <strong>Provisioning</strong> from the side menu and select <strong>Get Started</strong> if prompted.</p>
<p><img src="21.png" alt="21"></p>
<p>Change the <strong>Provisioning Mode</strong> to <strong>Automatic</strong>, and fill in the following fields:</p>
<ul>
<li>For <strong>Tenant URL</strong>, copy and paste the <strong>Base URL</strong> from above.</li>
<li>For <strong>Secret Token</strong>, copy and paste the <strong>Bearer Token</strong> from above.</li>
</ul>
<p>Click <strong>Test Connection</strong> to verify. If you recieve an error about &ldquo;invalid credentials&rdquo;, make sure you saved and activated your change in the step above.</p>
<p><img src="22.png" alt="22"></p>
<p>Click <strong>Save</strong> to continue.</p>
<p>Once your changes have been saved, change <strong>Provisioning Status</strong> to <strong>On</strong>.</p>
<p>Save your changes again and the Scope field should appear.</p>
<p>If you recieve an error, or the scope field is not appearing:</p>
<ul>
<li>Back out of the Provisioning menu and go into it again. This should fix the error and cause the scope menu to appear.</li>
<li>Ensure you have assigned users and/or groups (containing users) to the enterprise application first.</li>
</ul>
<p>For the <strong>Scope</strong>:</p>
<table>
<thead>
<tr>
<th>Scope</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Sync only assigned users and groups</strong></td>
<td>Only users and groups explicitly assigned access to this enterprise application (under Users and groups in the side menu) will be provisioned via SCIM to ZIA. Note that if you don&rsquo;t select a group and your scope is set to this option, that group will not appear in ZIA when creating policies.</td>
</tr>
<tr>
<td><strong>Sync all users and groups</strong></td>
<td>All users and groups defined in Azure AD are synced with ZIA; irrespective of what was defined under Users and Groups in the side menu.</td>
</tr>
</tbody>
</table>
<p>Set your scope accordingly and click <strong>Save</strong> again. Don&rsquo;t forget to do this or your user information will not sync with ZIA!</p>
<h2 id="3---synchronize">3 - Synchronize</h2>
<p>Your users and groups will sync to ZIA on the next API cycle (every 40 minutes). As this is the first time, you can manually force a sync by clicking the option <strong>Clear current state and restart synchronization</strong> (and then <strong>Save</strong>).</p>
<h2 id="4---verify">4 - Verify</h2>
<p>Once your users and groups have synchronised with ZIA, they&rsquo;ll be visible in the ZIA admin portal under <strong>Administration &gt; User Management</strong>.</p>
<p><img src="23.png" alt="23"></p>
<h1 id="test-the-azure-ad-configuration">Test the Azure AD configuration</h1>
<p>We&rsquo;re going to test everything that we&rsquo;ve done. Open Z-App (sign-out if you&rsquo;re already signed in with another user) and sign in with the credentials of one of your Azure AD users that you assigned to the ZIA Enterprise Application.</p>
<p>When you enter the username, Z-App should now redirect you to sign-in with Microsoft. Enter valid user credentials and test the sign-in.</p>
<p><img src="1.png" alt="1"></p>
<p>If everything is working well, the user will be signed in and Z-App will minimize itself to your system tray or menu-bar. If you open it, you&rsquo;ll see your user is authenticated.</p>
<p><img src="24.png" alt="24"></p>
<h2 id="troubleshooting-sign-in">Troubleshooting Sign-in</h2>
<p>If the Microsoft SSO fails, check the config on the Azure AD side. This could be due to:</p>
<ul>
<li>The URLs in the SAML config are not correct.</li>
<li>Your user has not been assigned to the enterprise application.</li>
</ul>
<p>If sign in passes Microsoft SSO, but you get a Zscaler error (as per the image below), check the error code in the bottom right corner against the <a href="https://help.zscaler.com/zia/troubleshooting-saml">list of error codes here</a>. This indicates an issue with the config on the Zscaler side (typically something to do with the certificate you imported from Azure AD).</p>
<p><img src="25.png" alt="25"></p>
<h1 id="finish">Finish</h1>
<p>If all went well, you should now have your ZIA tenant integrated with Azure AD with SAML-based SSO and SCIM user provisioning.</p>
]]></content>
        </item>
        
        <item>
            <title>Set up Azure Active Directory (Azure AD) for free</title>
            <link>https://nathancatania.com/posts/set-up-azure-active-directory-for-your-homelab/</link>
            <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/set-up-azure-active-directory-for-your-homelab/</guid>
            <description>Get an Azure Free Account Before you start, you will need to sign up for a free Azure account: https://azure.microsoft.com/en-au/free/
This gives you some Azure services, like Windows &amp;amp; Linux VMs, free for 12 months, while other Azure services (like Azure Active Directory) are free permanently up to certain usage limits.
With Azure AD free, you can freely create users and groups, but groups cannot be assigned and synchronized to enterprise applications.</description>
            <content type="html"><![CDATA[<h1 id="get-an-azure-free-account">Get an Azure Free Account</h1>
<p>Before you start, you will need to sign up for a free Azure account: <a href="https://azure.microsoft.com/en-au/free/">https://azure.microsoft.com/en-au/free/</a></p>
<p>This gives you some Azure services, like Windows &amp; Linux VMs, free for 12 months, while other Azure services (like Azure Active Directory) are free permanently up to certain usage limits.</p>
<p>With Azure AD free, you can freely create users and groups, but groups cannot be assigned and synchronized to enterprise applications. To do this you will need a premium account.</p>
<p>To see everything included in the free account, click <a href="https://azure.microsoft.com/en-au/free/free-account-faq/">here</a>.</p>
<h1 id="get-a-domain-name">Get a Domain Name</h1>
<p>You&rsquo;ll be integrating your own domain name into Azure AD in this guide, so you&rsquo;ll need one if you don&rsquo;t already. Domains are pretty cheap depending on the TLD. You can often find ones for $1-2/year.</p>
<p><a href="https://www.namecheap.com/">NameCheap</a>, <a href="https://domains.google/">Google Domains</a>, <a href="https://porkbun.com/">Porkbun</a> are all good sites to get a domain from.</p>
<h1 id="create-a-new-tenant">Create a new tenant</h1>
<p>From the Azure Home screen, open the menu and go to <strong>Azure Active Directory</strong>.</p>
<p><img src="aad1.png" alt="1"></p>
<p>You&rsquo;ll see the default directory. Ignore this and select <strong>Create a directory</strong> from the top.</p>
<p><img src="aad2.png" alt="2"></p>
<p>Under the <strong>Basics</strong> tab, select <strong>Azure Active Directory</strong>. Click next to go to the <strong>Configuration</strong> tab.</p>
<p><img src="aad3.png" alt="3"></p>
<p>Give your &ldquo;Organization&rdquo; a name. I went with my own name. You&rsquo;ll also need to select an Initial Domain Name. This will be a subdomain on the <code>onmicrosoft.com</code> domain. Eg: <code>nathanc.onmicrosoft.com</code></p>
<p>You cannot delete this domain, but can optionally add your own domain name in a later step. The subdomain you pick here must be unique and connot have been used before by any other Azure user.</p>
<p>Finally, select your country so you can be allocated to the closest DC region.</p>
<p>When you are done, click next to go to the <strong>Review + Create</strong> tab. Review your selection and click <strong>Create</strong> when you are ready.</p>
<p><img src="aad4.png" alt="4"></p>
<h1 id="add-a-custom-domain">Add a custom domain</h1>
<p>While you could use the <code>*.onmicrosoft.com</code> domain for your lab, it&rsquo;s generally a better idea to use your own custom domain name. This allows you to have identities such as <a href="mailto:nathan@mydomain.com">nathan@mydomain.com</a> instead of <a href="mailto:nathan@nathanc.onmicrosoft.com">nathan@nathanc.onmicrosoft.com</a>.</p>
<p>Once your tenant has been created, on the side panel for your new directory, click <strong>Custom domain names</strong>. Then click <strong>Add custom domain</strong> at the top.</p>
<p><img src="aad5.png" alt="5"></p>
<p>Enter in your full domain name, <strong>including the top-level</strong>, eg: <code>.com</code>, <code>.net</code>, <code>.cool</code> etc.</p>
<p>You&rsquo;ll be promoted to add a new TXT DNS record with your domain registrar using the infomation displayed. Once you&rsquo;ve done so, you can click <strong>Verify</strong>. The record may fail to validate straight away: it can take up to 72 hours before the validation works, although for me it took roughly 5 minutes.</p>
<p><img src="aad6.png" alt="6"></p>
<p>Once verified, elect to make your custom domain the primary domain for your new directory.</p>
<h1 id="add-some-users">Add some users</h1>
<p>From the directory side menu under <strong>Manage</strong>, click <strong>Users</strong>, then <strong>New User</strong>.</p>
<p><img src="aad7.png" alt="7"></p>
<p>Fill in the following fields for the user:</p>
<ol>
<li>Username</li>
<li>Name</li>
<li>Password</li>
<li>Job Title &amp; Department</li>
</ol>
<p>Users will be provisioned with the basic <strong>User</strong> role by default. You can add additional roles &amp; permissions if needed. We haven&rsquo;t setup any groups yet so leave that part alone.</p>
<p><img src="aad8.png" alt="8"></p>
<p>When you&rsquo;re finished, you&rsquo;ll be returned to the <strong>All users</strong> page with your new user created.</p>
<p>For a homelab, might be helpful to create several dummy users.</p>
<h1 id="create-some-groups">Create some groups</h1>
<p>Groups are exactly that: Secure grouping of users to simplify access policies within certain applications.</p>
<p>From the directory side menu under <strong>Manage</strong>, click <strong>Groups</strong>, then <strong>New Group</strong>. You&rsquo;ll notice I already have some groups defined.</p>
<p><img src="aad9.png" alt="9"></p>
<p>Leave the <strong>Group type</strong> as <strong>Security</strong>. Give you group a name and description.</p>
<p>Here you can assign an owner of the group, as well as members from a list of users you created earlier. You can also assign existing groups as a member making this new group the parent superset.</p>
<p><img src="aad10.png" alt="10"></p>
<p>Click <strong>Create</strong> when you are done.</p>
<h1 id="adding-enterprise-applications-for-sso">Adding Enterprise Applications for SSO</h1>
<p>From the directory side menu under <strong>Manage</strong>, click <strong>Enterprise applications</strong>, then <strong>New application</strong>.</p>
<p><img src="aad11.png" alt="11"></p>
<p>Search for the application you want to provide SSO to.</p>
<p>When you have found your application, click <strong>Create</strong>.</p>
<p><img src="aad12.png" alt="12"></p>
<h1 id="finish">Finish</h1>
<p>Azure AD should now be configured with some users and groups.</p>
]]></content>
        </item>
        
        <item>
            <title>Deploy Windows Server with an Azure Free Account</title>
            <link>https://nathancatania.com/posts/deploying-windows-server-2019-with-an-azure-free-account/</link>
            <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploying-windows-server-2019-with-an-azure-free-account/</guid>
            <description>Get an Azure Free Account Before you start, you will need to sign up for a free Azure account: https://azure.microsoft.com/en-au/free/
This gives you some Azure services, like Windows &amp;amp; Linux VMs, free for 12 months, while other Azure services (like Azure Active Directory) are free permanently up to certain usage limits.
To see everything included in the free account, click here.
Note: Don&amp;rsquo;t expect the server deployed under the free tier to be fast - we are limited to 1GB RAM and 1 vCPU with the B1s instance size.</description>
            <content type="html"><![CDATA[<h1 id="get-an-azure-free-account">Get an Azure Free Account</h1>
<p>Before you start, you will need to sign up for a free Azure account: <a href="https://azure.microsoft.com/en-au/free/">https://azure.microsoft.com/en-au/free/</a></p>
<p>This gives you some Azure services, like Windows &amp; Linux VMs, free for 12 months, while other Azure services (like Azure Active Directory) are free permanently up to certain usage limits.</p>
<p>To see everything included in the free account, click <a href="https://azure.microsoft.com/en-au/free/free-account-faq/">here</a>.</p>
<p>Note: Don&rsquo;t expect the server deployed under the free tier to be fast - we are limited to 1GB RAM and 1 vCPU with the B1s instance size.</p>
<h1 id="this-guide">This guide</h1>
<p>This guide will cover deploying a Windows Server VM to Azure and ensuring (at the time of writing this at least) that usage is contrained to the free account limits. This means that if you do everything correctly, you shouldn&rsquo;t have any on-going charges for the first 12 months - provided your usage doesn&rsquo;t exceed the free tier limits.</p>
<p>The Azure free account gives you approx US$200 to use on services for the first 30 days, so if you happen to make a mistake, you&rsquo;ll know the next time you log into Azure as you&rsquo;re available credit will have decreased.</p>
<h1 id="create-a-windows-server-virtual-machine">Create a Windows Server Virtual Machine</h1>
<p>From Azure Home, click <strong>Create a resource</strong>.</p>
<p><img src="azure1.png" alt="1"></p>
<p>In the <strong>Search the Marketplace</strong> box, type <code>Windows Server</code> and select it from the autocomplete box.</p>
<p>Leave the software plan as the default (we will change it in the next step) and click <strong>Create</strong>.</p>
<p><img src="azure2.png" alt="2"></p>
<h2 id="basics">Basics</h2>
<p>On the next page:</p>
<ol>
<li>Leave <strong>Subscription</strong> as the default. It should say <code>Azure subscription 1</code> or similar.</li>
<li>Create a new <strong>Resource Group</strong>. Call it whatever you like. I called mine <code>WinServerRG</code></li>
<li>Give your VM a name.</li>
<li>Select the appropriate Azure region to deploy your VM. This should be as close to your location as possible. I chose <code>Australia East</code>.</li>
<li>Leave <strong>Availability Options</strong> as <code>No infrastructure redundancy required</code>.</li>
</ol>
<p>For the <strong>Image</strong> field, click <strong>Browse all public and private images</strong>. Scroll down the list and select an image prefixed with <code>[smalldisk]</code>. I selected <strong>[smalldisk] Windows Server 2019 Datacenter</strong>.</p>
<p><img src="azure3.png" alt="3"></p>
<p>The <code>[smalldisk]</code> image options limit the OS disk to 30GB which allows us to stay within the limitations of the Azure free tier. Microsoft give us 2x 64GB of Premium SSD storage as part of the free tier, but by default, a normal Windows Server instance will deploy an OS disk with a 128GB Premium SSD disk.
<strong>This will cause you to be charged for a 128GB disk if you use a normal Windows Server image.</strong></p>
<p>Note that this still doesn&rsquo;t keep us within the free tier. Azure will attribute the 30GB OS disk size to a 32GB Premium SSD&hellip; which is not covered by the free tier. After we deploy the VM, we can re-size the OS drive to ~60GB which will be covered by one of our free 64GB Premium SSDs.</p>
<p>Next, we need to select the size of the VM.
<strong>Warning: Be sure to change this! The default size selected is typically very expensive!</strong></p>
<p>Click <strong>Change size</strong> and select <strong>B1s</strong> as the size of the VM instance.<!-- raw HTML omitted -->
For the Windows OS, Microsoft include 750 hours per month (for the 1st 12 months) of B1s usage as part of the free tier.
NB: 750 hours is just over 31 days. So your entire month is covered, every month, for the first 12 months for this single VM.</p>
<p><img src="azure4.png" alt="4"></p>
<p>Next, give your VM a username and <strong>STRONG</strong> password.</p>
<p>For <strong>Inbound port rules</strong>, select <strong>RDP (3389)</strong> as the allowed inbound service. This will allow you to remotely connect to your VM once deployed. I also selected <strong>HTTP (80)</strong> and <strong>HTTPS (443)</strong>.</p>
<p>It is critical that you have a strong password defined and that you have very restrictive inbound network security rules in the coming steps. <strong>If you don&rsquo;t, you have a significant change of your VM being hacked or attacked by a malicious entity.</strong></p>
<p>Click <strong>Next</strong> to go to the <strong>Disks</strong> tab where we will define the storage to be used.</p>
<h2 id="disks">Disks</h2>
<p>Leave <strong>Premium SSD</strong> selected as the OS disk type.
This allocates a 32GB Premium SSD as the OS drive. However, only 2x 64GB disks are covered by the free tier.
<strong>As such, after we create the VM, we will need to change the OS disk size to ensure Azure uses a 64GB disk which will be free.</strong></p>
<p>For <strong>Data disks</strong> select <strong>Create and attach a new disk</strong>.</p>
<p><img src="azure5.png" alt="5"></p>
<p>On the next screen change the size of the disk to <code>64GB</code>, leave the <strong>Source type</strong> as <code>None</code>, and give it whatever name you want.</p>
<p><img src="azure6.png" alt="6"></p>
<p>Click OK to return to the <strong>Disks</strong> tab and you will see your new disk listed under the <strong>Data disks</strong> section.</p>
<p>Now click <strong>Next</strong> to go to the <strong>Networking</strong> tab where we will define how our VM will be connected to the network and how open it will be for remote access.</p>
<h2 id="networking">Networking</h2>
<p>First, click to create a new Virtual Network.</p>
<p>The <strong>Address range</strong> will be populated to <code>10.0.0.0/16</code> by default. You can change this to whatever you want. I set my vnet address range to <code>10.99.0.0/16</code>.</p>
<p>Next you need to carve out a smaller subnet from within the <code>/16</code> vnet we specified above. Give it a name (it can be anything - I called mine <code>Infrastructure</code>), and set the CIDR range. I used <code>10.99.0.0/24</code>.</p>
<p><img src="azure7.png" alt="7"></p>
<p>Click OK when you are done and select both the Virtual network and subnet you created.</p>
<p>Next click to create a new Public IP. Give it a name, set the <em>SKU</em> as <code>Basic</code> and the <strong>Assignment</strong> as <code>Static</code>.</p>
<p>Your first 3 fields will look something like this:</p>
<p><img src="azure7-2.png" alt="7-2"></p>
<p>This next step is <strong>CRITICAL</strong> to get correct. Failing to do so will expose your VM to the internet making it vulnerable to attack.</p>
<p>For <strong>NIC network security group</strong>, select <strong>Advanced</strong>, and click to create a new security group.</p>
<p><img src="azure9.png" alt="9"></p>
<p>Give the new security group a name and <strong>delete the default inbound rule present</strong>. Click to add a new inbound rule.</p>
<p><img src="azure10.png" alt="10"></p>
<p>We are going to restrict remote access to your Windows Server VM from your current IP address only. For me, this was my home IP, meaning I&rsquo;ll only be able to access the VM when I&rsquo;m at home. Not a big deal and we can always change or update this later.</p>
<p>To find your current public IP address, open a new tab and simply search Google for <code>What is my IP?</code>. You&rsquo;ll see something like this:</p>
<p><img src="azure8.png" alt="8"></p>
<p>I&rsquo;ve modified this image to obscure my own IP. Select and copy the IP shown and go back to your Azure tab.</p>
<p>Change <strong>Source</strong> field for the inbound security rule to <code>IP Address</code>. Under <strong>Source IP address/CIDR ranges</strong> paste in your IP address from Google.</p>
<p>Leave <strong>Source port ranges</strong> as an asterisk <code>*</code>, <strong>Destination</strong> as <code>Any</code>, but change the <strong>Destination port ranges</strong> as needed. At the very least, add port <code>3389</code> which is the inbound port for RDP. Without this, you won&rsquo;t be able to remotely connect to the VM. You can add other ports in too, like <code>80</code> (for HTTP) or <code>443</code> (for HTTPS) - just separate ports with a comma, eg: <code>3389,80,443</code></p>
<p>To open all inbound ports to your VM, you can use an asterisk <code>*</code> instead to denote <em>any</em> port.</p>
<p>Make sure the <strong>Action</strong> is set to <strong>Allow</strong>. Give the rule a name, and you can change the priority if needed. Click <strong>Add</strong> when finished.</p>
<p>Your rule will look something like the following:</p>
<p><img src="azure11.png" alt="11"></p>
<p>Next, click to add a new outbound rule. We will explicitly set a rule that allows our VM to reach any destination on the internet.</p>
<p>You can leave the <strong>Source</strong>, <strong>Source port ranges</strong>, and <strong>Destination</strong> as <code>Any</code>. Change the default <strong>Destination port ranges</strong> from <code>8080</code> to an asterisk <code>*</code>
<strong>Without this, your VM will only be able to connect to remote destinations on port 8080</strong>.</p>
<p>Make sure the <strong>Action</strong> is set to <code>Allow</code>. GIve the outbound rule a name and click <strong>Add</strong> when you are done.</p>
<p><img src="azure12.png" alt="12"></p>
<p>You are now finished configuring your network secutity group. It should look similar to the following:</p>
<p><img src="azure13.png" alt="13"></p>
<p>Click OK to create it.</p>
<p>Leave <strong>Accelerated networking</strong> set to <code>Off</code> and <strong>Load Balancing</strong> set to <code>No</code>. Click Next to go to the <strong>Management</strong> tab next.</p>
<h2 id="management">Management</h2>
<p>Not much to do on this page. Under the <strong>Monitoring</strong> section, set the <strong>Identity</strong> and <strong>Auto-shutdown</strong> options to <code>Off</code>.</p>
<p><img src="azure14.png" alt="14"></p>
<p>You can skip the <strong>Advanced</strong> and <strong>Tags</strong> tabs. Go to the <strong>Review + create</strong> tab when ready.</p>
<h2 id="review-and-create">Review and Create</h2>
<p>Make sure everything here is as expected, particularly the VM size/instance type selected. <strong>This should be <code>B1s</code> to qualify for free tier usage.</strong></p>
<p>Keep in mind that if you make a change to the first <strong>Basics</strong> tab, it will typically wipe all the other tabs meaning you&rsquo;ll need to fill in all of the above all over again.</p>
<p>Click <strong>Create</strong> when you&rsquo;re ready to initialize the VM.</p>
<p><img src="azure15.png" alt="15"></p>
<h1 id="deployment">Deployment</h1>
<p>After you click <strong>Create</strong> you&rsquo;ll be redirected to the deployment screen for your VM where you can see the status for each element (like the VM itself, disks, security group, etc) being created.</p>
<p><img src="azure16.png" alt="16"></p>
<p>Sit back as this can 2-5 minutes to complete. You&rsquo;ll see the deployment complete screen when your VM is ready.</p>
<p>If you have any errors during deployment. Make sure you followed the guide exactly. My first deployment failed because I didn&rsquo;t explicitly click to create resources like the Virtual network or subnet - thinking that these would be automatically created and I wouldn&rsquo;t have to do anything. If you still have issues, <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/windows/quick-create-portal">Microsoft&rsquo;s Quickstart Guide for Windows VMs</a> may help.</p>
<h1 id="adjust-the-os-disk-capacity-for-free-tier-compatibility">Adjust the OS Disk Capacity for Free Tier Compatibility</h1>
<p>As explained above, the <code>[smalldisk]</code> Windows Server image only requires 30GB of OS disk space, however this places us within the threshold of the 32GB Premium SSD - which is NOT included in the free Azure tier.</p>
<p>As such, we must expand the 30GB OS disk to ensure we hit the 64GB SSD thereshold and are therefore not billed.</p>
<p>From the Azure Home page, open the menu and go to <strong>Virtual Machines</strong>. If you can&rsquo;t find the <strong>Virtual Machines</strong> page, you can search for it at the top.</p>
<p>This will show you a list of your VMs. Click the VM you just created to view it in detail.</p>
<p>If your VM is running, you will need to STOP it by clicking the <strong>Stop</strong> button. This can take several minutes. You cannot resize a disk in Azure while the VM it is attached to is running.</p>
<p><img src="aad25.png" alt="aad25"></p>
<p>When the VM has stopped, under <strong>Settings</strong>, click <strong>Disks</strong>.</p>
<p>Select the disk listed under <strong>OS disk</strong>.</p>
<p><img src="aad26.png" alt="aad26"></p>
<p>Click <strong>Configuration</strong> in the side navigation menu and enter a new size for the drive. Make sure it is greater than 32GB and less than 64GB. When you are done, click <strong>Save</strong>. You can then return to the VM screen and power it on again.</p>
<p>If you want to make use of this extra space inside the VM, you will need to expand the OS drive via <strong>Computer Management</strong> in Windows.</p>
<h1 id="connecting-to-your-virtual-machine">Connecting to your Virtual Machine</h1>
<p>From the Azure Home page, open the menu and go to <strong>Virtual Machines</strong>. If you can&rsquo;t find the <strong>Virtual Machines</strong> page, you can search for it at the top.</p>
<p>This will show you a list of your VMs. Click the VM you just created to view it in detail.</p>
<p>Click the <strong>Connect</strong> button in the top menu. Note down the public IP assigned to your VM and the port number displayed (this should be 3389 for RDP). You will use these to connect to your VM.</p>
<p><img src="azure17.png" alt="17"></p>
<p>If you are on a Windows PC, you can download the RDP file and open it to connect to your VM.</p>
<p>If you are on MacOS, you&rsquo;ll need something like <a href="https://itunes.apple.com/us/app/microsoft-remote-desktop/id715768417?mt=12">Microsoft&rsquo;s Remote Desktop Client from the Mac App Store</a>, or <a href="https://www.royalapps.com/ts/mac/features">Royal TSX</a> to connect.</p>
<p>The username and password are the ones you specified when you created the VM.</p>
<h1 id="basic-configuration-tasks">Basic Configuration Tasks</h1>
<h2 id="1---check-for-system-updates-and-configure-updates">1 - Check for System Updates and Configure Updates</h2>
<p>Go to <strong>Start</strong> <strong>&gt;</strong> <strong>Settings</strong> (the gear icon on the left side) <strong>&gt;</strong> <strong>Update &amp; Security</strong></p>
<p><img src="azure18.png" alt="18"></p>
<p>Check for any system updates that are available, and configure the active hours for the server (the times outside of which the server can restart to install it&rsquo;s updates). I set my active hours to be 7AM to 1AM daily, which means updates and restarts can occur between 1AM and 7AM each day.</p>
<h2 id="2---set-the-server-name">2 - Set the Server Name</h2>
<p>Under <strong>Server Manager &gt; Local Server</strong>, on the right side, click the <strong>Computer name</strong> field to modify.</p>
<p>You could have also accessed the Windows Update settings from the previous step in this page.</p>
<p>Click on the <strong>Refresh</strong> button at the top of the screen to make the Server Manager window reflect the changes.</p>
<p><img src="azure19.png" alt="19"></p>
<h2 id="3---set-the-time-zone">3 - Set the Time Zone</h2>
<p>This time under Server Manager, click <strong>Time zone</strong>. Azure sets the server to <code>UTC</code> by default. Change this to your time zone as applicable.</p>
<h2 id="4---set-a-static-private-ipv4-address">4 - Set a Static Private IPv4 Address</h2>
<p>We&rsquo;re currently accessing the server via a public IP address. Azure performs NAT to convert this to one of our private virtual network IPs on the server side. That is, the public IP is mapped to one of our 253 usable IP addresses in the <code>10.99.0.0/24</code> address space (or similar depending on how you configured your network).</p>
<p>By default, it is assigned one of these IPs dynamically. We need to change this to static to ensure the server always has the same private IP.</p>
<p>Open Command Prompt and issue the command <code>ipconfig</code></p>
<p><img src="azure19-2.png" alt="19-2"></p>
<p>My server has been assigned the IP of <code>10.99.0.5</code>. Note down the <strong>IP</strong>, <strong>subnet mask</strong>, and <strong>default gateway</strong>.</p>
<p>Go back to <strong>Server Manager &gt; Local Server</strong> again, and this time click <strong>Ethernet</strong> on the left side.</p>
<p>Right-click on the network adaptor and click <strong>Properties</strong>. Select <strong>Internet Protocol Version 4 (TCP/IPv4)</strong> and click <strong>Properties</strong>. Optionally, untick <strong>Internet Protocol Version 6 (TCP/IPv6)</strong> to disable IPv6.</p>
<p><img src="azure20.png" alt="20"></p>
<p>Enter the IP address, subnet mask, and default gateway obtained above. Additionally, manually specify IPs for DNS. I used Cloudflare: <code>1.1.1.1</code> and <code>1.0.0.1</code>.</p>
<p><strong>Make sure you triple check the IPs entered!</strong> You may lose access to your VM otherwise!</p>
<p>Click OK when done.</p>
<p>Your RDP connection will drop. Don&rsquo;t panic. Wait a few seconds, then reconnect.</p>
<h2 id="5---restart-the-server">5 - Restart the Server</h2>
<p>You should restart the server so your changes can take effect (and updates can be installed).</p>
<h1 id="finish">Finish</h1>
<p>Well done! You should now have a working Windows Server deployed using the Azure free tier with a very basic configuration applied.</p>
]]></content>
        </item>
        
        <item>
            <title>[How to] Upgrade your PS4 to an SSD</title>
            <link>https://nathancatania.com/posts/upgrade-your-ps4-to-an-ssd/</link>
            <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/upgrade-your-ps4-to-an-ssd/</guid>
            <description>This guide will work for all models of PlayStation 4, however the location of the hard-drive bay is different between models.
Replacing your Hard Drive will NOT void your warranty and is covered in an official support article.
Why would you want to do this? A few reasons. Namely:
You need more space for games. Many PS4s ship with a 500GB HDD which can be filled quickly.
You want faster load times.</description>
            <content type="html"><![CDATA[<p>This guide will work for all models of PlayStation 4, however the location of the hard-drive bay is different between models.</p>
<p>Replacing your Hard Drive will NOT void your warranty and is covered in an <a href="https://support.playstation.com/s/article/Upgrade-PS4-HDD">official support article</a>.</p>
<h1 id="why-would-you-want-to-do-this">Why would you want to do this?</h1>
<p>A few reasons. Namely:</p>
<ul>
<li>
<p><strong>You need more space for games.</strong> Many PS4s ship with a 500GB HDD which can be filled quickly.</p>
</li>
<li>
<p><strong>You want faster load times.</strong> Upgrading your PC or Laptop to an SSD makes a night and day difference to performance. The PS4 is hampered by a mechanical drive, so by upgrading it so an SSD we should expect a similar performance increase.</p>
</li>
</ul>
<h1 id="how-long-will-it-take">How long will it take?</h1>
<p>I was able to have my PS4 back up and running playing games in about 4-5 hours. The majority of this comes from the time taken to backup and restore the data on the PS4 (including all of the games).</p>
<p>For reference, I had about 332GB of content on my PS4&rsquo;s existing HDD. The actual drive swap took 10 minutes at most.</p>
<p>I recommend going through your PS4&rsquo;s library and deleting any games that you haven&rsquo;t played in a while. This will drastically cut down the backup and restore time. Most disc based games consume 30-50GB of space.</p>
<h1 id="what-will-you-need">What will you need?</h1>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1x External Hard Drive</strong></td>
<td>This is used to backup your existing PS4 HDD so we can restore all of your content to your new SSD or HDD.</td>
</tr>
<tr>
<td><strong>1x USB Drive (at least 2GB)</strong></td>
<td>When you install the new drive into the PS4, you need to re-install the PS4 Operating System as well. We&rsquo;ll be loading a copy of the software onto this USB and using it for the install.</td>
</tr>
<tr>
<td><strong>1x Phillips Head Screwdriver</strong></td>
<td>You&rsquo;ll need a small one. There are at least 5 screws you&rsquo;ll need to undo to access the drive.</td>
</tr>
<tr>
<td><strong>1x New SSD or HDD</strong></td>
<td>This is your replacement drive to be installed. I went with a Crucial MX500 1TB SSD.</td>
</tr>
</tbody>
</table>
<h1 id="what-drive-should-you-buy">What drive should you buy?</h1>
<p>The PS4 only takes 2.5&quot; drives (no more than 9.5mm in height). These drives are typically sold as laptop drives.</p>
<p>As my upgrade was to an SSD, I purchased a <strong>Crucial MX500 1TB 2.5&quot; SSD</strong>. This cost approx $140 AUD (~$85 USD before taxes)</p>
<figure><img src="mx500.jpg"
         alt="Crucial MX500 1TB 2.5-inch SSD"/><figcaption>
            <p>Crucial MX500 1TB 2.5-inch SSD</p>
        </figcaption>
</figure>

<hr>
<h1 id="step-1---prepare-your-external-drives">Step 1 - Prepare your external drives</h1>
<h2 id="external-drive-for-backup">External Drive for Backup</h2>
<p>To backup your PS4, you will need an external hard drive large enough to fit the current contents of your PS4.</p>
<p><strong>The external drive MUST be formatted as FAT32 or ExFAT.</strong> I formatted my drive as ExFAT.</p>
<h2 id="usb-stick-for-os-re-install">USB Stick for OS Re-install</h2>
<p>You will also need a USB Flash Drive at least 2GB in size. This should be formatted as FAT32. We will use this drive to re-install the PS4&rsquo;s operating system after replacing the drive.</p>
<h1 id="step-2---download-the-ps4-operating-system">Step 2 - Download the PS4 Operating System</h1>
<p>When we swap the drive of the PS4, the OS must be re-installed. We need to download the PS4 firmware from Sony in order to do this.</p>
<p>Sony makes two types of firmware file available: a smaller upgrade file (~445 MB) and a full re-install file (~996 MB). Most guides that I read pointed me towards using the first one, which DID NOT WORK.</p>
<p><a href="https://www.playstation.com/en-gb/get-help/ps4-system-software/">Click here to download the PS4 firmware</a>. At the time of writing this post, the latest version is 6.72.</p>
<p>Scroll down until you reach the section:</p>
<blockquote>
<p>Update or reinstall PS4 system software using a USB</p>
</blockquote>
<p>There are two tabs:</p>
<ol>
<li>Update PS4 system software using USB</li>
<li><strong>Reinstall PS4 system software using USB</strong></li>
</ol>
<p>Select the second one, then click the button to download the firmware file.</p>
<figure><img src="update1.jpg"
         alt="Download the correct PS4 firmware file"/><figcaption>
            <p>Download the correct PS4 firmware file</p>
        </figcaption>
</figure>

<p><strong>You MUST name the firmware file <code>PS4UPDATE.PUP</code></strong></p>
<p>Next, go to the USB Stick you prepared in Step 1. The PS4 will only recognize the firmware file if it is placed inside a special folder structure.</p>
<p>You will need to create 2x folders; one inside the other.</p>
<ol>
<li>In the root/base of the USB, create a folder called <code>PS4</code>.</li>
<li>Inside the <code>PS4</code> folder, create another folder called <code>UPDATE</code></li>
</ol>
<p>Now copy the <code>PS4UPDATE.PUP</code> file into the <code>UPDATE</code> folder.</p>
<p>The full file path on the USB stick should be: <code>/PS4/UPDATE/PS4UPDATE.PUP</code></p>
<figure><img src="update2.jpg"
         alt="Required folder structure for the PS4 firmware file"/><figcaption>
            <p>Required folder structure for the PS4 firmware file</p>
        </figcaption>
</figure>

<p>Once you have done this, place the USB stick aside and move onto the next step.</p>
<h1 id="step-3---backing-up-the-ps4">Step 3 - Backing Up the PS4</h1>
<blockquote>
<p>Before backing up your PS4, you should go through your game library and remove as many installed games as possible. This will drastically reduce the time required to complete the backup and restore processes.</p>
</blockquote>
<p>Plug your EXTERNAL drive prepared in Step 1 into the PS4.</p>
<p>On the PS4&rsquo;s menu, navigate to:<!-- raw HTML omitted -->
<strong>Settings &gt; System &gt; Back Up and Restore &gt; Back Up</strong></p>
<figure><img src="backup1.jpg"
         alt="The Back Up option is under Settings &amp;gt; System"/><figcaption>
            <p>The Back Up option is under Settings &gt; System</p>
        </figcaption>
</figure>

<p>The PS4 will ask you what you want to backup. Everything will be selected by default.
If your external drive was formatted correctly, the PS4 will display the amount of free space on the drive. I ticked everything then clicked Next.</p>
<figure><img src="backup2.jpg"
         alt="Select what you would like to backup"/><figcaption>
            <p>Select what you would like to backup</p>
        </figcaption>
</figure>

<p>If your drive cannot be used, the &ldquo;Next&rdquo; button will be greyed out and the drive will display no usable free space. In this case, check that your drive has been formatted correctly. If you are using FAT32, try formatting as ExFAT instead.</p>
<p>Once you click &ldquo;Next&rdquo;, the backup process will begin. Initially the PS4 will estimate a massive amount of time to complete the backup (like 8 hours), but it will slowly adjust and decrease.</p>
<p>My backup of 332GB took about 90-100 minutes all up.</p>
<figure><img src="backup3.jpg"
         alt="The backup process is runnning"/><figcaption>
            <p>The backup process is runnning</p>
        </figcaption>
</figure>

<h1 id="step-4---shutdown-the-ps4">Step 4 - Shutdown the PS4</h1>
<p>Once the backup process has finished, completely <strong>Power Off</strong> your PS4. Do NOT put it into Rest Mode - it needs to be completely shut down.</p>
<p>Once it has been powered off, unplug the console completely and move it to a desk or table: It is time to replace the drive.</p>
<h1 id="step-5---accessing-the-ps4-hdd">Step 5 - Accessing the PS4 HDD</h1>
<blockquote>
<p>This step will be different depending on the model of PS4 you have. The location of the HDD bay is different across models. <!-- raw HTML omitted --><!-- raw HTML omitted -->My PS4 is the Pro model.<!-- raw HTML omitted --><!-- raw HTML omitted -->Sony has model specific instructions <a href="https://support.playstation.com/s/article/Upgrade-PS4-HDD?language=en_US">here</a>.</p>
</blockquote>
<p>On the back (or side) of the PS4, look for a removable panel.</p>
<figure><img src="swap1.jpg"
         alt="Accessing the drive tray"/><figcaption>
            <p>Accessing the drive tray</p>
        </figcaption>
</figure>

<p>This may require a bit of force to pry away from the console. Doing so will expose the drive tray.</p>
<figure><img src="swap2.jpg"
         alt="The exposed drive tray"/><figcaption>
            <p>The exposed drive tray</p>
        </figcaption>
</figure>

<p>Using your small Phillips head screwdriver, remove the screw securing the drive tray in place. The tray should slide out towards you..</p>
<p>The picture below shows the removed tray with the old HDD in place. The drive is secured in the tray by 4 screws: 2 on either side of the tray. Remove these screws to remove the drive.</p>
<p>Note that bottom of the drive faces upwards when placed into the tray.</p>
<figure><img src="swap3.jpg"
         alt="The old HDD"/><figcaption>
            <p>The old HDD</p>
        </figcaption>
</figure>

<p>The empty tray, the old HDD, and the new SSD to be installed:</p>
<figure><img src="swap4.jpg"
         alt="The drive tray, old HDD, and new SSD side-by-side."/><figcaption>
            <p>The drive tray, old HDD, and new SSD side-by-side.</p>
        </figcaption>
</figure>

<p>Place the new drive/SSD into the tray with the bottom of the drive facing upwards.</p>
<p><strong>WARNING: If the new drive is not placed in the correct orientation, it will not slide back into the PS4, and you risk damaging the connector.</strong></p>
<p>Secure the drive with the 4 screws you removed earlier.</p>
<figure><img src="swap5.jpg"
         alt="The new SSD mounted in the drive tray"/><figcaption>
            <p>The new SSD mounted in the drive tray</p>
        </figcaption>
</figure>

<p>Slide the drive tray back into the PS4. It should sit flush the way it did before with minimal force required. <em>If it does not go back in all the way, check that you have mounted the drive the correct way up.</em></p>
<p>Screw the drive bay back into place, and snap the removable plastic cover back on.</p>
<p>Done!</p>
<h1 id="step-6---re-installing-the-ps4-operating-system">Step 6 - Re-installing the PS4 Operating System</h1>
<h2 id="safe-mode-install">Safe Mode Install</h2>
<p>Plug your PS4 back in - do not power it on just yet.</p>
<p>Insert the USB stick containing the PS4 Firmware File you downloaded in Step 2.</p>
<p>Power on the PS4.</p>
<p>The PS4 will boot into Safe Mode. This is OK and normal.</p>
<p>If your USB was configured correctly and you downloaded the correct firmware file, the PS4 will prompt you to initialize the system and re-install the OS.</p>
<p>Proceed. The software will install and your PS4 will reboot.</p>
<figure><img src="install1.jpg"
         alt="Re-installing the OS"/><figcaption>
            <p>Re-installing the OS</p>
        </figcaption>
</figure>

<p>If there is an issue with your USB stick or the firmware file, the PS4 will give you an error like the following:</p>
<blockquote>
<p>The update file cannot be used.<!-- raw HTML omitted -->Connect a USB storage device that contains an upgrade file for reinstallation for version [VERSION] or later.<!-- raw HTML omitted -->(CE-34788-0)</p>
</blockquote>
<figure><img src="install2.jpg"
         alt="Safe Mode USB error"/><figcaption>
            <p>Safe Mode USB error</p>
        </figcaption>
</figure>

<p>If this happens to you, the fix is usually quite trivial:</p>
<ol>
<li>Check your USB is formatted correctly as FAT32. Alternatively, try a different USB stick.</li>
<li>Check your folder structure is correct. The PS4 firmware file should be inside a folder called <code>UPDATE</code>, which itself should be in a folder called <code>PS4</code>. The <code>PS4</code> folder should not be within any other folder and should be located in the root of the USB.</li>
<li>Check your USB does not have multiple partitions. If you don&rsquo;t know what this is, you should be OK.</li>
<li>Check the PS4 firmware file is named correctly: <code>PS4UPDATE.PUP</code> It must be called this EXACTLY.</li>
<li>Make sure you downloaded the correct firmware file! You want the larger firmware file intended for re-installs, not the smaller firmware file for upgrades.</li>
</ol>
<h2 id="system-initialization">System Initialization</h2>
<p>Once the install finishes, your PS4 will reboot to a &ldquo;Welcome&rdquo; screen and will prompt you to setup the PS4 from factory-default settings. Follow the prompts until you get to the PS4 menu.</p>
<figure><img src="install3.jpg"
         alt="Initialization is complete"/><figcaption>
            <p>Initialization is complete</p>
        </figcaption>
</figure>

<p>Don&rsquo;t bother signing into PSN. Instead, we are going to restore all of your content in the next step.</p>
<h1 id="step-7---restoring-the-ps4">Step 7 - Restoring the PS4</h1>
<p>Congratulations, your new drive should be working nicely! We&rsquo;re now going to restore all of your content that we backed up earlier.</p>
<p>First, plug in your EXTERNAL hard drive that was used for the PS4 backup.</p>
<p>Navigate to: <strong>Settings &gt; System &gt; Back Up and Restore &gt; Restore</strong></p>
<p>Follow the prompts. You may get a message that your PS4 will initialize itself (again) before starting the restore process. This is OK. Proceed.</p>
<p><figure><img src="restore1.jpg"
         alt="Starting the Restore process"/><figcaption>
            <p>Starting the Restore process</p>
        </figcaption>
</figure>

{% include image.html path=&ldquo;2019-08-16/restore1.jpg&rdquo;
path-detail=&ldquo;2019-08-16/restore1.jpg&rdquo;
alt=&ldquo;Starting the Restore process&rdquo; %}</p>
<p>Like the backup process, the restore process can take quite some time. My data was restored in about 110 minutes.</p>
<figure><img src="restore2.jpg"
         alt="Restore in progress&amp;hellip;"/><figcaption>
            <p>Restore in progress&hellip;</p>
        </figcaption>
</figure>

<p>Once the restore is completed, your PS4 will reboot. You may be asked some questions similar to the initialization process earlier. Don&rsquo;t panic. All of your data is OK.</p>
<p>Your PS4 should launch to it&rsquo;s menu with all of your games, content and data restored.</p>
<h1 id="finish">Finish</h1>
<p>Well done you are finished!
Enjoy your new drive. If you installed an SSD - enjoy the faster load times.</p>
<p>While the improvement isn&rsquo;t as profound as it would be on a PC, I found the PS4 menu itself to be a fair bit smoother.</p>
<p>Testing with Destiny 2, I noticed (on average) a ~50% reduction in load times across the majority of activities. YMMV of course.</p>
]]></content>
        </item>
        
        <item>
            <title>ZTP Juniper devices with Sky Enterprise</title>
            <link>https://nathancatania.com/posts/ztp-juniper-devices-with-sky-enterprise/</link>
            <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/ztp-juniper-devices-with-sky-enterprise/</guid>
            <description>1.0 - ZTP Overview Arguably, the best feature of Sky Enterprise is its ability to make Zero Touch Provisioning (ZTP) of Juniper devices a breeze. You no longer need to mess around with DHCP options, nor do you need to ensure your config files are accessible via FTP.
Sky Enterprise allows you to ZTP your devices through the concept of &amp;ldquo;ZTP Templates&amp;rdquo;. A ZTP template is the Junos configuration you wish to apply to a device, exported in XML format (instead of the normal C-like syntax of Junos), with some variables added in - allowing you to re-use the same template across multiple devices.</description>
            <content type="html"><![CDATA[<h1 id="10---ztp-overview">1.0 - ZTP Overview</h1>
<p>Arguably, the best feature of Sky Enterprise is its ability to make Zero Touch Provisioning (ZTP) of Juniper devices a breeze. You no longer need to mess around with DHCP options, nor do you need to ensure your config files are accessible via FTP.</p>
<p>Sky Enterprise allows you to ZTP your devices through the concept of &ldquo;ZTP Templates&rdquo;. A ZTP template is the Junos configuration you wish to apply to a device, exported in XML format (instead of the normal C-like syntax of Junos), with some variables added in - allowing you to re-use the same template across multiple devices.</p>
<h2 id="why-you-should-bother-with-ztp">Why you should bother with ZTP?</h2>
<p>ZTP allows you to simply ship a device to site, install it, and plug it in &ndash; that&rsquo;s it! No more pre-staging!</p>
<p>The device will not only download its configuration and configure itself, but will also on-board itself and start streaming telemetry to your Sky Enterprise dashboard.</p>
<p>While this is valuable for SRX and NFX devices, most people in the Juniper ecosystem will likely find it far more timesaving for deploying EX series switches in bulk.</p>
<h2 id="ztp-methods">ZTP Methods</h2>
<p>There are 2 methods of ZTP on most branch Junos devices:</p>
<ol>
<li>Autoinstallation</li>
<li>Phone-Home Client</li>
</ol>
<p>Both options are typically present in the factory default config.</p>
<h3 id="autoinstallation">Autoinstallation</h3>
<p>Autoinstallation is traditional ZTP that relies on DHCP options.</p>
<pre tabindex="0"><code>system {
    autoinstallation {
        traceoptions {
            level verbose;
            flag {
                all;
            }
        }
        interfaces {
            ge-0/0/0 {
                bootp;
            }
            ge-0/0/15 {
                bootp;
            }
        }
    }
}
</code></pre><p>Autoinstallation does not require external WAN access to provision the device, but does typically take more effort to get working.
This guide will not discuss ZTP via the Autoinstallation method.</p>
<h3 id="phone-home-client">Phone-Home Client</h3>
<p>With the Phone-Home Client method (which both Sky Enterprise and Contrail SD-WAN use), the device will continuously call home and present its serial number to <code>redirect.juniper.net</code>.</p>
<pre tabindex="0"><code>system {
    phone-home {
        server https://redirect.juniper.net;
        rfc-complaint;
    }
}
</code></pre><p>When you add a new ZTP device with Sky Enterprise, your device serial number is automatically added to the <code>redirect.juniper.net</code> server.</p>
<p>When the device reaches <code>redirect.juniper.net</code>, the server checks to see if the serial number of the device is present in its database. The serial number is associated with the location (and associated certificate) the device can retrieve its configuration from - in this case, the FQDN of the bootstrap server of Sky Enterprise:</p>
<pre tabindex="0"><code>go.oneconfig.com/restconf/data/juniper-zerotouch-bootstrap-server:devices/device=&lt;DEVICE-SERIAL-NUMBER&gt;/notification
</code></pre><p>The device will then contact and present its serial number to this new server.</p>
<p>Sky Enterprise will not respond with the configuration of the device until an Administrator authorizes the ZTP process within the UI - this provides an additional layer of security in case the device is lost or stolen.</p>
<p>If the device serial number is not present within <code>redirect.juniper.net</code>, the device will not be redirected anywhere and the phone-home process will continue to loop until removed from configuration.</p>
<h2 id="ztp-requirements">ZTP Requirements</h2>
<h3 id="network-requirements">Network Requirements</h3>
<p>As you won&rsquo;t be pre-staging your devices, they will need to use DHCP to obtain network settings and perform the initial connection to complete the ZTP process.</p>
<p>The devices require:</p>
<ul>
<li>IP address</li>
<li>Default Route</li>
<li>DNS server(s).</li>
</ul>
<p>DNS is especially important, as without it, the device will not be able to resolve <code>redirect.juniper.net</code>; causing ZTP to fail.</p>
<h3 id="software-requirements">Software Requirements</h3>
<p>For the phone-home client to be present in the factory default configuration, the minimum software requirements are:</p>
<ul>
<li><strong>SRX devices:</strong> Junos 15.1X49-D110 or above.</li>
<li><strong>EX devices:</strong> Junos 18.2R1 or above (18.3R1 or above for Contrail SD-WAN 5.0)</li>
</ul>
<h3 id="cabling-requirements">Cabling Requirements</h3>
<ul>
<li>EX devices will automatically obtain a DHCP lease at boot via the Out-of-Band Management Port on the <code>vme.0</code> interface.</li>
<li>SRX devices will automatically obtain a DHCP lease at boot via port <code>ge-0/0/0</code> for in-band management, and <code>fxp0</code> (MGMT Port) for Out-of-Band management.</li>
<li>The 4G/LTE mPIM can also be used for SRX ZTP, as this will (in most cases) automatically obtain IP connectivity from the carrier.</li>
</ul>
<hr>
<h1 id="20---zero-touch-provisioning-ztp-with-sky-enterprise">2.0 - Zero Touch Provisioning (ZTP) with Sky Enterprise</h1>
<p>This section will walk through the process of creating a ZTP template, loading it into Sky Enterprise, and using it provision a new device.</p>
<p>Baseline example ZTP templates are provided as a starting point.</p>
<h2 id="ztp-templates">ZTP Templates</h2>
<p>A ZTP template is the configuration you wish to provision on a device (or group of devices), slightly modified with variables to enable it to be re-used.</p>
<p>Sky Enterprise requires that ZTP templates be in XML format.</p>
<p>The process for creating a ZTP template from scratch is as follows:</p>
<ol>
<li>Create your required config in Junos.</li>
<li>Export the config in XML format and copy it to a text-editor (or into the example template above).</li>
<li>Add variables where required (in Jinja2 format).</li>
<li>Paste the template into Sky Enterprise.</li>
</ol>
<h3 id="example-ztp-templates">Example ZTP Templates</h3>
<p>The example templates below contain the required configuration for the device to function with Sky Enterprise. You can add your own XML config in freely.</p>
<ul>
<li><a href="https://github.com/nathancatania/Junos-Notes/blob/master/SkyEnterprise/ZTP/srx-ztp-template.xml">SRX Example ZTP Template</a></li>
<li><a href="https://github.com/nathancatania/Junos-Notes/blob/master/SkyEnterprise/ZTP/ex-ztp-template.xml">EX Example ZTP Template</a></li>
</ul>
<h3 id="obtaining-your-xml-configuration">Obtaining your XML Configuration</h3>
<p>Do not try and create your own XML config from scratch - create the config on a Junos device then export it as XML.</p>
<p>To display your config as XML in Junos and save it to file:</p>
<pre tabindex="0"><code>show configuration | display xml | save /tmp/xmlconfig.xml
</code></pre><p>Get the saved file from Junos:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>scp username@device-hostname:/tmp/xmlconfig.xml ~/path/to/save/file/to
</span></span></code></pre></div><h3 id="overriding-existing-configuration">Overriding Existing Configuration</h3>
<p>Currently SkyEnterprise cannot override any existing configuration (ie: the factory default configuration).</p>
<p>The current workaround is to delete the section of config you wish to override, and then re-add your new config.</p>
<p>To delete sections of config in XML, add the <code>delete</code> parameter to a parent XML tag. For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;device</span> <span style="color:#a6e22e">xmlns=</span><span style="color:#e6db74">&#34;http://juniper.net/zerotouch-bootstrap-server&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;config&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>         ...
</span></span><span style="display:flex;"><span>         ...
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">&lt;security</span> <span style="color:#a6e22e">delete=</span><span style="color:#e6db74">&#34;delete&#34;</span><span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">&lt;security&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;log&gt;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">&lt;mode&gt;</span>stream<span style="color:#f92672">&lt;/mode&gt;</span>
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">&lt;report&gt;&lt;/report&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;/log&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;pki&gt;</span>
</span></span><span style="display:flex;"><span>               ...
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;/pki&gt;</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">&lt;/security&gt;</span>
</span></span><span style="display:flex;"><span>         ...
</span></span><span style="display:flex;"><span>         ...
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/config&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/device&gt;</span>
</span></span></code></pre></div><p>Sections of the snippet above have been omitted for brevity.</p>
<p>In the example above, everything under the original <code>security</code> section of the config is deleted. A user defined <code>security</code> config is then added.</p>
<h3 id="variables">Variables</h3>
<p>There wouldn&rsquo;t be much point to ZTP if the same hardcoded config had to be used for every device. Likewise, it would be tedious to have to upload a different config for every device you wish to provision.</p>
<p>The answer to this is <strong>Variables</strong>.</p>
<p>Replacing hardcoded values in your ZTP template with variables allows the template to be used across multiple devices. When assigning a specific ZTP template to a device, Sky Enterprise will prompt you to fill in a value for all variables detected in the template. When a device contacts Sky Enterprise and requests its config, Sky Enterprise renders the template with the variable values given and pushes the config to the device.</p>
<p>Using this method, each device that uses the same template will have its own unique configuration.</p>
<h4 id="format">Format</h4>
<p>Sky Enterprise uses Jinja templating to render ZTP templates.</p>
<p>To create a variable, enclose the name of the variable within <strong>two</strong> curly brackets. For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-jinja" data-lang="jinja"><span style="display:flex;"><span><span style="color:#75715e">{{</span> management_ip_and_cidr <span style="color:#75715e">}}</span>
</span></span></code></pre></div><p>When you assign the template to a device, Sky Enterprise will prompt you to fill in a value for the <code>management_ip_and_cidr</code> variable.</p>
<h4 id="rules-and-restrictions">Rules and Restrictions</h4>
<p>When naming your variables, remember KISS (Keep It Simple Stupid):</p>
<ul>
<li>Do not use special characters or symbols other than underscore _</li>
<li>Do not use spaces.</li>
<li>Numbers are ok, but try not to start the variable with a number.</li>
<li>Be descriptive so you can remember what the variable is for.</li>
<li>Consider using two variables for ip/cidr notation,<!-- raw HTML omitted -->eg: <code>{{ ip }}/{{ cidr }}</code></li>
<li>Do not use a Sky Enterprise Special or Reserved variable names (see below).</li>
</ul>
<h4 id="sky-enterprise-reserved-variables">Sky Enterprise Reserved Variables</h4>
<p>You should ensure that any ZTP template you create includes the configuration required for the device to communicate back to Sky Enterprise.</p>
<p>NB: The example ZTP templates from the section above already include this.</p>
<p>The following variables are reserved by Sky Enterprise and are automatically pre-filled when rendering the configuration from the template.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-jinja" data-lang="jinja"><span style="display:flex;"><span><span style="color:#75715e">{{</span> ztp_username <span style="color:#75715e">}}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">{{</span> ztp_password <span style="color:#75715e">}}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">{{</span> ztp_host_id <span style="color:#75715e">}}</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">{{</span> ztp_secret <span style="color:#75715e">}}</span>
</span></span></code></pre></div><h2 id="example-ztp-template-with-variables">Example ZTP Template with Variables</h2>
<p>The config snippet below describes how to use the variables within a template. You can view the full example here.</p>
<p>This example config is for an SRX device, and simply sets the hostname, DNS nameservers, <code>fxp0</code> management interface, and a default route to the gateway. Parts of the config (like the root password, and Sky Enterprise specific config) have been omitted.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;device</span> <span style="color:#a6e22e">xmlns=</span><span style="color:#e6db74">&#34;http://juniper.net/zerotouch-bootstrap-server&#34;</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;unique-id&gt;</span>{{ serial }}<span style="color:#f92672">&lt;/unique-id&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;config&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;configuration&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;system&gt;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">&lt;host-name&gt;</span>{{ hostname }}<span style="color:#f92672">&lt;/host-name&gt;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">&lt;name-server&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;name&gt;</span>{{ dns_server_1 }}<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">&lt;/name-server&gt;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">&lt;name-server&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;name&gt;</span>{{ dns_server_2 }}<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">&lt;/name-server&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;/system&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;interfaces&gt;</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">&lt;interface</span> <span style="color:#a6e22e">delete=</span><span style="color:#e6db74">&#34;delete&#34;</span><span style="color:#f92672">/&gt;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">&lt;name&gt;</span>fxp0<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">&lt;/interface&gt;</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">&lt;interface&gt;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">&lt;name&gt;</span>fxp0<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">&lt;unit&gt;</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">&lt;name&gt;</span>0<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">&lt;family&gt;</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">&lt;inet&gt;</span>
</span></span><span style="display:flex;"><span>                       <span style="color:#f92672">&lt;address&gt;</span>
</span></span><span style="display:flex;"><span>                          <span style="color:#f92672">&lt;name&gt;</span>{{ oob_management_ip_and_cidr }}<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>                       <span style="color:#f92672">&lt;/address&gt;</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">&lt;/inet&gt;</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">&lt;/family&gt;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">&lt;/unit&gt;</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">&lt;/interface&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;/interfaces&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;routing-options&gt;</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">&lt;static&gt;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">&lt;route&gt;</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">&lt;name&gt;</span>0.0.0.0/0<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>                 <span style="color:#f92672">&lt;next-hop&gt;</span>{{ gateway_ip }}<span style="color:#f92672">&lt;/next-hop&gt;</span>
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">&lt;/route&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&lt;/static&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&lt;/routing-options&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;/config&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;/configuration&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;/device&gt;</span>
</span></span></code></pre></div><p>Now, when deploying this template to SkyEnterprise, we will be prompted to fill in values for each of the above variables.</p>
<p>Sky Enterprise will then render the template with these variables and push the config to the device when it contacts the phone-home server.</p>
<p>Note that the <code>fxp0</code> interface is first deleted and then re-added via the template config. This is in case there is an existing <code>fxp0</code> configuration (as is the case with most factory default configs).</p>
<h2 id="loading-the-template-into-sky-enterprise">Loading the Template into Sky Enterprise</h2>
<p>Once you have your template completed, you&rsquo;re ready to load it into Sky Enterprise.</p>
<p>From the Sky Enterprise UI, navigate to <code>CONFIGURATION</code> &gt; <code>ZTP</code>:</p>
<figure><img src="1.png"
         alt="Navigate to the ZTP tab under Configuration"/><figcaption>
            <p>Navigate to the ZTP tab under Configuration</p>
        </figcaption>
</figure>

<p>Click <code>Add ZTP Template</code>. Here you will give your template a name, description, and paste the entire ZTP template (in XML) that you created above.</p>
<figure><img src="2.png"
         alt="Paste in your ZTP template and give it a name"/><figcaption>
            <p>Paste in your ZTP template and give it a name</p>
        </figcaption>
</figure>

<h2 id="provisioning-a-new-device">Provisioning a New Device</h2>
<p>Next, you will use your new template to Zero Touch a new device.</p>
<p>From the UI, navigate to <code>HOME</code> &gt; <code>DEVICES</code>:</p>
<figure><img src="3.png"
         alt="To add a new device, navigate to the Devices tab under Home"/><figcaption>
            <p>To add a new device, navigate to the Devices tab under Home</p>
        </figcaption>
</figure>

<p>Click <code>Add Device</code>:</p>
<ol>
<li>Give your device a name (this will be displayed in the UI)</li>
<li>Select whether it is a firewall (SRX), switch (EX), or NFX device.</li>
<li>Select <code>Create ZTP Device</code></li>
<li>Populate the device Serial Number. <strong>This is added to the Juniper redirect server.</strong></li>
<li>Select the ZTP template to be used.</li>
<li>Populate any variables.</li>
<li>Click <code>Create Device</code></li>
</ol>
<figure><img src="4.png"
         alt="Populate details for your ZTP device"/><figcaption>
            <p>Populate details for your ZTP device</p>
        </figcaption>
</figure>

<p><strong>NB: It is VERY important that the Serial Number you enter is correct.</strong>
The device will not be able to obtain its configuration otherwise as the correct serial will not be present in the redirect server.</p>
<h2 id="authorizing-the-device">Authorizing the Device</h2>
<blockquote>
<p>And now we play the waiting game&hellip;</p>
</blockquote>
<p>Sky Enterprise is usually quite quick about adding the Serial Number to the redirect server, but this can take up to 15 minutes.</p>
<p>Navigate back to <code>CONFIGURATION</code> &gt; <code>ZTP</code>. Your device&rsquo;s status is reflected here. If the device has successfully contacted Sky Enterprise, the state field should be <code>Authorization Required</code>. For security reasons, Sky Enterprise will not push the configuration to the device until you or another admin authorizes the ZTP process.</p>
<p>To initiate the ZTP process, click the menu icon next to the device name, and select <code>Authorize</code>.</p>
<figure><img src="5.png"
         alt="Authorize the ZTP process"/><figcaption>
            <p>Authorize the ZTP process</p>
        </figcaption>
</figure>

<p>If you have email notifications configured, Sky Enterprise will notify you that a device has requested authorization to ZTP.</p>
<figure><img src="6.png"
         alt="Email notification for ZTP"/><figcaption>
            <p>Email notification for ZTP</p>
        </figcaption>
</figure>

<p>If the ZTP process completes successfully, your device should appear under <code>HOME</code> &gt; <code>DEVICES</code> as <code>ONLINE</code>.</p>
<p><strong>Congratulations! You just Zero Touched a device!</strong></p>
<p><em>Not working? See Section 4.0 for Troubleshooting tips.</em></p>
<hr>
<h1 id="30---operational-mode-commands-and-stage-2-configuration">3.0 - Operational Mode Commands and Stage 2 Configuration</h1>
<p>Sky Enterprise does not allow you to run operational mode commands as part of the ZTP process. Likewise, there is no Stage 2 configuration permitted.</p>
<p>Only a single rendered configuration can be pushed as part of ZTP per device. This raises several questions, like:</p>
<ol>
<li>How do you manage PKI for features such as VPNs and SSL Proxy?</li>
<li>How do you run enrollment commands or OP scripts for features like Sky ATP?</li>
<li>How do you run HA commands for Stacking or Clustering?</li>
</ol>
<p>All of these examples require Operational Mode commands such as as<!-- raw HTML omitted --><code>request chassis cluster ...</code> or <code>request security ...</code>.</p>
<p>Sky Enterprise supports some of this functionality through its UI - like Virtual Chassis/Stacking config. You can additionally run commands through the &lsquo;Virtual CLI&rsquo; of Sky Enterprise UI. However, both of these are still manual processes.</p>
<p>What if you wanted to automate this as part of the ZTP process?<!-- raw HTML omitted -->
Event Policies are the answer!</p>
<h2 id="event-policies--triggering-events">Event Policies &amp; Triggering Events</h2>
<p>An Event Policy can be used to trigger the completion of additional tasks after the ZTP process has completed. For example, running Operational Mode commands, or running a script to apply additional (Stage 2) config.</p>
<p>You would include the Event Policy configuration as part of the initial ZTP template used to provision your device.</p>
<p>A good use case for this is PKI management on SRX. You can use an Event Policy to trigger the <code>request security pki</code> commands to obtain certificates from a CA and enroll them on the device in order to bring up VPNs or utilize SSL Proxy.</p>
<h2 id="find-an-event-to-trigger-event-policy">Find an Event to Trigger Event Policy</h2>
<p>First, locate an appropriate event (usually a Syslog event) to trigger your Event Policy.</p>
<p>To obtain a complete list of all events that a policy can be triggered with, use the following command in Configuration Mode (this might be slow):</p>
<pre tabindex="0"><code>set event-options policy test-policy1 events ?
</code></pre><p>The <code>?</code> at the end of the command will load the complete list of all event triggers.</p>
<p>Ideally, you want to pick an event that would not be encountered again once the required commands have been run (or Stage 2 config applied).</p>
<p>For the example mentioned in the section above, if we try and bring up an IPsec VPN without any of the required PKI present, we will see the event <code>pkid_no_keypair</code> in the messages log. We can use this as an Event Policy trigger event.</p>
<p>A good method of finding events that you can trigger on is to apply your config to a test device, and watch the <code>messages</code> log to see what events/warnings/errors occur. You can&rsquo;t trigger on everything here (the event must be in the list obtained above), but it is a good starting point to determine what issues your device is having as a result of not running the appropriate commands.</p>
<pre tabindex="0"><code>show log messages | last 50
</code></pre><h2 id="configuring-an-event-policy">Configuring an Event Policy</h2>
<p>The following is an example of an Event Policy:</p>
<pre tabindex="0"><code>event-options {
    policy ca_request {
        events pkid_no_keypair;
        then {
            execute-commands {
                commands {
                    &#34;op url https://raw.githubusercontent.com/nathancatania/Junos-Notes/master/POCs/SDWAN_Lite/enrol.slax&#34;;
                }
            }
        }
    }
}
</code></pre><p>This policy will execute on the <code>pkid_no_keypair</code> event, and will run a remote SLAX script, which in itself will run multiple Operational Mode commands.</p>
<p>You do not need to run a script to execute commands - you can set the Event Policy to run Operational Mode commands directly.</p>
<p>There is a small caveat to this:
<!-- raw HTML omitted -->Commands in the Event Policy are bound by a character limit. If your command exceeds the limit, the policy will not commit. The workaround to this is to run the command via a script.</p>
<p>If you examine the script above, you will see that it runs 3x Operational Mode commands:</p>
<pre tabindex="0"><code>request security pki ca-certificate enroll ca-profile sdwan-profile

request security pki generate-key-pair certificate-id sdwan-local

request security pki local-certificate enroll ca-profile sdwan-profile certificate-id sdwan-local domain-name juniper.example email ncatania@juniper.example ip-address 10.20.30.2 subject DC=juniper.example,CN=srxce1,OU=engineering,O=juniper,L=melbourne,ST=australia,C=au challenge-password E2B42DC325CA34D0
</code></pre><p>The last command exceeds the character limit; hence a script is used to run it instead.</p>
<p>You can get creative with your Event Policies, including applying additional configuration to your devices. The trick is to finding the correct event to trigger on.</p>
<h2 id="event-policy-caveats">Event Policy Caveats</h2>
<h3 id="continuous-policy-execution">Continuous Policy Execution</h3>
<p>If you are worried about your Event Policy continuously executing, you can use it to trigger additional config that has it remove itself after doing what it needs to do.</p>
<h3 id="script-privacy">Script Privacy</h3>
<p>Any script that you execute will need to be hosted remotely, as you cannot add files to the device as part of the ZTP process.</p>
<p>In the case of SRX and NFX ZTP, you could include a PSK IPsec VPN in your initial ZTP config that allows the device to reach the remote script in your internal network. This ensures you don&rsquo;t have to host your script publicly if it contains sensitive information.</p>
<p>For EX switches, the device should be able to reach your internal network through whichever firewall or gateway it is connected to.</p>
<hr>
<h1 id="40---troubleshooting">4.0 - Troubleshooting</h1>
<h2 id="checking-logs">Checking Logs</h2>
<p>If you find you are having issues with the ZTP process, examining the <code>messages</code> log can assist with troubleshooting:</p>
<pre tabindex="0"><code>show log messages | match phone-home | last 50
</code></pre><p>For more in-depth detail, you can modify the phone-home client to enable <code>traceoptions</code> (AKA debug logging):</p>
<pre tabindex="0"><code>set system phone-home traceoptions flag all
set system phone-home traceoptions file phc.log
</code></pre><p>This will log detailed output from the phone-home client to a log file called <code>phc.log</code>. To examine this file:</p>
<pre tabindex="0"><code>show log phc.log | last
</code></pre><h2 id="failed-configuration">Failed Configuration</h2>
<p>If your configuration failed to apply, you will see something like this in the <code>messages</code> log:</p>
<pre tabindex="0"><code>root@srx340&gt; show log messages | last
[...]
May 14 02:17:29  srx340 phone-home: phcd_platform_junos_commit: Read:error: configuration check-out failed
May 14 02:17:29  srx340 phone-home: phcd_platform_junos_apply_config: vnf_name:Local config failed!
May 14 02:17:29  srx340 phone-home: phcd_act_download_cfg: Failed to apply received configuration
May 14 02:17:29  srx340 phone-home: The stage1 configuration failed to committed on the device
</code></pre><p>Looking further up the log, or examining the traceoptions log from the phone-home client, will usually reveal the reason as to why the configuration failed.</p>
<p>This is usually due to a malformed or invalid XML config.</p>
<h2 id="srx-troubleshooting">SRX Troubleshooting</h2>
<p>The SRX has a few quirks that may cause issues for you when attempting ZTP.</p>
<pre tabindex="0"><code>******
May 14 02:17:29  srx340 phone-home: phcd_platform_junos_commit: Read:error: AUTHENTICATION service may not be de-configured while clients are present. Please clear bindings
******
May 14 02:17:29  srx340 phone-home: phcd_platform_junos_commit: Read:error: configuration check-out failed
May 14 02:17:29  srx340 phone-home: phcd_platform_junos_apply_config: vnf_name:Local config failed!
May 14 02:17:29  srx340 phone-home: phcd_act_download_cfg: Failed to apply received configuration
May 14 02:17:29  srx340 phone-home: The stage1 configuration failed to committed on the device
</code></pre><p>Note the first line in the log. With the factory default config, branch SRX devices have a DHCP server configured on <code>ge-0/0/0.0</code>. If you attempt to ZTP the device via this port, and remove the DHCP server config as part of your Stage 1 config, the deployment may fail. The device will not let you remove the the DHCP server settings as long as the port is in use.</p>
<p>If you hit this issue, as a workaround try to ZTP with LTE or a different port - such as <code>fxp0</code>. Failing that, leave the DHCP server configuration intact and remove it after the ZTP process completes.</p>
]]></content>
        </item>
        
        <item>
            <title>Connect Juniper Sky Enterprise to Aerohive HiveManager</title>
            <link>https://nathancatania.com/posts/connecting-skyenterprise-to-aerohive-hivemanager/</link>
            <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/connecting-skyenterprise-to-aerohive-hivemanager/</guid>
            <description>Introduction Juniper Sky Enterprise is a neat little application that can manage and provision SRX, EX, and NFX series products from Juniper Networks. Sky Enterprise also allows you to monitor (but not configure) any Aerohive APs that you have deployed, however the documentation on how to do so is hidden away on the OneConfig website.
This post will walk through the process of adding your Aerohive APs to your Sky Enterprise inventory.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Juniper Sky Enterprise is a neat little application that can manage and provision SRX, EX, and NFX series products from Juniper Networks. Sky Enterprise also allows you to monitor (but not configure) any Aerohive APs that you have deployed, however the documentation on how to do so is <a href="https://oneconfig.com/support/hivemanager-api-integration/">hidden away on the OneConfig website.</a></p>
<p>This post will walk through the process of adding your Aerohive APs to your Sky Enterprise inventory.</p>
<p>In short:</p>
<ul>
<li>To link Sky Enterprise and HiveManager, we need to give Sky Enterprise an <code>Owner ID</code> and <code>API Authorization Token</code> from HiveManager. This allows Sky Enterprise to utilize HiveManager&rsquo;s API to pull information about your APs.</li>
<li>You can generate API tokens from within HiveManager, but you require a <code>Client ID</code> in order to do so.</li>
<li>Normally to obtain a <code>Client ID</code>, we would register and create an application at the Aerohive Developer site, however in this case, Sky Enterprise is the application itself that we want to integrate with, so we will use their Client ID.</li>
</ul>
<p>Let&rsquo;s get started!</p>
<hr>
<h2 id="step-1---retrieve-your-owner-id-from-hivemanager">Step 1 - Retrieve your Owner ID from HiveManager</h2>
<p><a href="https://cloud.aerohive.com/login">Login to Aerohive HiveManager</a> using your existing credentials.</p>
<p>Hover over your name in the top right corner and click <strong>About HiveManager</strong></p>
<figure><img src="1.png"
         alt="Click &amp;lsquo;About HiveManager&amp;rsquo; to obtain your Owner ID"/><figcaption>
            <p>Click &lsquo;About HiveManager&rsquo; to obtain your Owner ID</p>
        </figcaption>
</figure>

<p>Your <strong>Owner ID</strong> is also known as your the <code>VHM Id</code>.</p>
<figure><img src="2.png"
         alt="Your Owner ID is the VHM Id"/><figcaption>
            <p>Your Owner ID is the VHM Id</p>
        </figcaption>
</figure>

<p><strong>Copy down the <code>VHM Id</code> displayed. You will need this in a later step.</strong></p>
<hr>
<h2 id="step-2---generate-an-api-token-in-hivemanager">Step 2 - Generate an API Token in HiveManager</h2>
<p>Hover over your name in the top right corner again, but this time click <strong>Global Settings</strong></p>
<figure><img src="3.png"
         alt="Access the Global Settings for HiveManager"/><figcaption>
            <p>Access the Global Settings for HiveManager</p>
        </figcaption>
</figure>

<p>Click <strong>API Token Management</strong> under <strong>API</strong> in the menu on the left. Then click the <code>+</code> button to generate a new token.</p>
<p>In the popup, paste in the code <code>e4ba0053</code>.</p>
<figure><img src="4.png"
         alt="Generate the API Access Token needed in Sky Enterprise"/><figcaption>
            <p>Generate the API Access Token needed in Sky Enterprise</p>
        </figcaption>
</figure>

<blockquote>
<p><code>e4ba0053</code> is the Client ID for Sky Enterprise. It is essential that you use this code or else you will run into issues with your credentials later.</p>
</blockquote>
<p>Click <strong>Generate</strong> to create an API Access Token.</p>
<p><strong>Copy down the <code>Access Token</code> displayed. You will need this in a later step.</strong></p>
<hr>
<h2 id="step-3---get-the-url-of-your-hivemanager-region">Step 3 - Get the URL of your HiveManager Region</h2>
<p>While browsing HiveManager, note down the URL in use. Copy from the <code>https://</code> part through to the <code>.com</code></p>
<figure><img src="5.png"
         alt="Copy the highlighted part of the HiveManager URL"/><figcaption>
            <p>Copy the highlighted part of the HiveManager URL</p>
        </figcaption>
</figure>

<p>For example: For the Australian Data Center, the URL to be copied will be:</p>
<pre tabindex="0"><code>https://cloud-aus.aerohive.com
</code></pre><hr>
<h2 id="step-4---linking-sky-enterprise-to-hivemanager">Step 4 - Linking Sky Enterprise to HiveManager</h2>
<p><a href="https://skyenterprise.juniper.net/">Login to Juniper Sky Enterprise</a> using your existing credentials.</p>
<p>Click <strong>Settings</strong> in the menu bar at the top. Scroll down to the <strong>Aerohive</strong> option and tick the checkbox.</p>
<figure><img src="6.png"
         alt="Enable Aerohive monitoring in Sky Enterprise"/><figcaption>
            <p>Enable Aerohive monitoring in Sky Enterprise</p>
        </figcaption>
</figure>

<ul>
<li>Copy your <code>Owner ID</code> (AKA <code>VHM Id</code>) obtained in Step 1 into the <strong>Owner ID</strong> field.</li>
<li>Copy the <code>Access Token</code> generated in Step 2 into the <strong>Authentication Token</strong> field.</li>
<li>Copy the HiveManager URL from Step 3 into the <strong>Regional Data Center</strong> field.</li>
</ul>
<p>When you are done, scroll to the bottom of the page and click <strong>Update</strong>. A green notification from Sky Enterprise will let you know all is well.</p>
<p>If Sky Enterprise responds with an &ldquo;invalid credentials&rdquo; message, check that they information you have entered into the fields above is correct.</p>
<hr>
<h2 id="step-5---verify-your-aerohive-aps-can-be-viewed-in-sky-enterprise">Step 5 - Verify your Aerohive APs can be viewed in Sky Enterprise</h2>
<p>If the above step was successful, you should now have a <strong>Wifi APs</strong> tab under the <strong>Devices</strong> menu. This will list all of the APs you have in your HiveManager inventory.</p>
<figure><img src="7.png"
         alt="List of APs in Sky Enterprise"/><figcaption>
            <p>List of APs in Sky Enterprise</p>
        </figcaption>
</figure>

<p>You can click the dropdown box/link next to each AP for more information, or a link back to HiveManager.</p>
<figure><img src="8.png"
         alt="Viewing AP information in Sky Enterprise"/><figcaption>
            <p>Viewing AP information in Sky Enterprise</p>
        </figcaption>
</figure>

]]></content>
        </item>
        
        <item>
            <title>Unlock or change the super password for Junos Space 17.2, 18.X</title>
            <link>https://nathancatania.com/posts/unlocking-or-changing-the-super-password-for-junos-space-172r1/</link>
            <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/unlocking-or-changing-the-super-password-for-junos-space-172r1/</guid>
            <description>Introduction For Junos Space and its associated applications, if you have forgotten the password to the super account (or have locked yourself out of the account), you can reset the password and/or unlock the account by modifying the super user&amp;rsquo;s entry in the build_db DB of MySQL; via the Unix CLI in Space&amp;rsquo;s &amp;ldquo;debug&amp;rdquo; mode.
However in release 17.2R1, the default password of the jboss user (which is required in order to access the MySQL CLI in the first place) has changed.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>For Junos Space and its associated applications, if you have forgotten the password to the <strong>super</strong> account (or have locked yourself out of the account), you can reset the password and/or unlock the account by modifying the super user&rsquo;s entry in the <code>build_db</code> DB of MySQL; via the Unix CLI in Space&rsquo;s &ldquo;debug&rdquo; mode.</p>
<p>However in release 17.2R1, the default password of the <strong>jboss</strong> user (which is required in order to access the MySQL CLI in the first place) has changed. <del>As far as I can tell, Juniper has not documented this anywhere.</del></p>
<blockquote>
<p>Update July 2018:</p>
<ul>
<li>Juniper have now documented this changed in a <a href="https://kb.juniper.net/InfoCenter/index?page=content&amp;id=KB17582">KB article</a> (J-net login required).</li>
<li>This process is will also work with Junos Space releases 18.1 and 18.2.<!-- raw HTML omitted --></li>
</ul>
</blockquote>
<p>Previously, you would access the MySQL CLI using the user <strong>jboss</strong> and the password <strong>netscreenos</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>root@space-005056a51a72 ~<span style="color:#f92672">]</span><span style="color:#75715e"># mysql -u jboss -pnetscreenos build_db</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Welcome to the MySQL monitor.  Commands end with ; or <span style="color:#ae81ff">\g</span>.
</span></span><span style="display:flex;"><span>Copyright <span style="color:#f92672">(</span>c<span style="color:#f92672">)</span> 2000, 2017, Oracle and/or its affiliates. All rights reserved.
</span></span><span style="display:flex;"><span>mysql&gt;
</span></span></code></pre></div><p>In Space 17.2R1 (and above), the same credentials do not work:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>root@space-005056a51a72 ~<span style="color:#f92672">]</span><span style="color:#75715e"># mysql -u jboss -pnetscreenos build_db</span>
</span></span><span style="display:flex;"><span>ERROR <span style="color:#ae81ff">1045</span> <span style="color:#f92672">(</span>28000<span style="color:#f92672">)</span>: Access denied <span style="color:#66d9ef">for</span> user <span style="color:#e6db74">&#39;jboss&#39;</span>@<span style="color:#e6db74">&#39;localhost&#39;</span> <span style="color:#f92672">(</span>using password: YES<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>So if you&rsquo;ve locked your <strong>super</strong> user account or forgotten its password, what do you do now?</p>
<h2 id="new-sql-password">New SQL password</h2>
<p>It seems as of 17.2, during installation, Space will automatically generate a random password for the <strong>jboss</strong> user of the MySQL database.</p>
<p>Lucky for us (?), Space also stores this generated password in plaintext (!! 😱) for us to reference.</p>
<p>The passwords are located at: <code>/etc/sysconfig/JunosSpace/pwd</code></p>
<p>Dumping them to screen, we can copy the password for the <strong>jboss</strong> user:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>root@space-005056a51a72 ~<span style="color:#f92672">]</span><span style="color:#75715e"># cat /etc/sysconfig/JunosSpace/pwd</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mysql.repUser<span style="color:#f92672">=</span>-BkGJCdQSEktjxIVRlF4rBOx9g3LHgCM
</span></span><span style="display:flex;"><span>mysql.repAdmin<span style="color:#f92672">=</span>p8AGI_-jAbsNlKq4cnnSVb0rh1aeOLO-
</span></span><span style="display:flex;"><span>postgres.postgres<span style="color:#f92672">=</span>postgres
</span></span><span style="display:flex;"><span>postgres.opennms<span style="color:#f92672">=</span>opennms
</span></span><span style="display:flex;"><span>postgres.replication<span style="color:#f92672">=</span>replication
</span></span><span style="display:flex;"><span>cassandra.jboss<span style="color:#f92672">=</span>netscreen
</span></span><span style="display:flex;"><span>jboss.admin<span style="color:#f92672">=</span>LJrZaVdj++++50395922
</span></span><span style="display:flex;"><span>mysql.root<span style="color:#f92672">=</span>BCiIAlkj5_NZj83VQpuX4E2oSRBHTlWA
</span></span><span style="display:flex;"><span>mysql.jboss<span style="color:#f92672">=</span>AEYZIMccv0Uq8ct_WoSgbo0BB4Wwu8RH
</span></span></code></pre></div><p>You want the <code>mysql.jboss=</code> string, which in the example above is: <code>AEYZIMccv0Uq8ct_WoSgbo0BB4Wwu8RH</code></p>
<p><strong>This is your password to authenticate the MySQL jboss user!</strong></p>
<p>You can now access the MySQL CLI:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">[</span>root@space-005056a51a72 ~<span style="color:#f92672">]</span><span style="color:#75715e"># mysql -u jboss -p&lt;YOU-JBOSS-PASSWORD&gt; build_db</span>
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Welcome to the MySQL monitor.  Commands end with ; or <span style="color:#ae81ff">\g</span>.
</span></span><span style="display:flex;"><span>Copyright <span style="color:#f92672">(</span>c<span style="color:#f92672">)</span> 2000, 2017, Oracle and/or its affiliates. All rights reserved.
</span></span><span style="display:flex;"><span>mysql&gt;
</span></span></code></pre></div><p>Replace the <code>&lt;YOUR-JBOSS-PASSWORD&gt;</code> with the string retrieved above. You will now have access to the CLI.</p>
<h2 id="fixing-the-super-account">Fixing the super account</h2>
<p>Now that we have the password to access our MySQL CLI, we can finally unlock or reset the <strong>super</strong> account to regain access to our Space applications.</p>
<h3 id="unlocking-the-super-account">Unlocking the super account</h3>
<p>If the super account is <strong>locked</strong>, you can unlock it from the MySQL CLI. Enter the following two DB queries/commands at the <code>mysql&gt;</code> shell prompt:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> * from USER_IP_ADDRESS where user_id in <span style="color:#f92672">(</span><span style="color:#66d9ef">select</span> id from USER where name LIKE <span style="color:#e6db74">&#39;%super%&#39;</span><span style="color:#f92672">)</span><span style="color:#ae81ff">\G</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>DELETE FROM USER_IP_ADDRESS where user_id in <span style="color:#f92672">(</span><span style="color:#66d9ef">select</span> id from USER where name LIKE <span style="color:#e6db74">&#39;%super%&#39;</span><span style="color:#f92672">)</span>;
</span></span></code></pre></div><p>The super account should now be unlocked.</p>
<h3 id="changing-the-super-account-password">Changing the super account password</h3>
<p>If you have forgotten the password to the super account, you can reset it by altering the database entry for the &lsquo;super&rsquo; user. The password field takes an encrypted value. <strong>We will reset the password to the default value <code>juniper123</code></strong>. This will allow you to login and then change it to something more secure through the GUI.</p>
<p>To login to the DB and change the password in one command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>mysql -ujboss -p<span style="color:#66d9ef">$(</span>grep mysql.jboss /etc/sysconfig/JunosSpace/pwd | awk -F<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;{print $2}&#39;</span><span style="color:#66d9ef">)</span> build_db -e <span style="color:#e6db74">&#34;UPDATE USER set password=&#39;ok89Nva6qHxytSHsP8AeLg==&#39; where name=&#39;super&#39;&#34;</span>
</span></span></code></pre></div><p>This fetches the jboss password from the <code>pwd</code> file and executes the SQL statement to change the super user&rsquo;s password to <code>ok89Nva6qHxytSHsP8AeLg==</code> which represents <code>juniper123</code></p>
<h3 id="finish">Finish</h3>
<p>You should now be able to login to the Junos Space GUI using the username <code>super</code> and password <code>juniper123</code>.</p>
<p><strong>Make sure to change the super password immediately to something more secure!</strong></p>
]]></content>
        </item>
        
        <item>
            <title>Deploy a multi-node, multi-server Kafka Cluster with Docker</title>
            <link>https://nathancatania.com/posts/deploying-a-multi-node-kafka-cluster-with-docker/</link>
            <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/deploying-a-multi-node-kafka-cluster-with-docker/</guid>
            <description>What is Kafka? Essentially:
Kafka is an open-source, very scalable, distributed messaging platform by Apache. It is designed to handle large volumes of data in real-time efficiently.
Kafka works on the concept of a &amp;ldquo;publish-subscribe&amp;rdquo; methodology:
&amp;ldquo;Producers&amp;rdquo; will push content to the Kafka cluster, to a destination &amp;ldquo;topic&amp;rdquo;. A Kafka cluster is managed by Zookeeper, and can contain one or more &amp;ldquo;Brokers&amp;rdquo;. Brokers manage topics and the associated ingress and egress messages.</description>
            <content type="html"><![CDATA[<h2 id="what-is-kafka">What is Kafka?</h2>
<p><a href="https://kafka.apache.org/intro.html">Essentially:</a></p>
<blockquote>
<p>Kafka is an open-source, very scalable, distributed messaging platform by Apache. It is designed to handle large volumes of data in real-time efficiently.</p>
</blockquote>
<p>Kafka works on the concept of a &ldquo;publish-subscribe&rdquo; methodology:</p>
<ul>
<li>&ldquo;Producers&rdquo; will push content to the Kafka cluster, to a destination &ldquo;topic&rdquo;.</li>
<li>A Kafka cluster is managed by Zookeeper, and can contain one or more &ldquo;Brokers&rdquo;.</li>
<li>Brokers manage topics and the associated ingress and egress messages.</li>
<li>&ldquo;Consumers&rdquo; subscribe to specific topics and will receive a continuous stream of data from the cluster for as long as there is a Producer pushing content to that topic.</li>
</ul>
<p>Topics have two key properties: <em>partitions</em> and <em>replication factors</em>.</p>
<ul>
<li><em>Partitions</em> logically separate the messages within a topic into small &ldquo;groups&rdquo; which are distributed between all available brokers. For example, if there are 3 brokers in a cluster, and a topic has 6 partitions, Broker #1 might be assigned Partition #3 &amp; #6, Broker #2 - Partition #1 &amp; #5, and Broker #3 - Partition #2 &amp; #4.</li>
<li>A <em>replication factor</em> helps add redundancy to a topic and its partitions across the available Brokers. Using the example above, if the same topic has a replication factor of 3, then each broker would have a copy of the partitions managed by other brokers in addition to its own. Hence, if a broker goes down, the messages stored in the partitions held by it are not lost.</li>
</ul>
<p>The cool thing about Kafka consumers is that, when they are grouped together and used in conjunction with partitions, they can automatically load balance incoming messages between them!</p>
<p>This is really handy for avoiding Consumer bottlenecks if you are dealing with real-time data in high volumes. If a Consumer cannot process the incoming messages fast enough, it will fall behind and you will begin to notice an increasing delay between the current time and the incoming message. If a second Consumer is added to the same group as the first, and both are subscribed to a topic with 6 partitions, then Consumer #1 might be assigned messages from Partition #1, #2, #5, and Consumer #2 might be assigned messages from Partition #3, #4, #6. This is instead of Consumer #1 bottlenecking by having to process Partitions #1-6 by itself.</p>
<h2 id="why-docker">Why Docker?</h2>
<p>Deploying Kafka in Docker greatly simplifies deployment as we do not need to manually configure each broker individually!</p>
<p>We can use single Docker Compose file to deploy Kafka to multiple server instances using Docker Swarm in a single command. Additionally, Docker allows us to easily scale up our cluster to additional nodes in the future if we require.</p>
<h2 id="requirements">Requirements</h2>
<p>When deployed via Docker, Kafka tends to use approximately 1.3 GB - 1.5 GB of RAM per broker - so make sure your server instances have enough memory allocated and available.</p>
<h2 id="process">Process</h2>
<p>Before proceeding, make sure you have Docker installed on ALL of the servers you wish to deploy Kafka to.</p>
<h3 id="part-1---create-a-docker-swarm">Part 1 - Create a Docker Swarm</h3>
<p>To begin, we need to initialize a Docker Swarm. A Swarm will consist of at least one Master Node, and one or more Worker Nodes (or, if you just have a single server instance, a single Master Node).</p>
<h4 id="1-initialize-the-swarm--master-node">1. Initialize the Swarm &amp; Master Node</h4>
<p>On the server instance you have designated to be the Master, initialize the Swarm. This will set the current instance as the Master node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker swarm init --advertise-addr <span style="color:#f92672">[</span>MANAGER-IP<span style="color:#f92672">]</span>:2377
</span></span></code></pre></div><p>Where <code>[MANAGER-IP]</code> is the static IP address of the server instance.
You can find this using <code>ifconfig</code>.</p>
<p>This will generate a unique command which you will run on all other nodes in the next section in order to designate them as Worker nodes.</p>
<p>Save this command in a safe place.</p>
<p>Example (<strong>your command and token will be different!</strong>):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker swarm join --token SWMT<span style="color:#f92672">[</span>...<span style="color:#f92672">]</span>ewrp <span style="color:#f92672">[</span>MANAGER-IP<span style="color:#f92672">]</span>:2377
</span></span></code></pre></div><h4 id="2-check-your-firewall">2. Check your firewall</h4>
<p>Swarm nodes use port 2377 to communicate with the Master node which must not be blocked by any firewall.</p>
<p>Additionally, Swarm daemons use ports 7946 (tcp/udp) and 4789 (udp) to communicate.</p>
<p>Make sure your all of your instances are able to communicate:</p>
<ul>
<li>TCP/UDP traffic on ports 2377 and 7946.</li>
<li>UDP traffic on port 4789.</li>
</ul>
<h4 id="3-configure-the-worker-nodes">3. Configure the Worker Nodes</h4>
<p>On all other server instances you wish to deploy Kafka on, run the command generated in the step #1 above. This will add these instances to the Docker Swarm as Worker Nodes.</p>
<p>If you are having issues:</p>
<ul>
<li>As per Step #2 above, make sure all your instances can communicate on the specified ports.</li>
<li>Make sure all of your instances have static IP addresses assigned to them.</li>
</ul>
<h4 id="4-verify-the-swarm">4. Verify the Swarm</h4>
<p>On the <strong>Master Node</strong> only, run the following command to check the status of all nodes in the swarm:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker node ls
</span></span></code></pre></div><h3 id="part-2---deploying-kafka">Part 2 - Deploying Kafka</h3>
<h4 id="1-create-docker-composeyml">1. Create docker-compose.yml</h4>
<p>Copy the following into a file named <code>docker-compose.yml</code> on the Master Node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">version</span>: <span style="color:#e6db74">&#39;3.2&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">services</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">zookeeper</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#ae81ff">wurstmeister/zookeeper</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>         - <span style="color:#e6db74">&#34;2181:2181&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">kafka</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">image</span>: <span style="color:#ae81ff">wurstmeister/kafka:latest</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">deploy</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">mode</span>: <span style="color:#ae81ff">global</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">ports</span>:
</span></span><span style="display:flex;"><span>         - <span style="color:#f92672">target</span>: <span style="color:#ae81ff">9094</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">published</span>: <span style="color:#ae81ff">9094</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">tcp</span>
</span></span><span style="display:flex;"><span>           <span style="color:#f92672">mode</span>: <span style="color:#ae81ff">host</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">environment</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">HOSTNAME_COMMAND</span>: <span style="color:#e6db74">&#34;docker info | grep ^Name: | cut -d&#39; &#39; -f 2&#34;</span> <span style="color:#75715e"># Normal instances</span>
</span></span><span style="display:flex;"><span>         <span style="color:#75715e"># HOSTNAME_COMMAND: &#34;curl http://169.254.169.254/latest/meta-data/public-hostname&#34; # AWS Only</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_ZOOKEEPER_CONNECT</span>: <span style="color:#ae81ff">zookeeper:2181</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP</span>: <span style="color:#ae81ff">INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_ADVERTISED_PROTOCOL_NAME</span>: <span style="color:#ae81ff">OUTSIDE</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_ADVERTISED_PORT</span>: <span style="color:#ae81ff">9094</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_PROTOCOL_NAME</span>: <span style="color:#ae81ff">INSIDE</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_PORT</span>: <span style="color:#ae81ff">9092</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">KAFKA_CREATE_TOPICS</span>: <span style="color:#ae81ff">myTopic:3:3,anotherTopic:2:2</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">volumes</span>:
</span></span><span style="display:flex;"><span>         - <span style="color:#ae81ff">/var/run/docker.sock:/var/run/docker.sock</span>
</span></span></code></pre></div><ul>
<li>The Zookeeper container is responsible for managing the Kafka cluster.</li>
<li>Using the above configuration, you will be able to connect to your Kafka brokers using port 9094 at their designated IP/hostname.</li>
<li>Alter <code>CREATE_KAFKA_TOPICS</code> in to pre-allocate your topic names. Separate multiple topics with commas.
<ul>
<li>In the file above, two topics will be created: One with 3 partitions and 3 replications, and another with 2 partitions and 2 replications.</li>
</ul>
</li>
<li>You can specify an <code>environment</code> entry for most (if not all) Kafka configuration options. For more information, see <a href="https://github.com/wurstmeister/kafka-docker#pre-requisites">here</a>.</li>
</ul>
<p><!-- raw HTML omitted --><strong>If you are deploying to AWS!</strong><!-- raw HTML omitted -->
Comment out the <strong>first</strong> <code>HOSTNAME_COMMAND</code> line under <code>environment</code> and uncomment the <strong>second</strong> <code>HOSTNAME_COMMAND</code>.</p>
<p>There is a different method to resolving the instance hostname for AWS instances, which is critical to Kafka. <strong>Failing to do this will mean that while your broker(s) will be deployed, nothing will be able to find or connect to them.</strong></p>
<h4 id="2-check-your-firewall-again">2. Check your firewall (again)</h4>
<ul>
<li>Kafka communicates with Zookeeper on port 2181.</li>
<li>Kafka will listen for connections on 9094 and communicate internally on port 9092.</li>
<li>Make sure these ports are open for TCP/UDP traffic or you may have communication issues.</li>
</ul>
<h4 id="3-deploy-the-kafka-stack">3. Deploy the Kafka stack</h4>
<p>On the Master Node, run the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker stack deploy --compose-file docker-compose.yml kafka
</span></span></code></pre></div><ul>
<li>This will deploy a Kafka broker to each node in the Swarm, and bring online ONE Zookeeper management container.</li>
<li>Additionally, any Kafka topics specified in the <code>docker-compose.yml</code> file will be initialized.</li>
<li>The deployed service will have the name <code>kafka</code>.</li>
</ul>
<h4 id="4-verify-status">4. Verify status</h4>
<p>You can use the following command to verify the status of the Kafka stack:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker stack services kafka
</span></span></code></pre></div><p>The status for all containers should be shown. A successful launch on 3 servers (for example) should show 3/3 replicas for Kafka and 1/1 replicas for Zookeeper.</p>
<h3 id="part-3---stopping-the-cluster">Part 3 - Stopping the cluster</h3>
<p>Simply run the following command on the Master node:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker stack rm kafka
</span></span></code></pre></div><h3 id="part-4---sending--receiving-data-using-your-kafka-cluster">Part 4 - Sending &amp; Receiving data using your Kafka cluster</h3>
<p>The Kafka stack deployed above will initialize a single Kafka container on each node within the Swarm. Hence the IP address of each node is the IP address of a Kafka broker within the Kafka cluster.</p>
<p>The Kafka brokers will listen for Consumer applications and Producers on port 9094.</p>
<p>It does not matter which broker IP/hostname you use for the producer/consumer connection.
In many applications or APIs (eg: Telegraf, kafka-python etc) in which you can specify a list of brokers, only the first broker is used. The others are used as fallback (in the specified order) in case the preceding broker is unavailable or down.</p>
]]></content>
        </item>
        
        <item>
            <title>Installing Docker CE on an Air Gapped RHEL system</title>
            <link>https://nathancatania.com/posts/installing-docker-on-red-hat-with-no-internet-access/</link>
            <pubDate>Thu, 30 Nov 2017 00:00:00 +0000</pubDate>
            
            <guid>https://nathancatania.com/posts/installing-docker-on-red-hat-with-no-internet-access/</guid>
            <description>Introduction I recently completed a deployment inside a customer&amp;rsquo;s lab involving several containerized services, in which the server instances provided were not permitted to have direct access to the internet. To add to the issue, the instances themselves were running RHEL 7.3 with no active subscription.
There were several problems in play here:
Docker only make their Enterprise Edition (EE) compatible with RHEL. The usual free Community Edition (CE) is not officially supported.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>I recently completed a deployment inside a customer&rsquo;s lab involving several containerized services, in which the server instances provided were not permitted to have direct access to the internet. To add to the issue, the instances themselves were running RHEL 7.3 with no active subscription.</p>
<p>There were several problems in play here:</p>
<ol>
<li>Docker only make their Enterprise Edition (EE) compatible with RHEL. The usual free Community Edition (CE) is not officially supported.</li>
<li>Attempting to circumvent #1 by installing the RPM for Centos resulted in dependency issues.</li>
<li>Normally these dependency issues would be trivial to resolve with internet access, however in this case, no internet access was available on the instances.</li>
<li>Attempting to manually download the dependencies on another machine and transfer them to the servers resulted in more dependency issues (it was a tree of dependencies!)</li>
<li>How can the required container images be pulled with no internet access?</li>
</ol>
<p>The below writeup should cover the solution to all of these issues, so no matter what your issue is - I hope this is useful to you.</p>
<p><em>As always, proceed at your own risk. I will not be held responsible for any problems that result as a result of you following this guide.</em></p>
<hr>
<h1 id="part-1---configure-a-local-repository">Part 1 - Configure a local repository</h1>
<p><em>Skip this step if you have internet access on your target server as any issues with dependencies should resolve themselves automatically.</em></p>
<p>To resolve the dependency issues on RHEL, we are going to create a local Yum repository from the Red Hat installation media which contains resolutions to our dependency issues.</p>
<h2 id="1-download-the-rhel-iso">1. Download the RHEL ISO</h2>
<ul>
<li>Download the RHEL ISO for your applicable version (7.2, 7.3 etc).</li>
<li>RHEL ISOs can be downloaded from the <a href="https://www.gitbook.com/book/nathancatania/telemetry-backbone-installation/edit#">RedHat developer page</a> (free account required).</li>
<li>You can use the below command to check your version if unsure:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cat /etc/redhat-release
</span></span></code></pre></div><h2 id="2-copy-the-iso-to-the-required-servers">2. Copy the ISO to the required servers</h2>
<ul>
<li>The ISO will need to be copied to all the servers which Docker is to be installed on.</li>
</ul>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>scp rhel-server-7.X-x86_64-dvd.iso &lt;user&gt;@&lt;hostname&gt;:
</span></span></code></pre></div><h2 id="3-mount-the-iso">3. Mount the ISO</h2>
<ul>
<li>Mount the ISO on your target server:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>mount -o loop rhel-server-7.X-x86_64-dvd.iso /mnt
</span></span></code></pre></div><h2 id="4-copy-the-repository-locally">4. Copy the repository locally</h2>
<ul>
<li>Copy the repository from the mounted ISO and set the correct permissions.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>cp /mnt/media.repo /etc/yum.repos.d/rhel7dvd.repo
</span></span><span style="display:flex;"><span>chmod <span style="color:#ae81ff">644</span> /etc/yum.repos.d/rhel7dvd.repo
</span></span></code></pre></div><h2 id="5-edit-the-repo-file">5. Edit the repo file</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>vi /etc/yum.repos.d/rhel7dvd.repo
</span></span></code></pre></div><p><em>If you haven&rsquo;t used vi before, press <code>a</code> to enter edit mode, <code>ESC</code> to exit edit mode, and <code>:wq</code> to save and quit.</em></p>
<ul>
<li>Change the <code>gpgcheck=0</code> parameter to <code>1</code>.</li>
<li>Add the following 3 lines to the end of file (but before the <code>~</code> characters in the editor):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>enabled<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>baseurl<span style="color:#f92672">=</span>file:///mnt/
</span></span><span style="display:flex;"><span>gpgkey<span style="color:#f92672">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
</span></span></code></pre></div><p>Save and exit vi.</p>
<h2 id="6-clean-the-repositories">6. Clean the repositories</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>yum clean all <span style="color:#f92672">&amp;&amp;</span> subscription-manager clean
</span></span></code></pre></div><h2 id="7-verify-the-repo-works">7. Verify the repo works</h2>
<p>This should generate a very long packages list if working correctly.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>yum  --noplugins list
</span></span></code></pre></div><hr>
<h1 id="part-2---install-docker-ce">Part 2 - Install Docker CE</h1>
<p>Attempting to install the RPM for Centos will fail due to a missing dependency. In this part, we will download Docker CE and the dependency manually and install.</p>
<h2 id="1-download-the-docker-ce-rpm-for-centos">1. Download the Docker CE RPM for Centos</h2>
<p><em><strong>Note 1:</strong> At the time of this post, Docker 17.09.0 CE was the latest version available for Centos. You may wish to check for a more up-to-date version if applicable.</em></p>
<p><em><strong>Note 2:</strong> The Container SELinux dependency below was for RHEL 7.3. Your version may differ. Please confirm before proceeding.</em>
On your internet-enabled machine, download the Docker 17.09.0 CE package and its dependency.</p>
<p>If your instance does not have internet access, you will need to complete this step on a connected machine and then transfer the files across.</p>
<p>Docker CE:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>curl https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.09.0.ce-1.el7.centos.x86_64.rpm -o docker.rpm
</span></span></code></pre></div><p>Dependency:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>curl http://mirror.centos.org/centos/7.3.1611/extras/x86_64/Packages/container-selinux-2.9-4.el7.noarch.rpm -o containerselinux.rpm
</span></span></code></pre></div><h2 id="2-install">2. Install</h2>
<p>Make sure to run the command with both RPMs in the specific order below! The dependency should be installed first!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>yum install -y containerselinux.rpm docker.rpm
</span></span></code></pre></div><p>If the above command succeeds: congratulations! You have successfully installed Docker CE on Red Hat!</p>
<h2 id="3-optional-start-docker">3. [OPTIONAL] Start Docker</h2>
<p>Start Docker and set it to start at boot.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>systemctl start docker
</span></span><span style="display:flex;"><span>systemctl enable docker
</span></span></code></pre></div><hr>
<h1 id="part-3---transfer-docker-images">Part 3 - Transfer Docker images</h1>
<p><em>This step is not required if you have internet access available on your server</em></p>
<p>Now that Docker is installed, there is the issue of: how do we actually get our Docker images onto the server if there is no internet access available?</p>
<p>The answer is: You will pull the images on another (internet-connected) machine with Docker, save the images, and then transfer them across to your server. Docker will always attempt to use a local image <strong>first</strong> before pulling the image from a remote repo.</p>
<h2 id="1-pull-the-required-docker-images">1. Pull the required Docker images</h2>
<p>In this example, we will be pulling the images for both Zookeeper and Kafka (your images might differ).</p>
<p>On an internet-enabled machine with Docker installed, run the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker pull my_docker_image
</span></span><span style="display:flex;"><span>save -o my_docker_image.docker my_docker_image
</span></span></code></pre></div><p>Replacing <code>my_docker_image</code> with the same of the image you want to pull and save.</p>
<p>For example, for both Kafka and Zookeeper:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker pull wurstmeister/zookeeper
</span></span><span style="display:flex;"><span>docker pull wurstmeister/kafka:latest
</span></span><span style="display:flex;"><span>docker save -o zookeeper_image.docker wurstmeister/zookeeper
</span></span><span style="display:flex;"><span>docker save -o kafka_image.docker wurstmeister/kafka
</span></span></code></pre></div><p>Copy the <code>.docker</code> file(s) you saved across to your target server.</p>
<h2 id="2-load-the-docker-images">2. Load the Docker images</h2>
<p>On your target (non-internet connected) server, load the Docker images into inventory with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker load -i my_image_name
</span></span></code></pre></div><p>For example, again for both Kafka and Zookeeper:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>docker load -i kafka_image.docker
</span></span><span style="display:flex;"><span>docker load -i zookeeper_image.docker
</span></span></code></pre></div><h2 id="3-done">3. Done!</h2>
<p>You can now use Docker as you normally would with the images loaded above.</p>
]]></content>
        </item>
        
    </channel>
</rss>
